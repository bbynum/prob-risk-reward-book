[["index.html", "Probability, Risk, and Reward Preface 0.1 Motivation 0.2 About the Author", " Probability, Risk, and Reward Bill Bynum with Brian Avery 2023-08-24 Preface 0.1 Motivation Probability can be fun…and frustrating. Probability can clarify a complex situation…and sometimes be very counter-intuitive. Probability is often taught late in a formal mathematics education (if at all) with math tools including calculus and linear algebra but the results are important for many who may not have had access to these theoretical mathematical techniques such as social scientists, life scientists, business students, health science majors, and just plain-old citizens. Our experience teaching probability leads us to believe that there is a real need for teaching and explanatory materials in applied probability that is accessible without advanced prerequisite mathematics knowledge. To do this, we use a simple model of identifying an interesting problem and asking the learner to identify their preconceptions. When shared these preconceptions generate hypotheses and give the students a little skin in the game. Then the student is ready for some experience to compare against their preconceptions. We gain experience through data collection and simulation and this guides us to capture the theory that can explain the phenomena. Following this process of guided exploration we have seen students refine their intuition and develop probabilistically reasoning skills. 0.2 About the Author Bill Bynum is an Associate Professor of mathematics at Westminster University with mathematical and statistical thinking at the entry level a key focus of my teaching. Bill has taught in the math and data science programs at Westminster since 1989. He has a M.A. in mathematics from University of Colorado. "],["probability_basics.html", "Chapter 1 Probability Basics 1.1 Introduction 1.2 Chapter Scenario - The Three Card Game 1.3 Terminology 1.4 Example - Rolling a Die 1.5 Simple Events 1.6 The Complement: NOT 1.7 Compound Events: AND 1.8 Compound Events: OR 1.9 Compound Events: Conditional Probability 1.10 The Three Card Game Revisited 1.11 Exercises", " Chapter 1 Probability Basics 1.1 Introduction Probability is the measure of the likelihood of an event. In this chapter, basic terminology and principles of probability are introduced beginning. We begin with finding probabilities for simple events for such experiments as tossing a die and then examining how to handle compound events involving the logical NOT, AND, OR connectives. Then it gets exciting when we introduce conditional probability. 1.2 Chapter Scenario - The Three Card Game There are three cards – one blue both sides, one red on both sides, and one blue on one side and red on the other. The cards are shuffled (both interspersed and randomly turned over) and you receive one of the three cards and it is placed face down on the table. You know only the face you see and not the color of the other side of the card. If the other side of the card is a different color, you win \\(\\$1\\) while if the other side of the card is the same color you lose \\(\\$1\\). Figure 1.1: Three Card Game What do you think the probability is that you will win? A fair game is one in which the payoffs and probabilities give neither you nor your opponent (often called the house) a systematic advantage. Does this game sound like a “fair” game to you? Explain. 1.3 Terminology Before getting back to resolve the Three Card Game question, let’s develop some basic probability terminology. A probability experiment is a process with a random element producing a well-defined outcome. Examples of a probability experiment are such as things as tossing a die or receiving the genes that determine one’s eye color. The probability of an event is the measure of the likelihood of that event on a scale of 0 to 1 where a probability of 1 can be interpreted as certainty the event will occur and a probability of 0 interpreted as certainty the event will NOT occur. There are two main schools of thought regarding what probability is - the frequentist and the bayesian - and the debate between these schools can be heated but for our initial purposes we will think of the probability of an event as the relative frequency of its occurrence in the long run. In very informal shorthand, we think of probability as the ratio of successes to the total number of trials as shown below. \\[Probability = \\frac{successes}{total}\\] We must be careful to distinguish between exact theoretical probabilities and approximate empirical probabilities. Theoretical probability is exact and is based on assumptions about all the possible basic outcomes, often that they are equally likely. We use theoretical probability when it is reasonable to make assumptions like these about the probability experiment. Empirical probability is approximate and is based on performing the probability experiment a number of times and examining the data. We use empirical probability when the situation is complex enough that theoretical approaches are not accessible and when data can be gathered. Both approaches, the theoretical and the empirical, have value and you will learn when and how to use each of them. A third approach is subjective probability in which probability estimates are derived from personal judgments. This approach is used when theoretical and empirical approaches are not available like like for one-time events such as estimates of a certain bill passing congress. The use of subjective probability is also very powerful when combined with effective tools for updating probability estimates based on new information and evidence. These tools include Bayes’ Theorem and other techniques of bayesian statistics to be discusssed later in the text. 1.4 Example - Rolling a Die Consider the probability experiment of rolling a die. We say it is a fair die if each of the six sides are equally likely. With this assumption, we can approach probability questions using theoretical probability. In this case, the probability of the die landing on any particular side is \\(1/6\\) which can also be approximated as \\(0.167\\) or \\(16.7\\%\\). This means that as the experiment is repeated over and over again the proportion of the time the die lands on that particular side ultimately approaches \\(frac{1}{6}\\). Note, a probability equalling \\(1/6\\) does not mean that in any number of trials we will obtain that result exactly \\(1/6\\) of the time as samples will vary. An empirical approach to the probability experiment of rolling a die would be to actually perform the experiment a large number of times and observe what happens. Running a simulation of rolling a fair die might be instructive here. The R code below performs 10,000 trials of rolling a die and recording the results in both a table and a histogram. At this point, focus on the output and don’t worry so much about the R code. die &lt;- sample(x=1:6, size=10000, replace = TRUE) sim_die &lt;- data.frame(die) knitr::kable(table(sim_die), caption = &#39;Frequency Table for the Tossing One Die Simulation&#39;, booktabs = TRUE ) Table 1.1: Frequency Table for the Tossing One Die Simulation die Freq 1 1674 2 1659 3 1660 4 1700 5 1674 6 1633 Each row of the frequency table shows how often 1, 2, 3, 4, 5, and 6 appeared in our simulation of 10,000 tosses. Because samples vary, we do not get each face appearing exactly \\(1/6\\) of the time but when we examine the data visually in a histogram we see how similar the outcomes are. When interpreting empirical data we need to be aware of this issue of sampling variation. ggplot(sim_die, aes(x=as.factor(die), y=..prop.., group=1)) + geom_bar() + labs(x=&quot;die roll result&quot;, y=&quot;proportion&quot;) ## Warning: The dot-dot notation (`..prop..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(prop)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. Figure 1.2: Relative Frequency Histogram for Tossing One Die An event is any well-defined outcome of the probability experiment. For this experiment of rolling a die, one example of an event would be the outcome of rolling an even number. We often use function notation when describing probabilities. For a well-defined event A in a probability experiment we will use P(A) to represent the probability event A occurs. We also informally use short descriptions of events combined with probability function notation as long as the context is clear. For example, when tossing a die, if it is clear from the context that we mean the event of getting a six, we might write \\(P(Six) = 1/6\\). The sample space is a list of all possible outcomes of a probability experiment. One desirable property of a sample space description is that the simple events we use are equally likely, meaning all have the same probability of occurring. For example, with the experiment of tossing one die the sample space is \\(\\{1,2,3,4,5,6\\}\\). Figure 1.3: Sample Space for One Die 1.5 Simple Events To gain some experience using sample spaces to determine probabilities consider the following simple events for the experiment of tossing one die: E: getting an even outcome S: getting a six L: getting a number less than three By simply determining the ratio of successes to total members of the sample space \\(\\{1,2,3,4,5,6\\}\\), the probability of an event is found. Getting an even can occur in three ways out of six so the probability of event E is \\(3/6\\). In probability notation we write \\(P(E) = 3/6\\). Figure 1.4: An Even Outcome on One Die Getting a six occurs in only one of six ways so the probability of event S is \\(1/6\\) and expressed in probability notation as \\(P(S)=1/6\\). Figure 1.5: An Outcome of Six on One Die Getting a number less than three can occur in two ways so the probability of event L is \\(2/6\\) and expressed in probability notation as \\(P(L)=2/6\\). Figure 1.6: An Outcome Less Than Three on One Die 1.6 The Complement: NOT We now consider compound events consisting of certain logical combinations of other events. We begin with the complement. The complement of an event A consists of all the outcomes that are NOT outcomes of A. We use the notation not A to represent the complement of A. (Note, some sources use \\(\\bar{A}\\) though this can be confusing as the same symbol in other contexts represents the mean of a sample. Other sources may use yet different notation for the complement including \\(E^c\\) and \\(\\tilde E\\).) As an example, we can find the probability of the complements of the above described events for the toss of one die. The complement of obtaining an even number is obtaining an odd number and this can happen three ways out of six so \\(P(not \\ E)=3/6\\). The complement of obtaining a six would be obtaining anything other than a six. This can happen five ways out of six so \\(P(not \\ S)=5/6\\). Be careful with inequalities. The complement of obtaining a die result less than three would be obtaining a die result greater than or equal to three. This can happen four ways out of six so \\(P(not \\ L)=4/6\\). 1.6.1 The Complement Principle Observe the relationship between \\(P(A)\\) and \\(P(not \\ A)\\) for different events. Just as the chance of getting rain and the chance of not getting rain add to \\(100\\%\\), we see that the probabilities of an event and its complement add to 1. This relationship between the probability of an event and its complement is called The Complement Principle which will be a very important problem-solving tool. Theorem 1.1 (The Complement Principle) For all events A, \\(P(A)+P(not \\ A) = 1\\). An alternative version of the Complement Principle reads \\(P(A) = 1 - P(not \\ A)\\). 1.7 Compound Events: AND When we talk about the compound event A and B we mean the event where both events A and B occur. As an example, if we were considering the sample space of students in class and we were interested in the event “Female and Sophomore” only individuals who are female sophomores would qualify. Again, different texts use different notation so don’t be surprised to see on different occasions \\(A \\ and \\ B\\) as well as \\(A \\ \\&amp; \\ B\\) or even \\(A \\cap B\\) and sometimes \\(A \\wedge B\\). We just can’t seem to agree on one symbol. We will most often use \\(A \\ and \\ B\\) to represent the compound event of both A and B occurring. For the experiment of tossing one die and the events defined above, we can find the probability of \\(E \\ and \\ S\\), \\(E \\ and \\ L\\), as well as \\(S \\ and \\ L\\). The only member of the sample space that is both even and six is six itself so \\(P(E \\ and \\ S)=1/6\\). Figure 1.7: Being Both Even and a Six on One Die The only member of the sample space that is both even and less than three is two so \\(P(E \\ and \\ L)=1/6\\). Figure 1.8: Being Both Even and Less Than Three on One Die Examining the sample space to find elements that are both six and less than three we see there are no such creatures. Thus, \\(P(S \\ and \\ L)=0\\). 1.7.1 Mutually Exclusive Events When two events cannot occur at the same time we say they are mutually exclusive or, equivalently, disjoint. For example, the events of selecting a Sophomore student and selecting a Junior student from our class are mutually exclusive events. For the experiment of rolling one die and the events E, S, and L defined above, we see events S and L are mutually exclusive since one cannot roll a six and a number less than three at the same time on the same die. This is indicated in the diagram below showing there is no overlap. Figure 1.9: Being Both a Six and Less Than Three on One Die Cannot Occur Here is the precise definition of mutually exclusive events: Definition 1.1 (Mutually Exclusive) Events A and B are mutually exclusive if and only if \\(P(A \\ and \\ B)=0\\). 1.8 Compound Events: OR We now consider the compound event E or F meaning that either event E occurred or event F occurred or both occurred. We call this an inclusive or. As an example, if we were considering the sample space of students in class and we were interested in the event of selecting a “Male or Sophomore” then this includes all individuals who are male, who are sophomore, or who are both male and sophomore. For the experiment of rolling one die and the events defined above, we can find the probability of the event \\(E \\ or \\ S\\), \\(E \\ or \\ L\\), as well as \\(S \\ or \\ L\\). In the image of the sample space below we see that after circling the elements that are even and marking the element that is six, a total of three elements are identified. Thus, \\(P(E \\ or \\ S)=3/6\\). Figure 1.10: Three Outcomes are Even or a Six In the image of the sample space below, we see that after circling the elements that are even and boxing the elements that are less than three, a total of four elements are identified. Thus, \\(P(E \\ or \\ L)=4/6\\). Figure 1.11: Four Outcomes are Even or Less Than Three In the image of the sample space below we see that after putting a triangle around the element six and boxing the elements that are less than three, a total of three elements are identified. Thus, \\(P(S \\ or \\ L)=3/6\\). Figure 1.12: Three Outcomes are Less Than Three or a Six 1.8.1 Minding the Overlap Suppose someone notices that \\(P(S \\ or \\ L) = P(S) + P(L)\\). When will a fact like this be true and when not? In examining the sample spaces above we see that events S and L are mutually exclusive. In this case, the probability of one event or the other will be the sum of the two individual probabilities. In the other cases, we see the events are not mutually exclusive. Events E and L share the element two and events E and S share the element six. In these cases, we cannot add the individual probabilities to find the probability of one or the other because elements in the overlap will be counted twice. In a later chapter, these insights are summarized in the Addition Principle and Special Addition Principle. 1.9 Compound Events: Conditional Probability We consider one more way of “connecting” simple events to form a compound event. The conditional event \\(X|Y\\) means the event X given we know event Y occurred and we pronounce it “X given Y”. As an example, if we were considering the sample space of students in class and we were interested in the event \\(Female \\ | \\ Sophomore\\) we would mean given Sophomores only, what is the probability of being Female. Note, this is different from \\(Sophomore \\ | \\ Female\\) which is the probability you are Sophomore given you are Female. Tossing one die with the events as described above, \\(P(L \\ | \\ E)\\) represents the probability of L given we know E occurred, that is, the probability of a number less than three given we know the number is even. Knowing it is even narrows down the sample space to three options, \\(\\{2,4,6\\}\\). Figure 1.13: Revised Sample Space Given it is Even on One Die Of those three options, only one of those is less than three, thus, \\(P(L \\ | \\ E) = 1/3\\). Figure 1.14: Being Less Than Three Given it is Even on One Die Conditional probabilities are very important and a little more practice is in order. First, we note that the event \\(L \\ | E\\) means something different than the event \\(E \\ | L\\). To find \\(P(E \\ | L)\\) we note that given event L occurred means the new sample space has just two elements, \\(\\{1,2\\}\\). Figure 1.15: Revised Sample Space Given it is Less Than Three on One Die And of these two options only one is even. Thus, \\(P(E \\ | L)=1/2\\). Figure 1.16: Being Even Given it is Less Than Three on One Die Consider the event $ S  | E$. Given that event E occurred we know the outcome is even so our new sample space has only three outcomes, \\(\\{2,4,6\\}\\). Of these, one is a six. Thus, \\(P(S \\ | E)=1/3\\). Figure 1.17: Being Six Given it is Even on One Die The event \\(E \\ | S\\) has a different meaning. Given that event S occurred we know the outcome was a six so the new sample space has only this one outcome, \\(\\{6\\}\\), and it is even. Thus, \\(P(E \\ | S)=1/1=1\\). Figure 1.18: Being Even Given it is a Six on One Die To find \\(P(S \\ | \\ L)\\) we restrict our sample space to the two outcomes, \\(\\{1,2\\}\\), where L occurred and note that neither of them is six. Thus, \\(P(S \\ | \\ L)=0/2=0\\). Figure 1.19: Being Six Given Less Than Three on One Die In this case, \\(P(L \\ | \\ S)\\) is also 0 since if we are given event S we know that L could not have occurred. Because events L and S are mutually exclusive we see that \\(P(L \\ | \\ S)=0\\). 1.9.1 Observations about Conditional Probability As we develop our probabilistic thinking ability, we will learn a lot about the power of conditional probability. Here are some initial observations. First, note that, in general, for events A and B, \\(P(A \\ | \\ B)\\) means something very different from \\(P(B \\ | \\ A)\\) and, consequently, the probabilities are usually different. Second, note in cases where the events A and B are mutually exclusive that \\(P(A \\ | \\ B)=0\\). Third, in some cases, the conditional probability is the same as the original probability. Interestingly, in our examples above, \\(P(L)\\) and \\(P(L \\ | \\ E)\\) are equal. This means that event E gave us no information about the occurrence of L and we say that events E and L are independent. When knowledge that E occurred did not change the probability of L occurring and we say these two events are independent. Here is the formal definition. Definition 1.2 (Independence) Event A and B are independent if and only if \\(P(A \\ | \\ B)=P(A)\\). Note that if A and B are independent then not only does \\(P(A \\ | \\ B)=P(A)\\) but it is also true that \\(P(B \\ | \\ A)=P(B)\\). If two events are not independent we may say that they are dependent. 1.10 The Three Card Game Revisited We consider the game described in the chapter scenario. Three cards – one blue on both sides, one red on both sides, and one blue on one side and red on the other - are shuffled (both interspersed and randomly turned over) and one card is randomly placed face down on the table. If the other side of the card has a different color, you win \\(\\$1\\) while if the other side of the card has the same color you lose \\(\\$1\\). Here is one common faulty analysis of this situation: Once you see the color of the side that is showing this narrows down the possibilities to two - 1) the card with the same color on the other side, and 2) the card with the other color on the other side - thus, mistakenly, we might believe there is a 50/50 chance the other side has the same color. There is a subtle error in the above thinking. While we are correct in seeing there are only two possible cards we are incorrect in thinking they are equally likely. It turns out, we are more likely to have been shown the card with same color on both sides. Thus, the error is we selected a sample space in which the outcomes are not equally likely. In order to make sure we obtain a sample space with equally likely outcomes we might create an artificial distinction so we can tell similar events apart. Suppose we mark the two sides of the blue card as B1 and B2, the two sides of the red card as R1 and R2, and the two sides of the other card as B3 and R3. Then the sample space of which side we have been shown is \\(\\{B1, B2, R1, R2, B3, R3\\}\\) and, because the cards have been randomly shuffled and turned, each of these are equally likely. Out of these six elements of the sample space, in four of the cases the other side of the card the same color - B1, B2, R1, R2 - and in only two cases - B3, R3 - is the other side the opposite color. Thus, the probability the other side is the same color is \\(4/6=2/3\\) and the probability the other side is a different color is \\(2/6=1/3\\). This makes sense because on two of the three cards we will always lose and only on the one card that is different on both sides will we win. Unfortunately, this means we are more likely to lose \\(\\$1\\) than to win \\(\\$1\\) and the game is not fair. 1.11 Exercises 1.11.1 Exercise - The Monty Hall Problem You are shown three doors. Behind one is a car, behind the other two are goats. You are to choose one door. Hopefully you get the car. To spice it up, Let’s Make a Deal host, Monty Hall, who knows exactly what is behind each door, reveals a goat behind one of the doors that you have not chosen. Now, there remain two doors – the one you chose, and the other unopened door. Monty asks you if you want to switch doors. Should you? Figure 1.20: Monty Hall Problem 1.11.2 Exercise - Twelve-sided Die Consider the different probability experiment of tossing one 12-sided Dungeons and Dragons dice. Describe the sample space and identify several events and find the probabilities of these simple events as well as at least one complement, one AND, one OR, and one conditional probability. Use probability function notation where appropriate. Figure 1.21: Twelve-sided Die "],["tree_diagrams.html", "Chapter 2 Tree Diagrams 2.1 Introduction 2.2 Chapter Scenario - Kitty Litter 2.3 Example - Flipping Two Coins 2.4 Terminology Review 2.5 Simulation 2.6 Tree Diagrams 2.7 An Example with Rats 2.8 Chapter Scenario Revisited - Kitty Litter 2.9 The Urn Model 2.10 Exercises", " Chapter 2 Tree Diagrams 2.1 Introduction In this chapter, tree diagrams are introduced as important tools to analyze probability questions. 2.2 Chapter Scenario - Kitty Litter Turns out much to our surprise the new cat was PREGNANT! Now, we have four little kittens we are not sure what to do with. They are adorable. Wonder about their sex!? I think that the most likely possibility is two female kittens and two male kittens. My partner begs to differ and thinks a 3-1 split is more likely. Can you help us out by thoroughly analyzing this situation and clearly explaining which of us is right? We have a bet and I don’t want to be the one to take out the litter box for the next year! 2.3 Example - Flipping Two Coins Imagine a simple situation where two coins are tossed and the number of heads is observed and the outcome has some relevance for you depending on whether the result yields 0, 1, or 2 heads. Do you think each of these outcomes is equally likely? What do you think is the probability of each of these outcomes? We use this coin-flipping scenario as a primary example not because we have inherent interest flipping coins but because this scenario is an effective model for many real-world situations such as gene inheritance. We can review probability terminology, run a simulation, and then see how tree diagrams help us analyze this situation. 2.4 Terminology Review We have described probability as the measure of the likelihood of an event on a scale of 0 to 1 with 0 meaning certain failure and 1 meaning certain success. \\[Probability = \\frac{successes}{total}\\] Consider a coin is flipped and we examine whether it lands on heads or tails. We say it is a fair coin if heads and tails are equally likely. In this case, the probability of the coin landing on heads is \\(1/2\\) which can also be expressed as \\(0.5\\) or \\(50\\%\\) meaning that as the experiment is repeated the proportion of heads ultimately approaches \\(0.50\\). Of course, sample vary so in any given number of trials the result may not be exact. The probability experiment of flipping a coin twice and counting the number of heads leads to three possible outcomes - 0 heads, 1 head, or 2 heads but this might not be a useful sample space because these three outcomes may not be equally likely. To explore this, we could gather data by performing the experiment many times and recording the outcome but in this case a simulation might be faster and provide a larger sample much more quickly. Besides, you may not have a coin in your pocket. 2.5 Simulation Simulation is often a helpful tool to explore probability questions like the question above regarding whether getting 0, 1, or 2 heads when flipping two coins are all equally likely. The code below simulates 10,000 trials of two coin flips keeping track of the number of heads, number of tails, and proportion of heads for each trial. sim_2 &lt;- do(10000)*rflip(n=2, prob=1/2) knitr::kable( head(sim_2), caption = &#39;Table 1: Two Coin Simulation&#39;, booktabs = TRUE ) Table 2.1: Table 1: Two Coin Simulation n heads tails prop 2 0 2 0.0 2 0 2 0.0 2 1 1 0.5 2 2 0 1.0 2 1 1 0.5 2 2 0 1.0 The result is visualized in a histogram of the heads variable showing the frequency of obtaining 0, 1, and 2 heads. ggplot(data=sim_2, aes(x=heads)) + geom_histogram(aes(y=..density..), binwidth = 1) Figure 2.1: Histogram for Number of Heads When Flipping Two Coins Examining the histogram we see that obtaining one head is more likely than the other two options and, thus, getting 0, 1, and 2 heads when flipping two coins are not equally likely outcomes. Prompted by the results of the simulation, we want to know why getting one head is more likely and tree diagrams will help us. 2.6 Tree Diagrams The outcomes of a probability experiment can be catalogued with a tree diagram where at each node the different branches represent the different possible outcomes at each stage of the process. Consider the tree diagram for flipping a single coin where we label each node as either H for Heads or T for tails and label the probability along each branch. Figure 2.2: Tree Diagram for One Coin Including the possible outcomes for a second coin results in a tree diagram with four branches. Figure 2.3: Tree Diagram for Two Coins Each path from the top of the tree to the bottom represents one possible outcome when tossing two coins. In this experiment, there is a 50/50 chance of getting heads or tails thus all four paths are equally likely each occurring with probability \\(0.5 \\times 0.5 = 0.25\\). If we think of the probability associated with each branch as the proportion of the time we travel down that branch then multiplying these probabilities makes perfect sense to determine the probability of traveling down sequential branches. We can now understand why getting one head is more likely as there are two paths, HT and TH, compared to only one path generating zero heads, TT, and only one path generating two heads, HH, resulting in the following probabilities: \\[P(0\\ heads) = P(TT) = (0.5)(0.5) = 0.25\\] \\[\\small P(1\\ head) = P(TH\\ or\\ HT) = P(TH) + P(HT) = (0.5)(0.5) + (0.5)(0.5) = 0.25 + 0.25 = 0.5\\] \\[P(2\\ heads) = P(HH) = (0.5)(0.5) = 0.25\\] 2.7 An Example with Rats Now consider the experiment of choosing three rats at random from a large population of rats that is 40% male and 60% female. Just as we did for coins, we can draw a tree diagram with branches representing the sex of the first, second, and third rat chosen and label the associated probabilities on each branch. Selecting the rats and identifying gender would be equivalent to having a coin that lands on one side 40% of the time and on the other 60% of the time. In the tree diagram below, we have added subscripts to identify whether we are referring to the first, second, or third rat selected. Figure 2.4: Tree Diagram for Three Rats What is the probability of selecting 0 female rats? Note that because the population is large at each stage of the process the probability of selecting a female rat remains for all practical purposes 0.60. \\[P(0\\ female\\ rats) = P(M_{1}\\ and\\ M_{2}\\ and\\ M_{3}) = (0.4) \\times (0.4) \\times (0.4) = 0.064\\] What is the probability of selecting 1 female rat? There are actually three distinct paths through the tree where 1 female rat and 2 male rats are selected and each one has the probability \\((0.6) \\times (0.4)^2\\) thus the probability is \\[P(1\\ female\\ rat) = 3 \\times (0.6) (0.4)^2 = 0.288\\] 2.7.1 Practice For the probability experiment described above, choosing three rats at random from a large population of rats that is 40% male and 60% female, what is the probability of getting 2 female rats? 3 female rats? 2.8 Chapter Scenario Revisited - Kitty Litter Recall our surprise - four kittens on the way! Concerning the kittens sexes, is a 2-2 or a 3-1 split is more likely? There was a bet riding on the matter. Were you able to help us? Did you use a tree diagram to visualize the sample space? We can let F represent the event of a female kitten and M represent the event of a male kitten. We can use subscripts 1, 2, 3, and 4 to represent the first-born, second-born, and so on. A tree diagram will show us there are 16 possible birth orderings by sex. Assuming that getting a female kitten and getting a male kitten are equally likely events, all branches in this tree are equally likely. Figure 2.5: Tree Diagram for Four Kittens Counting branches, we see there are six branches with a 2-2 sex split of two female kittens and two male kittens. Thus, the probability of a 2-2 sex split is \\(6/16\\). Again counting branches, there are eight branches with a 3-1 sex split of either three females and one male or three males and one female. Thus, the probability of a 3-1 sex split is \\(8/16=1/2\\). Therefore, the 3-1 split is more likely than the 2-2 split. Is it possible they can be trained to enjoy the go out of doors and not in the house? 2.9 The Urn Model When confronted with a question of personal importance to you where probabilistic concerns are relevant to getting an accurate answer, the ability to develop a model that captures important probability details is a key problem-solving tool. By model we mean a systematic description that shares all of the important characterics of the problem, be it a physical, visual, mathematical, or computational representation (http://www.dictionary.com/browse/model). For probability experiments two useful models are the coin-flipping model and the urn model. We have already looked briefly at a coin-flipping experiment. We will see throughout our probabilistic treatment of genetics that we will often use coin-flipping as a mental model to think about questions of genetic risk and reward. The urn model is another important way to think about probability questions. Consider an urn with some beads in it. Imagine the urn has 20 beads 12 of which are black and 8 white and we are to draw out three of these beads at random and we want to find the probability of ending up with 0, 1, 2, or 3 black beads. Figure 2.6: The Urn Model First, we need to be clear up one question: is the drawing out of beads to be done with replacement or without replacement? By with replacement we mean that after each draw of one bead, it is replaced, the beads thoroughly mixed, before another bead is selected at random. By without replacement we mean that after one bead is removed, it is not replaced before the next bead is selected. Note, if we are selecting three beads at once this could be viewed as equivalent to selecting the beads one at a time without replacement. Figure 2.7: Tree Diagram for Three Beads For this experiment with three beads drawn at random without replacement from an urn containing 12 black and 8 white beads, what is the probability of ending up with 0, 1, 2, or 3 black beads, respectively? First, let’s tackle the probability of getting 0 black beads. From examining the tree we see \\[P(0\\ blacks) = P(W_{1}\\ and\\ W_{2}\\ and\\ W_{3}) = \\frac{8}{20} \\times \\frac{7}{19} \\times \\frac{6}{18}\\] Finding the probability of one black is more work. As we examine the tree we see there are three distinct paths resulting in one black. Check out their separate probabilities here. \\[P(B_{1}\\ and\\ W_{2}\\ and\\ W_{3}) = \\frac{12}{20} \\times \\frac{8}{19} \\times \\frac{7}{18} = 0.098\\] \\[P(W_{1}\\ and\\ B_{2}\\ and\\ W_{3}) = \\frac{8}{20} \\times \\frac{12}{19} \\times \\frac{7}{18} = 0.098\\] \\[P(W_{1}\\ and\\ W_{2}\\ and\\ B_{3}) = \\frac{8}{20} \\times \\frac{7}{19} \\times \\frac{12}{18} = 0.098\\] In spite of the numerators being in different orders, we notice that these three separate probabilities are numerically equal. Thus, for the final probability we see \\[P(1\\ black) = 3 \\times \\frac{12}{20} \\times \\frac{8}{19} \\times \\frac{7}{18} = 0.295\\] 2.9.1 Practice For the urn described above containing 12 black and 8 white beads with three beads drawn at random without replacement, what is the probability of obtaining two black beads? What is the probability of obtaining three black beads? 2.9.2 An Urn Model with Replacement Consider a situation where an urn contains beads that are drawn with replacement. This means that after one bead has been randomly selected, its color is noted and it is replaced in the urn before the second one is randomly drawn and after each draw the bead is replaced. In this context, the composition of the urn remains the same and the probabilities do not change meaning that what happens when drawing one bead is independent of what happens on another draw. An urn model where beads are drawn with replacement can represent many probability experiments. Consider the chapter scenario. An urn model representing examining the sex composition of four kittens would be an urn containing two beads, one white and one black, where the white bead represents a female kitten and a black bead represents a male kitten. From this urn, four beads would be drawn at random with replacement. Figure 2.8: An Urn Model for Four Kittens 2.10 Exercises 2.10.1 Exercise - Three Coins in the Fountain A penny, a nickel, and a dime are all flipped at the same time. Draw an appropriate tree diagram with associated probabilities labeled on each branch and find the probabilities of the following events: obtaining no heads, obtaining exactly one head, exactly two heads, and exactly three heads. 2.10.2 Exercise - More Coins Draw a tree diagram for the probability experiment of flipping four coins. Label each node as either H for Heads or T for tails and label the probability along each branch. Find the probability of obtaining no heads and the probability of obtaining at least one head and describe the relationship between these two probabilities. 2.10.3 Exercise - Class Committee Consider the experiment of selecting a committee of three individuals from a class of 20 of which 8 are male and 12 are female. Draw a tree diagram with associated probabilities for the sex of the first, second, and third person chosen for the committee and find the probabilities the committee consists of 0 females, 1 female, 2 females, and 3 females, respectively. "],["multiple_events.html", "Chapter 3 Multiple Events 3.1 Introduction 3.2 Chapter Scenario - The Game of Diff 3.3 Example - Pair of Dice 3.4 Fundamental Counting Principle 3.5 Example - Galileo’s Dice Problem 3.6 Chapter Scenario Revisited - The Game of Diff 3.7 Exercises", " Chapter 3 Multiple Events 3.1 Introduction After being introduced to the basic terminology of probability, we want to see how probability works in more complex situations. In this chapter we tackle dealing with multiple events and using the Fundamental Counting Principle. 3.2 Chapter Scenario - The Game of Diff Suppose the casino has hired you as a consultant to create a simple but appealing dice game. It is proposed that the player pays a certain fee and then rolls two dice. The difference between the dice is tabulated and the player receives that amount in dollars. The casino wants to know how much to charge for this game. Your job as consultant is to determine an appropriate price which, while appealing to the player, will also generate a consistent profit for the casino. To decide, first estimate what you think the average winnings for this game would be and, second, what price you think would appeal to the player but also generate a consistent profit for the casino. Figure 3.1: Game of Diff Example After estimating the average winnings, play the game ten times with a partner documenting the actual difference. Based on this preliminary data does it look like you made a reasonable choice for price? Why or why not? 3.3 Example - Pair of Dice After working with the toss of one die in the previous chapter, we examine the outcomes when tossing two dice to explore how to handle multiple events. Earlier you examined the experiment of tossing one die. The sample space for this experiment is the set of equally likely outcomes S={1,2,3,4,5,6} and the probability of different simple and compound events can be found using this sample space. When examining two dice, one might naively consider all the different outcomes one could get when summing the dice and proceed with a possible sample space of S = {2,3,4,5,6,7,8,9,10,11,12}. You might suspect this is not a useful sample space based on experience. It seems like getting a sum of 2 or 12 is unusual but getting a sum of 7 occurs more frequently. The simulation below generates 10,000 tosses of two dice and their sum and helps us see that these sums are not equally likely and thus not a great sample space to work with. die1 &lt;- sample(x=1:6, size=10000, replace = TRUE) die2 &lt;- sample(x=1:6, size=10000, replace = TRUE) sum &lt;- die1 + die2 sim_two_dice &lt;- data.frame(die1, die2, sum) knitr::kable( table(sum), caption = &#39;Tossing Two Dice Simulation&#39;, booktabs = TRUE ) Table 3.1: Tossing Two Dice Simulation sum Freq 2 277 3 565 4 789 5 1075 6 1386 7 1698 8 1442 9 1143 10 812 11 528 12 285 ggplot(data=sim_two_dice, aes(x=sum)) + geom_histogram(aes(y=..density..), binwidth = 1) Figure 3.2: Histogram for Tossing Two Dice It is often helpful to clarify a probability experiment and its sample space by making an artificial distinction. Pretend the dice are different colors, say, the first die white and the second die black. This allows us to distinguish between the individual outcomes on each die. Given that the six different outcomes on each side are equally likely, the resulting \\(6 \\cdot 6 = 36\\) outcomes illustrated in the table below provides a sample space of equally likely outcomes from which to find the probability of events you are interested in. Since there are 6 ways to roll the first white die and 6 ways to roll the second black die there are \\(6 \\cdot 6 = 36\\) ways to roll both dice. This insight uses the Fundamental Counting Principle described below: 3.4 Fundamental Counting Principle Consider a multi-step process requiring k steps. If Step1 can be done \\(n_{1}\\) ways, Step2 can be done $n_{2} ways, and so on up to Step k being done $n_{k} ways, then the total number of ways the entire process can be done \\(n_{1} \\cdot n_{2} \\cdot ... \\cdot n_{k}\\) ways. Furthermore, since all outcomes on each individual die are equally likely these 36 possibilities represent equally likely outcomes for the experiment of tossing two dice. We can use this sample space to answer some questions. Figure 3.3: Sample Space for Two Dice For example, there is only one combination of dice that yields a sum of 2 (that is 1+1) and there is only one combination of dice that yields a sum of 3 (that is 1+2) but a sum of 3 is twice as likely because when we distinguish the dice we see 1+2 and 2+1 as distinct options and we get \\(P(sum=2)=1/36\\) while \\(P(sum=3)=2/36\\). Let’s try another one: which is more likely, a sum of 6 or a sum of 7? From the sample space we see five ways to obtain a 6 and six ways to obtain a 7 indicating a sum of 7 is more likely. Stated as probabilities, \\(P(sum=6)=5/36\\) and \\(P(sum=7)=6/36\\). 3.4.1 Practice Which is more likely when tossing two dice, a sum of 3 or a sum of 11? Explain. Simply by counting successes in the sample space we find the probability of compound events. Let’s define a few events for this experiment of tossing two dice and find the probabilities of related compound events. E: The sum is even. F: The sum is less than or equal to 5. It is helpful to identify members of the sample space satisfying each event. Figure 3.4: Sample Space for Two Dice with Events E and F We see \\(P(E)=18/36=1/2=0.5\\) and also note \\(P(not \\ E)=18/36=1/2=0.5\\). From the sample space, \\(P(F)=10/36\\) and \\(P(not \\ F)=26/36\\). Looking at compound events, recall that AND refers to the overlap where both events are true so \\(P(E \\ and \\ F)=4/36\\). We think of OR as an inclusive or representing the event one or the other or both occur. Counting unique elements of the sample space that are either an even sum or a sum less than or equal to five we see \\(P(E \\ or \\ F)=24/36\\). Conditional probability is trickier. \\(P(E \\mid F)\\) means the probability that the sum is even given we know the sum is less than or equal to five. To handle this, we assume the sum is less than or equal to five and this narrows down our sample space to 10 possibilities of which 4 have an even sum yielding \\(P(E \\mid F)=4/10\\). Figure 3.5: Sample Space for Two Dice Given F It means something quite different to consider \\(P(F \\mid E)\\), the probability the sum is less than or equal to five given it is even. Out of the 18 even sums, we find 4 of them are less than or equal to five yielding \\(P(F \\mid E)=4/18\\). Figure 3.6: Sample Space for Two Dice Given E It is important to note we found all of the probabilities above by focusing on the meaning of the events rather than some fancy formula. 3.4.2 Practice For the experiment of tossing two dice with the event D being the sum is odd and the event T being at least one of the dice is a three find P(D), P(T), P(not D), P(not T), P(D and T), P(D or T), P(D|T), and P(T|D). 3.5 Example - Galileo’s Dice Problem In Galileo’s day, a clear understanding of probability was still being developed. While Galileo is well-known for his work on inventing the telescope and pointing it for the first time at the moon, his experimental approach to understanding the physics of motion dropping objects from the Tower of Pisa, and, most famously, his advocation of the Copernican planetary model and his subsequent condemnation by church authority, Galileo was also exploring the fundamental notions of chance. The king approached Galileo for help with a mathematical problem. There was a gambling game involving tossing three dice. According to conventional reasoning a sum of nine should occur with the same frequency as a sum of ten because there were an equal number of ways to obtain each. There were six dice combinations to obtain a sum of 9 - 1+2+6, 1+3+5, 1+4+4, 2+2+5, 2+3+4, and 3+3+3. Similarly, there were six dice combinations to obtain a sum of 10 - 1+3+6, 1+4+5, 2+2+6, 2+3+5, 2+4+4, and 3+3+4. However, it had been observed that a sum of ten occurred more frequently than a sum of nine. While not thrilled to divert his attention to solving the king’s problems, Galileo nevertheless looked into the issue and thereby advanced the theory of probability. We can walk in Galileo’s footsteps and discover why the theory of the time and the real-world experience did not agree? To see how Galileo solved this problem we need to absorb the lesson of creating a helpful artificial distinction. Let’s pretend we can tell the dice apart. First of all, since there are 6 equally likely outcomes on each die, there are \\(6 \\cdot 6 \\cdot 6=216\\) total equally likely outcomes in the sample space. Let’s examine the different combinations of 9 and 10 in the light of distinguishable dice where order matters. Sum of Nine Combo 1+2+6 - Orderings 1+2+6, 1+6+2, 2+1+6, 2+6+1, 6+1+2, 6+2+1 Combo 1+3+5 - Orderings 1+3+5, 1+5+3, 3+1+5, 3+5+1, 5+1+3, 5+3+1 Combo 1+4+4 - Orderings 1+4+4, 4+1+4, 4+4+1 Combo 2+2+5 - Orderings 2+2+5, 2+5+2, 5+2+2 Combo 2+3+4 - Orderings 2+3+4, 2+4+3, 3+2+4, 3+4+2, 4+2+3, 4+3+2 Combo 3+3+3 - Orderings 3+3+3 Sum of Ten Combo 1+3+6 - Orderings 1+3+6, 1+6+3, 3+1+6, 3+6+1, 6+1+3, 6+3+1 Combo 1+4+5 - Orderings 1+4+5, 1+5+4, 4+1+5, 4+5+1, 5+1+4, 5+4+1 Combo 2+2+6 - Orderings 2+2+6, 2+6+2, 6+2+2 Combo 2+3+5 - Orderings 2+3+5, 2+5+3, 3+2+5, 3+5+2, 5+2+3, 5+3+2 Combo 2+4+4 - Orderings 2+4+4, 4+2+4, 4+4+2 Combo 3+3+4 - Orderings 3+3+4, 3+4+3, 4+3+3 Tallying the orderings we see there are 25 orderings yielding a sum of 9 and 27 yielding a sum of 10 thus \\(P(sum=9)=25/216=0.116\\) while \\(P(sum=10)=27/216=0.125\\) confirming the real-world experience that a sum of 10 is actually more likely than a sum of 9. A simulation might reinforce this. We simulate the sum of 10,000 tosses of three dice and examine the frequency table of results. die1 &lt;- sample(x=1:6, size=10000, replace = TRUE) die2 &lt;- sample(x=1:6, size=10000, replace = TRUE) die3 &lt;- sample(x=1:6, size=10000, replace = TRUE) sum3 &lt;- die1 + die2 + die3 sim_three_dice &lt;- data.frame(die1, die2, die3, sum3) knitr::kable( table(sum3), caption = &#39;Tossing Three Dice Simulation&#39;, booktabs = TRUE ) Table 3.2: Tossing Three Dice Simulation sum3 Freq 3 45 4 136 5 277 6 451 7 704 8 971 9 1156 10 1197 11 1301 12 1159 13 960 14 688 15 455 16 270 17 178 18 52 We can examine the relative frequencies. knitr::kable( prop.table(table(sum3)), caption = &#39;Relative Frequencies for Tossing Three Dice Simulation&#39;, booktabs = TRUE ) Table 3.3: Relative Frequencies for Tossing Three Dice Simulation sum3 Freq 3 0.0045 4 0.0136 5 0.0277 6 0.0451 7 0.0704 8 0.0971 9 0.1156 10 0.1197 11 0.1301 12 0.1159 13 0.0960 14 0.0688 15 0.0455 16 0.0270 17 0.0178 18 0.0052 Are the relative frequencies for obtaining a sum of 9 and for obtaining a sum of 10 similar to what theory suggests? ggplot(data=sim_three_dice, aes(x=sum3)) + geom_histogram(aes(y=..density..), binwidth = 1) Figure 3.7: Histogram for Tossing Three Dice Although the difference is small, attentive human eyes observed it and persistent inquiring minds found the theory needed to explain it. This is often the way knowledge develops - from careful observation about in the world to an explanatory mathematical model. 3.6 Chapter Scenario Revisited - The Game of Diff In the Game of Diff the player pays a certain fee and then rolls two dice and wins in dollars the difference. We can run an R simulation tossing two dice and computing the difference a large number of times to get a better sense of expected winnings. # Simulate 10000 die tosses and the difference and put in a data frame die1 &lt;- sample(1:6, 10000, replace=TRUE) die2 &lt;- sample(1:6, 10000, replace=TRUE) diff &lt;- abs(die1 - die2) diff_data &lt;- data.frame(die1, die2, diff) head(diff_data) ## die1 die2 diff ## 1 4 6 2 ## 2 3 1 2 ## 3 2 3 1 ## 4 6 1 5 ## 5 2 3 1 ## 6 2 5 3 We tabulate the simulation results with a frequency table and a relative frequency table. table(diff_data$diff) ## ## 0 1 2 3 4 5 ## 1639 2793 2216 1726 1102 524 prop.table(table(diff_data$diff)) ## ## 0 1 2 3 4 5 ## 0.1639 0.2793 0.2216 0.1726 0.1102 0.0524 We can visualize the differences with a histogram. ggplot(diff_data, aes(x=diff)) + geom_histogram(binwidth=1) What was the most common difference? What was the least common difference? Computing summary statistics provides important information. diff_stats &lt;- favstats(diff) diff_stats ## min Q1 median Q3 max mean sd n missing ## 0 1 2 3 5 1.9431 1.420163 10000 0 The mean difference based on the simulation of 10,000 trials is 1.9431. How do these results compare with theory. Now, we find the mean value for the Game of Diff using our traditional, theoretical analysis. With two dice being tossed we want to start with the sample space of the 36 equally likely outcomes. We complete the table by identifying the value of the difference over these outcomes. Figure 3.8: Table for the Difference of Two Dice By counting the number of occurrences of each possible difference we find the probability distribution for X, the difference of two dice. Figure 3.9: Probability Distribution for the Difference of Two Dice Based on the table, we can find and input the probability distribution and compute the mean/expected value using R. x &lt;- c(0, 1, 2, 3, 4, 5) probs &lt;- c(6/36, 10/36, 8/36, 6/36, 4/36, 2/36) expectation_diff &lt;- sum(x*probs) expectation_diff ## [1] 1.944444 The true expected value for the game of diff is 1.9444444. How close was the sample mean generated from simulation to the true mean found by the expected value formula? We know, in the long run, the sample mean will approach the true, theoretical expected value. Accordingly, based on the simulation results and theoretical results above, what you would now recommend for the price of the game including how much money you would predict the casino would make per game and the house advantage as a percentage. Of course, you need to balance two things. First, you want to make sure you set a price that is greater than the expected value to ensure profitibility for the casino. Second, you want to the price to be competitive and still attract gamblers. What price would you recommend? 3.7 Exercises 3.7.1 Exercise - My Die, Your Die Suppose that I toss a die and you toss a die. Find the probability of the following events. (a) Your die is the same result as my die. (b) Your die is different than my die. (c) Your die is greater than my die. 3.7.2 Exercise - Three Dice Three dice are tossed. Answer the following questions. (a) Which is more likely - rolling a sum of 3 or a sum of 18? (b) Which is more likely - rolling a sum of 4 or a sum of 17? (c) Which is more likely - rolling a sum of 10 or a sum of 11? (d) Which is more likely - rolling a sum of 10 or less or rolling a sum of 11 or more? 3.7.3 Exercise - Dice Games Consider the two-person dice games described below. For each game determine which player has an advantage or whether the two options are equally likely. (a) In Game One, two dice are rolled and Asmah wins if the sum is odd and Ismail wins if the sum is even. (b) In Game Two, two dice are rolled and Asmah wins with a sum of 2,3,4,5,10,11,12 and the Ismail wins with a sum of 6,7,8,9. 3.7.4 Exercise - De Morgan’s Laws The negation of “A or B” is “not A and not B”. The negation of “A and B” is “not A or not B”. These logical observatons are called De Morgan’s Laws. For the event of tossing two dice with A being the event of rolling doubles and B being the event of rolling a sum of seven, describe the following events verbally and find their probability. (a) not(A or B) (b) not(A and B) "],["interlude_four_problems.html", "Chapter 4 Interlude - In an Attempt to Kill the Student, the Authors Solve the Same Simple Problem Four Ways (One Bad and Three Good) 4.1 A Problem from the Game of Risk", " Chapter 4 Interlude - In an Attempt to Kill the Student, the Authors Solve the Same Simple Problem Four Ways (One Bad and Three Good) By dissecting an easy problem we can gain insight into multiple problem-solving strategies that can be useful in other problems. Or we can kill motivation altogether. We will see. In this interlude, we see one example worked multiple ways. The specific problem-solving tools will be expounded upon in subsequent chapters. 4.1 A Problem from the Game of Risk In the game of Risk competitors resolve attacks by rolling dice. Suppose that you are rolling two dice and you are interested in whether or not we obtain a six. We consider the following compound events. While there are six sides to each die, because we are primarily interested in whether or not we obtain a six, we will use the tree diagram below where event S represents getting a six and event N represents getting a non-six, ie., 1, 2, 3, 4, or 5. Figure 4.1: Tree Diagram for Sixes on Two Dice Even if we are tossing identical dice simultaneously it is helpful to conceptualize the experiment as if we are tossing the dice sequentially. We have added subscripts to identify whether we are referring to the first die tossed or the second die tossed. What is the probability of obtaining a six on both dice? Because the two events of getting a six on the first die and getting a six on the second die are independent, we can use The Multiplication Rule for Independent Events which says for any two independent events \\(E\\) and \\(F\\), \\(P(E\\ and\\ F) = P(E) \\times P(F)\\). \\[P(two\\ sixes) = P(S_{1}\\ and\\ S_{2}) = P(S_{1}) \\times P(S_{2}) = \\frac{1}{6} \\times \\frac{1}{6}\\] What is the probability of obtaining a six on at least one of the two dice? We examine this problem from four points of view - the wrong point of view, the addition rule, the partition technique, and the complement principle. 4.1.0.1 The Wrong Way Here is a faulty answer: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ or\\ S_{2}) = P(S_{1})+ P(S_{2}) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = \\frac{1}{3}\\ \\ WRONG!\\] Can you spot the problem? The issue is that one branch with a six on both dice, the overlap where both events \\(S_{1}\\) and \\(S_{2}\\) occur, was counted twice. 4.1.0.2 The Addition Rule Here is a correct version using what is called The Addition Rule where the overlap, since it was counted twice, is subtracted: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ or\\ S_{2}) = P(S_{1})+ P(S_{2}) - P(S_{1}\\ AND\\ S_{2}) =\\\\ \\frac{1}{6} + \\frac{1}{6} - \\frac{1}{6} \\times \\frac{1}{6} = \\frac{11}{36}\\] 4.1.0.3 The Partition Approach An alternative approach is to partition the event into mutually exclusive parts. We might informally describe this approach as divide and conquer. In this case, there are three distinct branches that satisfy at least one six occurring: \\[P(at\\ least\\ one\\ six) = P(S_{1}\\ and\\ N_{2}) + P(N_{1}\\ and\\ S_{2}) + P(S_{1}\\ and\\ S_{2}) = \\\\ \\frac{1}{6} \\times \\frac{5}{6} + \\frac{5}{6} \\times \\frac{1}{6} + \\frac{1}{6} \\times \\frac{1}{6} = \\frac{11}{36}\\] 4.1.0.4 The Complement Principle A third correct approach uses The Complement Principle which observes that for any event \\(E\\), \\(P(E) = 1 - P(not\\ E)\\). In this situation, we note \\(P(at\\ least\\ one) = 1 - P(none)\\). Sometimes it is less work to find the complement of an event and subtract from one. \\[P(at\\ least\\ one\\ six) = 1 - P(no\\ sixes) = 1 - P(N_{1}\\ and\\ N_{2}) = \\\\ 1 - \\frac{5}{6} \\times \\frac{5}{6} = \\frac{11}{36}\\] To summarize what we have learned about problem-solving here, there is more than one way to solve a probability problem (and some ways are wrong!). But several good strategies to use are the addition rule being careful not to double-count, divide and conquer by partitioning the event into mutually exclusive pieces, or use the complement principle to solve the opposite problem and subtract this from one. "],["working_with_or_statements.html", "Chapter 5 Working with OR Statements 5.1 Introduction 5.2 Chapter Scenario - Paying Taxes 5.3 Class Composition Example 5.4 Venn Diagrams for Three Events 5.5 Example - Watching Sports 5.6 Revisiting the Chapter Scenario - Paying Taxes 5.7 Exercises", " Chapter 5 Working with OR Statements 5.1 Introduction Most of the interesting probability questions involve combinations of simple events. In this section we examine the probabilities of at least one of two events occurring (or), and describe the key Addition Principle. Venn diagrams are introduced as useful tools for visualizing relationships between overlapping events. 5.2 Chapter Scenario - Paying Taxes On the Diane Rehm show on Wednesday, September 28, 2016 a discussion of federal taxes occurred. Here is the link to the show: https://thedianerehmshow.org/. A claim something like the following was made: 55% of individuals pay federal income tax, 70% pay payroll taxes, and 80% pay at least one of the two. Can you determine the percentage of individuals that pay federal income tax but not payroll taxes and the percentage who pay payroll taxes but not federal income tax? 5.3 Class Composition Example Suppose we took a poll of all 25 students in class and asked them to identify whether or not they were from Utah and whether or not they are planning to major in a business-related field with the following results: 13 are from Utah 8 plan to major in a business-related field 5 are from Utah AND plan to major in a business-related field If one student is chosen at random what is the probability they are from Utah OR plan to major in a business-related field? Let’s let U represent the event of being from Utah and B the event of planning to major in a buisness-related field. 5.3.1 Practice What is wrong with the following approach? \\[P(U \\ or \\ B) = P(U)+P(B)= 13/25 + 8/25 = 21/25 \\ WRONG!!!\\] You may have spotted the mistake that some individuals have been double-counted. The Addition Rule will take care of this. \\[P(U \\ or \\ B) = P(U)+P(B)-P(U \\ and \\ B) = 13/25 + 8/25 - 5/25 = 16/25\\] From the information above we can determine there are 9 individuals that are not from Utah and not planning on majoring in business-related field. Venn Diagrams are a helpful way to visualize the relationships between overlapping events like these. Two overlapping events may be represented in a Venn diagram with two overlapping circles. Think of the rectangle containing them as the entire sample space. Examine the three Venn diagrams below. The first Venn diagram illustrates the compound event each region represents. The second Venn diagram identifies the number of individuals in each region. The third Venn diagram identifies the proportion of the population in each region, or, equivalently, the probability of selecting an individual in the given region if one person was chosen at random. Figure 5.1: Venn Diagram of Class Composition 5.4 Venn Diagrams for Three Events A Venn diagram for three overlapping events is represented with three overlapping circles creating the eight regions all labeled in the diagram below. Figure 5.2: Venn Diagram of Three Events By the Fundamental Principle of Counting, to identify a region there are two choices for each event - out or in - leading to \\(2^{3}=8\\) total regions. The table below describes the event each region represents. Figure 5.3: Venn Diagram Event Description 5.5 Example - Watching Sports A group of students was asked whether or not they like to watch basketball, soccer, and/or football. Here are the results of the survey. Total number surveyed: 78 Number choosing basketball: 26 Number choosing soccer: 30 Number choosing football: 36 Number choosing both basketball and soccer: 10 Number choosing both basketball and football: 12 Number choosing both soccer and football: 18 Number choosing basketball and soccer and football: 8 We can draw a Venn Diagram by identifying with regions B for basketball, S for soccer, F for football, and T representing the total number surveyed. We want to determine how many individuals there are in each of the eight regions. As in the example with two overlapping events, the key problem-solving strategy is to start with the overlap. Here we see some of the overlapping regions described. Can you proceed outward to complete the Venn diagram? Figure 5.4: Partially Completed Venn Diagram for Three Sports 5.6 Revisiting the Chapter Scenario - Paying Taxes Remember in our example, 55% of individuals pay federal income tax, 70% pay payroll taxes, and 80% pay at least one of the two and we wish to determine the percentage of individuals that pay federal income tax but not payroll taxes and the percentage who pay payroll taxes but not federal income tax. A Venn diagram can help with F representing federal income tax and P payroll taxes. From the Addition Principle, \\[P(F \\ or \\ P)=P(F)+P(P)-P(F \\ and \\ P)\\] We know three of these quantities which may be substituted in. \\[0.80=0.55+0.70-P(F \\ and \\ P)\\] Solving we find \\(P(F \\ and \\ P)=0.55 + 0.70 - 0.80=0.45\\) allowing us to complete the Venn diagram. Figure 5.5: Venn Diagram of Paying Taxes 5.7 Exercises 5.7.1 Exercise - We Need More Women Scientists in This World consider a class of 10 people. Is it possible that 60% of them are female and 60% of them are science majors. Draw at least two different venn diagrams showing this possibility. Suppose we are told that 60% are female and 60% are science majors and 80% are at least either female or science majors. Determine how many females are science majors and how many females are not science majors. 5.7.2 Exercise - Venn for Four Create a Venn diagram template for four events {A, B, C, D} and accurately label each region. 5.7.3 Exercise - Class Schedules Suppose that a group of 100 first year students were given a survey indicating that 58 of them are registered for a math class and 40 of them are registered for a foreign language class. Can we safely assume that 98 of them are registered for either a math class or a foreign language class? Suppose we are told that 22 of them are registered for both a math class and a foreign language class, then determine how many are registered for a math class or a foreign language class. 5.7.4 Exercise - Class Survey Design and administer a short three-question class survey where each question is a yes or no answer and draw a Venn diagram of the results identifying the number of individuals in each of the eight regions. Questions could relate to almost anything but try to select questions where you will see different responses. 5.7.5 Exercise - Minding the Gap Suppose the probability of event A is 1/3 and the probability of event B is 1/2. What is the possible range of values for P(A or B), that is, what is the smallest possible value for P(A or B) and what is the largest possible value for P(A or B)? "],["working_with_and_and_not_statements.html", "Chapter 6 Working with AND and NOT Statements 6.1 Introduction 6.2 Chapter Scenario - The Birthday Problem 6.3 The Chevalier de Mere 6.4 Analysing Game One 6.5 Analyzing Game Two 6.6 Revisiting the Chapter Scenario - The Birthday Problem 6.7 Exercises", " Chapter 6 Working with AND and NOT Statements 6.1 Introduction Most of the interesting probability questions involve combinations of simple events. In this section we examine the probabilities of two events both occurring (and) as well as an event not occurring (not). In this chapter,we describe the key probability principles related to and, and not statements, namely, the Multiplication Principle and Complement Principle, respectively. 6.2 Chapter Scenario - The Birthday Problem You may be sitting in a classroom right now. If not, imagine you are. Suppose there are a total of 20 people in class. What is the chance that two of you have the same birthday (meaning same day of the year but not necessarily the same year)? Which is it closer to - a 10%, 20%, 30%, 40%, or 50% chance, or possibly even higher chance? 6.3 The Chevalier de Mere Aaah, the “Horseman of the Sea,” that famous gambler who had a horse and lived by the sea. And who was, by the way, an acquaintance of Pascal, owner of famous triangle in the year 1654. There were two games of chance that the Chevalier wanted some advice on and he wrote Pascal and letter and, viola, the theory of probability was born. OK, it wasn’t that simple but the Chevalier’s question did stimulate a deeper understanding of probability intimating at what we now call the multiplication rule and the complement rule. Here are the two games under consideration - Game One: You could bet on the chance of getting at least one six on four rolls of a die. Game Two: For a longer game, you could bet on the chance of getting at least one double six on 24 rolls of two dice. 6.3.1 Practice Estimate the probability of winning Game One and the probability of winning Game Two. No formal computation necessary at this point. Each of these games was an even-money game meaning the payoff ratio was 1:1 where you would either win or lose the exact amount bet. The Chevalier de Mere had a lot of experience and felt that the first game offered a better chance of winning than the second game but he could find no theoretical explanation as to why. In his mind, with the prevailing math at the time, the two games seemed comparable. If I am given 4 tries to get something that happens on average every 6 times then being given 24 tries at something that happens on average every 36 times should be comparable. But in reality it was not. In short, his mathematical reasoning was letting him down. We can use simulation to recreate the Chevalier’s experience. The code below simulates 10,000 trials of Game One and documents the number of wins and losses. die_tosses &lt;- matrix(sample(1:6, 4*10000, replace=TRUE), ncol=4) #generate die tosses sixes_logic &lt;- die_tosses==6 #identify where there are sixes (TRUE=1, FALSE=0) number_of_sixes &lt;- apply(sixes_logic, 1, sum) #Tabulate the number of sixes in each game game_one_winners &lt;- number_of_sixes &gt; 0 #Identify the winners - those with at least one six #Calculate the proportion of game one winners knitr::kable( prop.table(table(game_one_winners)), caption = &#39;Game One Simulation&#39;, booktabs = TRUE ) Table 6.1: Game One Simulation game_one_winners Freq FALSE 0.4871 TRUE 0.5129 The simulated Chevalier in this simulation would notice winning \\(51.39\\%\\) of the time. Let’s simulate 10,000 trials of Game Two for comparison sake. two_Die_tosses &lt;- matrix(sample(1:6, 24*10000, replace=TRUE) + sample(1:6, 24*10000, replace=TRUE), ncol=24) #generate 10000 trials of 24 two dice rolls double_sixes_logic &lt;- two_Die_tosses==12 #identify double sixes (TRUE=1, FALSE=0) #head(double_sixes_logic, n=10) number_of_double_sixes &lt;- apply(double_sixes_logic, 1, sum) #tabulate number of double sixes in each game game_two_winners &lt;- number_of_double_sixes &gt; 0 #identify winners - those with at least one double six #Calculate the proportion of game two winners knitr::kable( prop.table(table(game_two_winners)), caption = &#39;Game Two Simulation&#39;, booktabs = TRUE ) Table 6.2: Game Two Simulation game_two_winners Freq FALSE 0.5106 TRUE 0.4894 This time, our simulated Chevalier sees he is winning only \\(49.04\\%\\) of the time. Hence the rub. Why is Game One better than Game Two? Enter Pascal, stage right. Here we let you do a little play-acting and audition for the role of Pascal by analyzing the games and determining the chances of winning each. To do this, let’s explore what we now call the multiplication rule and the complement rule. The Multiplication Rule shows us that to obtain the probability of two potentially consecutive events we multiply related probabilities: 6.3.2 Theorem: The Multiplication Rule \\[For \\ all \\ events \\ A \\ and \\ B, \\ P(A \\ and \\ B)= P(A) \\cdot P(B \\mid A).\\] To understand the Multiplication Rule, examine the tree diagram below where branches are labeled with the events and the corresponding probabilities. We see that traveling the A and B branch happens with probability \\(P(A) \\cdot P(B \\mid A)\\). In the special case that events A and B are independent we note that \\(P(B \\mid A) = P(B)\\) resulting in the simplified tree diagram below. This leads to a special case of the multiplication principle. 6.3.3 Theorem: Special Case of the Multiplication Rule \\[If \\ the \\ events \\ A \\ and \\ B \\ are \\ independent \\ then \\ P(A \\ and \\ B) = P(A) \\cdot P(B).\\] The Complement Rule confirms that the probability of an event occurring is one minus the probability the event does not occur: 6.3.4 Theorem: Complement Rule \\[For \\ all \\ events \\ A, \\ P(A)= 1-P(not \\ A)\\] Remember this can also be written as \\(P(A) + P(not \\ A) = 1\\). Tackling the Chevalier’s problem one die at a time, consider the experiment of tossing just one die. Suppose we are interested in the event S of getting a six. \\[P(getting \\ a \\ six) = P(S) = 1/6\\] This is equivalent to the following version using the complement principle: \\[P(getting \\ a \\ six) = 1 – P(not \\ getting \\ a \\ six) = 1 - P(not \\ S) = 1 – 5/6 = 1/6\\] Now consider the experiment of tossing two dice. Let \\(S_{1}\\) represent getting a six on the first die and \\(S_{2}\\) getting a six on the second die. Note that whatever happens on the first die is independent of what happens on the second die. To find the probability of getting double sixes we can utilize the multiplication rule. \\[P(two \\ sixes)= P(S_{1} \\ and \\ S_{2})=P(S_{1}) \\cdot (S_{2})= 1/6 \\cdot 1/6=1/36\\] There is a note of caution here; remember this technique only works with independent events like dice rolls and would not work for dependent event like drawing from an urn without replacement. Similarly, we could now use independence and the Multiplication Rule to help us understand the event of not getting a six. \\[P(no \\ sixes)= P(S_{1}^{c} \\ and \\ S_{2}^{c}) = P(S_{1}^{c}) \\cdot P(S_{2}^{c}) =5/6 \\cdot 5/6=25/36\\] We often use the complement rule when finding the probability of at least one occurrence of an event in multiple trials. To say “at least one success” and to say “no successes” are complements of each other. We can take advantage of this because it is often easy to find the probability of “no successes” directly. To illustrate, we can use the complement rule as one way of finding the probability at least one of the two dice is a six. \\[P(at \\ least \\ one \\ six)= 1-P(no \\ sixes)= 1-5/6 \\cdot 5/6=1-25/36=11/36\\] Let’s put these pieces together – the Multiplication Rule and the Complement Rule – to solve the Chevalier de Mere’s dilemma first analyzing Game One then Game Two then making comparisons. 6.4 Analysing Game One The gambler bets on the chance of getting at least one six on four rolls of a die and if a six occurs wins the amount bet and if it does not occur then loses the amount bet. Consider drawing a tree diagram for four tosses of the die including the probabilities along each branch. For each toss of the die we need only identify two branches – NOT SIX (1,2,3,4 or 5) or SIX (6). You can stop the branch whenever a six occurs since the gambler wins in this instance. Figure 6.1: Tree Diagram for Game One The tree diagram for four tosses of a die considering the two outcomes of success or failure of getting a six on each toss generates sixteen branches through the tree but only five branches if we terminate the tree whenever we get a success. These branches are not equally likely, though, so we need to be careful about calculating probabilities. When finding the probability of at least one success in an experiment like this we often utilize the Complement Rule because while there are many branches that end in a success there is only one branch of all failures so this one would be easier to calculate the probability of than adding together the other branches. Examine the tree diagram above and identify the one branch in the sample space in which the gambler loses by shading it and find the probability of this occurrence. \\[P(no \\ sixes \\ in \\ four \\ tosses)=P(S_{1}^{c} \\ and \\ S_{2}^{c} \\ and \\ S_{3}^{c} \\ and \\ S_{4}^{c}) = \\\\ P(S_{1}^{c}) \\cdot P(S_{2}^{c}) \\cdot P(S_{3}^{c}) \\cdot P(S_{4}^{c})=(5/6)^{4}\\] Thus, by the Complement Principle, \\[P(at \\ least \\ one \\ six \\ in \\ four \\ tosses) = 1 - P(no \\ sixes \\ in \\ four \\ tosses) = \\\\ 1 - (5/6)^{4}\\] 6.4.1 Practice Are the probabilities you have found for losing or winning Game One consistent with the Chevalier de Mere’s observation that he found Game One to be a favorable game? Explain. 6.5 Analyzing Game Two Recall, in this game the gambler rolls a pair of dice and has 24 chances to obtain double-six winning the amount bet if she does and losing the bet if she does not obtain a double-six in 24 rolls. The Chevalier did not like this game as much. We analyze the game here to see if his lack of enthusiasm is justified. Consider what a tree diagram would look like for this game. If we let event \\(D_{i}\\) represent getting a double six on the \\(i^{th}\\) roll of the dice and \\(N_{i}\\) represent its complement we can stop the branching as a win whenever we hit a double six. Figure 6.2: Tree Diagram for Game Two Would it be realistic to use this tree diagram to assist us find the probability of a win? The main issue is there are so many ways to win - on the first toss, the second toss,…, the 24th toss. Who wants to add up 24 separate probabilities? Maybe the complement principle can help us since there is only one way to lose - never get a double six in all 24 tosses. Follow the chain of reasoning: \\[P(win) = 1 - P(lose) = 1 -P(no \\ sixes \\ in \\ 24 \\ rolls) = 1 - P(N_{1} \\ and \\ N_{2} \\ and \\ ... \\ N_{24}) = \\\\ 1 - P(N_{1}) \\cdot P(N_{2}) \\cdot ... \\cdot P(N_{24}) = 1 - (35/36)^{24}\\] We are using the fact that the different tosses of the dice are all independent. 6.5.1 Practice Compare the probabilities of winning and losing Game One with the probabilities of winning and losing Game Two and whether the opinions of the Chevalier de Mere’s games obtained through the simulation in R are consistent with the theoretical conclusions of our probability analysis. 6.6 Revisiting the Chapter Scenario - The Birthday Problem Given 365 days of the year (We ignore Leap Day February 29 with apologies to the Pirate of Penzance) and only 20 people it may initially feel like there is not much chance of a match but we are being deceived. With our problem-solving tools of the Multiplication and Complement Principles, we can find out for sure. Recall The Multiplication Rule shows us that to obtain the probability of two potentially consecutive events we multiply related probabilities: \\[P(A \\ and \\ B)= P(A) \\cdot P(B \\ \\mid \\ A)\\] If the events A and B are independent then \\(P(A \\ and \\ B)=P(A) \\cdot P(B)\\). The Complement Rule confirms that the probability of an event occurring is one minus the probability the event does not occur: \\[P(A)= 1-P(not \\ A)\\] Remember, this can also be written \\(P(A)=1-P(not \\ A)\\). We will build up our way into solving this problem by imagining that individuals walk into the room one at a time and announce their birthday to see if it matches or not with anyone else who is in the room. When the first person walks in the room, there is no one else there so their birthday can be any one of the 365 days without there being a match so the probability of no match is \\(365/365=1\\). Suppose only this one person is in the room. The probability that the second person to enter the room has the different birthday is \\(364/365\\). Suppose that two people are in the room and do not have the same birthday. The probability that the third person to enter the room has a different birthday than these two is \\(363/365\\). Now, suppose three people are in the room and do not have a birthday match. Then the probabillity that the fourth person to enter the room has a different birthday than these three is \\(362/365\\). For all of these events to occur we can use the multiplication principle. With four people the probability of no match is \\((365/365) \\cdot (364/365) \\cdot (363/365) \\cdot (362/365)\\) Using the complement principle for this case with four people \\[P(match)=1-P(no \\ match)=1-(365/365) \\cdot (364/365) \\cdot (363/365) \\cdot (362/365)\\] 6.6.1 Practice Extend this thinking to find the probability of no match with five people. We want to describe the solution in general for any number of people n according to the tree diagram below. Figure 6.3: Tree Diagram for Birthday Problem A computational shortcut will help us calculate the result. Given n people, the probability of a birthday match is \\[P(match)=1-P(no \\ match)=1-\\frac{365 \\cdot 364 \\cdot 363 \\cdot ... \\cdot (365-n+1)}{3655^{n}}= \\\\ 1-\\frac{P(365,n)}{365^{n}}\\] where \\(P(365,n)\\) represents the permutation of 365 days taken n at a time. We will discuss this in more detail in a later chapter. To solve the Chapter Scenario problem, we let \\(n=20\\) and see \\[P(match)=1-P(no \\ match)=1-\\frac{P(365,20)}{365^{20}}\\] We can use the prod() function in R for the computation. match_prob_20 &lt;- 1- prod(1 - (0:19)/365) match_prob_20 ## [1] 0.4114384 So the probability of a birthday match with 20 people is 0.4114384 which might surprise us. 6.7 Exercises 6.7.1 Exercise - Birthday Problem continued Continue in like fashion finding the probability of a birthday match with 21, 22, 23, etc. people until you find the first value of n for which this probability is greater than 0.5. 6.7.2 Exercise - Slips of Paper Ten slips of paper numbered 1 to 10 and identical is all other respects are placed in a hat. The slips are drawn out one at a time with replacement. What is the minimum number of draws that must be made for the probability of a match to be at least 0.5? What is the minimum number of draws that must be made for the probability of a match to be at least 0.9? 6.7.3 Exercise - Five Coins Suppose that a fair coin is flipped five times. What is the probability there is at least one head? 6.7.4 Exercise - Random Phone Number Suppose a local seven-digit phone number is chosen at random. What is the probability it will not contain a 9? 6.7.5 Exercise - Knights of the Round Table The famed Winchester Round Table of King Arthur shows places for 25 knights. Being a dangerous business, suppose that the probability of dying in a given year is 0.04. What is the probability that at least one of the 25 knights seated around the table will die within one year? "],["conditional_probability_and_bayes_theorem.html", "Chapter 7 Conditional Probability and Bayes’ Theorem 7.1 Introduction 7.2 Chapter Scenario - Drug Testing 7.3 Conditional Probability Basics 7.4 Example - Kittens 7.5 Conditional Probability and Urn Models 7.6 Bayes’ Rule 7.7 Example - Defective Fidget Spinners 7.8 Chapter Scenario Revisited - Drug Testing 7.9 Hypothetical 10,000 Table 7.10 Exercises", " Chapter 7 Conditional Probability and Bayes’ Theorem 7.1 Introduction Many probability questions provide relevant information about the context or prior events. Conditional probability provides tools to take this partial information into account. One of the most powerful theorem of conditional probability is Bayes’ Theorem which shows us how we should modify the probability of an event occurring in light of relevant new information. 7.2 Chapter Scenario - Drug Testing Imagine a proposal to test every United States university student for illicit drug use. Suppose the test has a sensitivity of 90% meaning that if a person is an illicit drug user the probability of a positive test result is 0.90. (A positive result indicates the individual does use drugs). Suppose the test has a specificity of 95% meaning that if a person is not an illicit drug user the probability of a negative result is 0.95. (A negative result indicates the individual does not use drugs.) Further, suppose the percentage of illicit drug users on Westminster’s campus is 22%. (Note, this is just a hypothetical possibility but the National Survey on Drug Use and Health indicates that in 2012, the rate of current use of illicit drugs was 22.0 percent among full-time college students aged 18 to 22. http://www.samhsa.gov/data/NSDUH/2012SummNatFindDetTables/NationalFindings/NSDUHresults2012.htm) Suppose that a student chosen at random tests positive for illicit drug use. Based on the information provided above, would you estimate the probability this student actually is an illicit drug user at closer to 0%, 20%, 40%, 60%, 80%, or 100%? Explain. 7.3 Conditional Probability Basics To review the basics of conditional probability recall that the event \\(A \\mid B\\) represents the event A occurring given that event B occurs. Thus, \\(P(A \\mid B)\\) could be interpreted as the proportion of the time A occurs under the circumstances that B has occurred. As a formal definition we have the following Conditional Probability Formula: \\[P(A \\mid B) = \\frac{P(A \\ and \\ B)}{P(B)}\\] To see this formula in action we can take another look at an earlier situation - the experiment of tossing one die with the following events: E: getting an even outcome S: getting a six L: getting a number less than three Earlier, we determined \\(P(L \\mid E)=1/3\\) directly by noting that of the three cases of even numbers, {2,4,6}, only one of them, 2, is less than three so the probability is 1/3. Watch how the conditional probability formula gets this right: \\[P(L \\mid E) = \\frac{P(L \\ and \\ E)}{P(E)} = \\frac{1/6}{3/6}=\\frac{1}{3}\\] 7.3.1 Practice For the events described above, use the conditional probability formula to confirm \\(P(E \\mid L)=1/2\\) and \\(P(S \\mid E)=1/3\\). 7.4 Example - Kittens Suppose a friend of yours has two kittens and indicates that at least one of them is a male. What, then, is the probability that both are male? Using the Conditional Probability Formula we reason as follows: \\[P(\\text{both male} \\mid \\text{at least one male}) = \\frac{P(\\text{both male and at least one male})}{P(\\text{at least one male})} = \\\\ \\frac{P(\\text{both male})}{P(\\text{at least one male})}= \\frac{1/4}{3/4}=\\frac{1}{3}\\] A common error is to think that since one is male then the other has a 50/50 chance of being male so the probability is 1/2 but we see this overestimates the case as the probability is really 1/3. Conditional probability can be subtle. Watch how a slight change of information can change the analysis. Suppose your friend with two kittens indicates that the youngest one is a male. Now, what is the probability that both kittens are male? \\[P(\\text{both male} \\mid \\text{first one is male}) = \\frac{P(\\text{both male and first one is male})}{P(\\text{first one is male})} = \\\\ \\frac{P(\\text{both male})}{P(\\text{first one is male})}= \\frac{1/4}{2/4}=\\frac{1}{2}\\] 7.5 Conditional Probability and Urn Models As described earlier, one valuable model for thinking about probability questions is an urn model. When drawing from an urn without replacement we recognize that probabilities change depending on which balls were previously drawn and it is the tool of conditional probability that is required to determine this. Consider an urn containing 8 blue balls and 5 red balls. If two balls are drawn without replacement we can find the probabilities of the different possibilities. Figure 7.1: Urn Model A tree diagram illustrates the possibilities where B represents drawing a blue ball and R represents drawing a red ball and a subscript of 1 or 2 identifies whether we are referring to the first or second ball, respectively. The probabilities on the branches for the second ball choice are all conditional probabilities. Figure 7.2: Decision Table Multiplying down the branches works great. Watch how this translates into conditional probabilities. \\[P(\\text{two blue})=P(B_{1} \\ and \\ B_{2})=P(B_{1}) \\cdot P(B_{2} \\mid B_{1}) = \\frac{8}{13} \\cdot \\frac{7}{12}= 56/132\\] 7.5.1 Practice Drawing two balls without replacement from the urn described above, what is the probability of obtaining two red balls? Use appropriate conditional probability notation to explain your work. 7.6 Bayes’ Rule Suppose we have an event A and we know its probability, P(A). If we know that event B occurred this may change the probability of A as we have seen in some of the examples above. Bayes’ Theorem helps us determine how knowledge of event B occurring changes the probabilty of event A. From the Conditional Probability Formula we have \\[P(A \\mid B) = \\frac{P(A \\ and \\ B)}{P(B)}\\] Using the Multiplication Rule we can replace \\(P(A \\ and \\ B)\\) by \\(P(A) \\cdot P(B \\mid A)\\) to get Bayes’ Rule. \\[P(A \\mid B) = \\frac{P(A \\ and \\ B)}{P(B)}=\\frac{P(A) \\cdot P(B \\mid A)}{P(B)}\\] Bayes’ Rule can also be written \\[P(A \\mid B) = \\frac{P(B \\mid A)}{P(B)} \\cdot P(A)\\] We call \\(P(B \\mid A)/P(B)\\) the support since when it is greater than 1 the probability of A increases and when it is less than 1 the probability of A decreases. It is often necessary in computing \\(P(B)\\) to partition event B. If mutually exclusive events \\(A_{1},A_{2},...,A_{n}\\) are a partition of the sample space then note \\[P(B)=P(B \\ and \\ A_{1} \\ or \\ B \\ and \\ A_{2} \\ or \\ ... \\ or \\ B \\ and \\ A_{n})\\] Let’s look at an example of how Bayes’ Rule can be used. 7.7 Example - Defective Fidget Spinners Remember fidget spinners? Suppose your retail store has received two shipments of fidget spinners. The two shipments look identical but you are told that in one of the shipments 10% of the fidget spinners are defective while in the other 25% are defective. For convenience let’s call the 10% defective shipment Shipment A and the 25% defective shipment Shipment B. If you check one of the fidget spinners from one of the shipments at random and you discover that it is defective, what is the probability that it is Shipment A and what is the probability it is Shipment B? Consider the following events: D: the fidget spinner selected is defective A: 10% defective Shipment A B: 25% defective Shipment B What we want to find is \\(P(A \\mid D)\\) as well as \\(P(B \\mid D)\\). Let’s tackle one of them. \\[P(A \\mid D) = \\frac{P(A \\ and \\ D)}{P(D)}=\\frac{P(A) \\cdot P(D \\mid A)}{P(D)}\\] Let’s breakdown the denominator. The defective fidget spinner came either from shipment A or shipment B so we can partition event D into either D and A or D and B and work with it as follows. \\[P(D) = P(D \\ and \\ A \\ or \\ D \\ and \\ B) = P(D \\ and \\ A) + P(D \\ and \\ B) = \\\\ P(A) \\cdot P(D \\mid A) + P(B) \\cdot P(D \\mid B)= \\\\ (0.5) \\cdot (0.10) + (0.5) \\cdot (0.25) = 0.175\\] We can put these pieces together. \\[P(A \\mid D) = \\frac{P(A) \\cdot P(D \\mid A)}{P(D)} = \\frac{(0.5) \\cdot (0.10)}{0.175}=\\frac{0.05}{0.175}=0.286\\] Without any information we would think there is a 50/50 chance of either shipment being Shipment A but after gathering this seemingly small amount of evidence we see the probability it is Shipment A has been reduced to 0.286. 7.8 Chapter Scenario Revisited - Drug Testing Recall the proposal to test every United States university student for illicit drug use with a test that has a sensitivity of 90% and a specificity of 95%. Thus, an illicit drug user will test positive 90% of the time and a non-illicit drug user will test negative 95% of the time. Further, suppose the percentage of illicit drug users on Westminster’s campus is 22%. Suppose a Westminster student chosen at random tests positive for illicit drug use. What is probability this student actually is an illicit drug user? Figure 7.3: Decision Table We can define the following events. D: the individual is an illicit drug user \\(D^{c}\\): the individual is not an illicit drug user +: the test is positive -: the test is negative Based on the provided information we know the following: \\(P(+ \\mid D)=0.90\\) \\(P(- \\mid D)=0.10\\) \\(P(+ \\mid D^{c})=0.05\\) \\(P(- \\mid D^{c})=0.95\\) \\(P(D)=0.22\\) \\(P(D^{c})=0.78\\) A tree diagram visualizes the relationships between these probabilities. Figure 7.4: Drug Testing Tree Diagram There are a lot of meaningful events to consider. \\[P(positive)=P(+)=P(+ \\ and\\ D \\ or + and \\ D^{c})=P(+ \\ and \\ D) + P(+ \\ and \\ D^{c}) = \\\\ P(D) \\cdot P(+ \\mid D) + P(D^{c}) \\cdot P(+ \\mid D^{c}) = (0.22) \\cdot (0.90) + (0.78) \\cdot (0.05) = 0.237\\] One of the most interesting probabilities is the probability that a person who tested positive actually does illicit drugs. \\[P(D \\mid +) = \\frac{P(D \\ and \\ +)}{P(+)} = \\frac{0.22 \\cdot 0.90}{0.22 \\cdot 0.90 + 0.78 \\cdot 0.05} = \\frac{0.198}{0.237}=0.835\\] That means the probability someone who tests positive does not do illicit drugs is \\(1 - 0.835=0.165\\). 7.9 Hypothetical 10,000 Table One additional way to better understand the probabilities is to imagine a hypothetical 10,000 people from the population who are tested and the results line up perfectly with the indicated probabilities. (Note, each actual sample of 10,000 would vary and results would most likely not line up perfectly with the probabilities.) We can complete the “Hypothetical 10,000” table below using your understanding of probability and percentages and the following instructions: First, complete the marginal column totals according to the overall illicit drug use percentages. (Blue) Second, complete each interior cell by finding the designated percentage in each category. (Yellow) Third, complete the row totals by adding the interior table values. (Green) Note: The Blue boxes should sum to 10,000. The Yellow boxes should also sum to 10,000. And the Green boxes should sum to 10,000. Figure 7.5: Hypothetical 10,000 Table 7.10 Exercises 7.10.1 Exercise - Three Kids An old high school friend tells you she has three children and that they are not all boys. What is the probability they are all girls? 7.10.2 Exercise - Condemned Man A bag contains 5 white and 8 black balls. A man is condemned to draw a ball and be executed if it is a black one. The man requests that he be allowed to arrange the balls in two bags according to his own preference and then, blindfolded, select one of the two bags and select one of the balls from this bag at random. What is, from the prisoner’s point of view, the most favorable division of balls? Explain your answer. (Source: Hans Freudenthal. Probability and Statistics) 7.10.3 Exercise - Liberal and Conservative Urns Suppose there are two urns, one liberal urn containing 70% blue beads and 30% red beads and the other conservative urn containing 20% blue beads and 80% red beads. Suppose one urn is chosen at random and one bead chosen at random from that urn. (a) If the bead is blue what is the probability you have chosen the liberal urn? (b) If the bead is red what is the probability you have chosen the liberal urn? "],["expectation.html", "Chapter 8 Mathematical Expectation 8.1 Introduction 8.2 Chapter Scenario - Deal or No Deal 8.3 Introducing Mathematical Expectation 8.4 Example - Win Six 8.5 Example - Chuck-a-Luck 8.6 Chapter Scenario Revisited - Deal or No Deal 8.7 Deal or No Deal Extended 8.8 Exercises", " Chapter 8 Mathematical Expectation 8.1 Introduction We construct probability distributions and compute and interpret the mathematical expectation or expected value. 8.2 Chapter Scenario - Deal or No Deal Have you ever seen the show Deal or No Deal? If so, I feel sorry for you! We can get a sense of Deal or No Deal by searching for an online version one of which can be found at http://www.gamesolo.com/flash-game/deal-or-no-deal.html . Figure 8.1: Howie Mandel and Deal or No Deal A player chooses one of 26 suitcases each containing a different amount of money from \\(\\$0.01\\) to \\(\\$1,000,000\\). The values below show the dollar amounts of the 26 suitcases. Figure 8.2: Deal or No Deal Suitcases Taking everything into account - your current financial situation, your philosophy of life, your personality, everything – what is the maximum amount you personally would be willing to pay for one chance to play Deal or No Deal and keep the amount in the suitcase you selected? What probability tools might help you make an informed decision? 8.3 Introducing Mathematical Expectation 8.4 Example - Win Six What if you get one roll of a fair die and if a six comes up you win \\(\\$100\\). What is the true value of this proposition, that is, what would be a fair price for this risk/reward opportunity? Equivalently, we can ask how much we would win on average. We call this theoretical average the mathematical expectation or expected value. Since the probability of rolling a six is \\(\\frac{1}{6}\\), we would win \\(\\$100\\) about once every six tries so on average we would win \\(\\frac{1}{6}\\) of \\(\\$100\\) so the expected value is \\(100 \\times\\frac{1}{6}=\\$16.67\\). Suppose we also would win \\(\\$10\\) if we roll a four or a five. This would sweeten the pot. And if the pot is sweetened that means the expected value increases. But, by how much? For this portion of the bet, we would win \\(\\$10\\) \\(\\frac{1}{3}\\) of the time for an additional \\(10 \\times\\frac{1}{3}=\\$3.33\\) on average. We can put these two together to get the total expected value: \\[100 \\times \\frac{1}{6} + 10 \\times \\frac{1}{3} = \\$16.67 + \\$3.33 = \\$20\\] Let’s start with a slightly simpler game we’ll call Win Six. Suppose you bet \\(\\$1\\) then you roll a die. If a 1, 2, or 3 comes up you lose \\(\\$1\\). If a 4 or 5 comes up you win \\(\\$1\\). If a 6 comes up you win \\(\\$6\\). Hey, let’s call it Win Six! Our goal was to analyze a risk/reward scenario and determine the expected value or the mathematical expectation. This is the theoretical mean which is the weighted average of the outcomes weighted by their probabilities. We can facilitate this calculation by describing the probability distribution, or the complete description of the different outcomes X and their associated probabilities, P(X). Outcome X P(X) Roll 6 +100 \\(\\frac{1}{6}\\) Roll 4 or 5 +10 \\(\\frac{1}{3}\\) Roll 1, 2, or 3 0 \\(\\frac{1}{2}\\) We get the mean/expected value by summing up the X times P(X) quantities. In formula form we say \\[E[X] = \\sum_{x} x \\cdot P(x)\\] We can determine this manually by adding the following column to the probability distribution and summing it. Outcome X P(X) X*P(X) Roll 6 +100 \\(\\frac{1}{6}\\) 16.67 Roll 4 or 5 +10 \\(\\frac{1}{3}\\) 3.33 Roll 1, 2, or 3 0 \\(\\frac{1}{2}\\) 0 The expected value for the game Win Six is the sum which equals \\(\\$20\\). 8.5 Example - Chuck-a-Luck Chuck-A-Luck is a popular carnival game since it is easy to understand, easy to set-up, and easy to hide when the county-mounty shows up with a simple layout for betting as shown below. One bets on a number, one through six. Three dice are rolled and you win the amount bet for each time that number shows. For example, if you bet \\(\\$1\\) on the number 5, if that number comes up once on the three dice you win \\(\\$1\\), if it comes up twice you win \\(\\$2\\), if it comes up three times you win \\(\\$3\\) but if it doesn’t come up at all you lose \\(\\$1\\) (or we say your result is \\(\\$1\\)). Is this game favorable to the players or to the house? In the long run, how much money per game would you expect to win or lose? Figure 8.3: Chuck-a-Luck Layout We can use the idea of mathematical expectation to analyze Chuck-a-Luck. Let’s assume we bet on the number 5. We can do this without loss of generality because the analysis would be the same if we bet on other numbers. Using F to represent getting a 5 and N to represent not getting a five and using subscripts to denote the first, second, and third die yields the tree diagram below. Figure 8.4: Chuck-a-Luck Tree Diagram Thus, \\(P(0 \\ fives) = (5/6)^{3}\\). There are three different branches where the result is exactly one five thus, \\(P(1 \\ five) = 3 \\cdot (1/6) \\cdot (5/6)^{2}\\). Similarly, three brances for exactly two fives so \\(P(2 \\ fives) = 3 \\cdot (1/6)^{2} \\cdot (5/6)\\). Lastly, for three fives, $P(3  fives) = (1/6)^{3}. If we let X represent the winnings in these circumstances we can write the probability distribution for X: Outcome X P(X) X*P(X) Number occurs 0 times -1 \\(\\frac{125}{216}\\) \\(-1 \\cdot \\frac{125}{216}\\) Number occurs 1 time +1 \\(\\frac{75}{216}\\) \\(+1 \\cdot \\frac{75}{216}\\) Number occurs 2 times +2 \\(\\frac{15}{216}\\) \\(+2 \\cdot \\frac{15}{216}\\) Number occurs 3 times +3 \\(\\frac{1}{216}\\) \\(+3 \\cdot \\frac{1}{216}\\) Calculating the mean/expected value by finding the sum shows \\[E[X]=\\sum_{x} x \\cdot P(x)= \\\\(-1) \\cdot (125/216)+1 \\cdot (75/216) +2 \\cdot (15/216)+3 \\cdot (1/216)=-17/216=-0.0787 \\] This means we would lose on average close to 8 cents per dollar bet giving the carnival a \\(7.87\\%\\) house advantage. 8.6 Chapter Scenario Revisited - Deal or No Deal Recall that in Deal or No Deal a player chooses one of 26 suitcases each containing a different amount of money from \\(\\$0.01\\) to \\(\\$1,000,000\\). You were asked to determine the maximum amount you would be willing to pay for the privilege of selecting one suitcase and keeping the amount in this suitcase. Individual responses range widely. Some students would pay nothing or maybe \\(\\$25\\) while other students will pay as much as \\(\\$500\\). We can apply probability tools like simulation and mathematical expectation developed above to inform our decision. First, let’s visualize the distribution of suitcase amounts. 8.6.1 Practice If a number of games of Deal or No Deal were played and the results recorded, what would you expect for shape, center, and spread of the data set? What might you expect for the average? To help you think about shape, note that the axes for a histogram would look something like the image below: Figure 8.5: Deal or No Deal Histogram Template 8.6.2 Simulating Deal or No Deal We can simulate a large number of trials of the game Deal or No Deal with the code below, first creating a vector with the suitcase amounts and then sampling from this vector. We’ll simulate playing the game 10,000 times. suitcases &lt;- c(0.01, 1, 5, 10, 25, 50, 75, 100, 200, 300, 400, 500, 750, 1000, 5000, 10000, 25000, 50000, 75000, 100000, 200000, 300000, 400000, 500000, 750000, 1000000) amount &lt;- sample(x=suitcases, size=10000, replace=TRUE) deal_sim &lt;- data.frame(amount) head(deal_sim) ## amount ## 1 5000 ## 2 400000 ## 3 5 ## 4 500 ## 5 750 ## 6 50000 We can visualize the results and see if our preconception regarding the distribution was accurate or not. ggplot(deal_sim, aes(amount))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 8.6: Deal or No Deal Simulation Results And we can run the numbers. deal_sim_stats &lt;- favstats(deal_sim$amount) deal_sim_stats ## min Q1 median Q3 max mean sd n missing ## 0.01 75 875 1e+05 1e+06 128493 248370.1 10000 0 How similar or different are the simulation results for shape, center, and spread compared to your predictions above? 8.6.3 Practice Discuss the two main measures of center – mean and median – for this data set. The mean is the arithmetical average while the median is the middle number of the data set when put in rank order. Were they close to one another or quite different? Explain. While simulation is an effective tool to explore Deal or No Deal outcomes we can also analyze the probability distribution and find the expected mean value, the median, and the standard deviation. Below is the R code creating the outcome variable suitcase and the probability variable probs to begin this analysis. Note the probability of any given suitcase being selected is \\(1/26\\). The suitcases variable code is duplicated from above for clarity. suitcases &lt;- c(0.01, 1, 5, 10, 25, 50, 75, 100, 200, 300, 400, 500, 750, 1000, 5000, 10000, 25000, 50000, 75000, 100000, 200000, 300000, 400000, 500000, 750000, 1000000) probs &lt;- rep(1/26, 26) The expectation is the sum of the suitcase amounts multiplied by their probabilities. This is easy to do by simply multiplying the suitcase vector by the probs vector. deal_expectation &lt;- sum(suitcases*probs) deal_expectation ## [1] 131477.5 It is suprising to many that the expectation is \\(\\$131,477.50\\). This is the amount the show would need to budget for for each game played. The median is quite different. With 26 different suitcase amounts, the median would be halfway between the 13th and the 14th ordered suitcase amounts. That means the theoretical median is \\((750 + 1000)/2=875\\). The median from our simulation is 875 with the median usually being either 750 or 1000 and only rarely being exactly 875. Two other important measures are the variance and the standard deviation which both help describe the variablility of the outcomes which will be discussed in the next chapter. 8.6.4 Reflection To reflect on what we’ve just experienced think back on the personal maximum you were willing to invest to play one round of Deal or No Deal. Thinking about the opportunity to play one round of Deal or No Deal as an investment opportunity, describe how this information from the simulated sample and the theoretical analysis impacts your thinking about your own personal maximum. Would you now consider paying the same, more, or less than you earlier indicated? In what way were the probability tools including simulation and expected value helpful tools in analyzing Deal or No Deal? 8.7 Deal or No Deal Extended In the actual Deal or No Deal game, you open a few suitcases at a time to see what you missed out on and after each round the banker offers you a fixed amount. You can take this money and run or you can keep playing – it is up to you. We just played the first round of the Deal or No Deal flashgame (http://www.gamesolo.com/flash-game/deal-or-no-deal.html) and opened six of the suitcases. Figure 8.7: Deal or No Deal First Offer We lost out on 50, 200, 50000, 300000, 400000, and the big one, 1000000. Not so good. We are bad at this game. After this, the banker offers us 8000. Should we take the money and run? Let’s calculate the expectation first. We do this by removing these suitcases, changing the probabilities and recomputing the expectation. How much does our expected value decrease? new_suitcases &lt;- c(0.01, 1, 5, 10, 25, 75, 100, 300, 400, 500, 750, 1000, 5000, 10000, 25000, 75000, 100000, 200000, 500000, 750000) new_probs &lt;- rep(1/20, 20) new_deal_expectation &lt;- sum(suitcases*probs) new_deal_expectation ## [1] 131477.5 8.8 Exercises 8.8.1 Exercise - Slot Machine Consider a dollar slot machine with three wheels each containing ten symbols. On each wheel there is one JACKPOT symbol and nine other non-jackpot symbols. You put $1 in the slot and the payoffs are as follows: If 3 JACKPOT symbols appear $487 is returned. If 2 JACKPOT symbols appear $10 is returned. If 1 JACKPOT symbol appears $1 is returned. Find the expected value. Note, with slot machines you put in your \\(\\$1\\) so you start out \\(-\\$1\\). Make sure you take this into account in your calculations. 8.8.2 Exercise - Design Your Own Slot Machine Consider a simple one dollar slot machine that has three identical wheels each of which has 10 symbols (not necessarily all distinct). Your job is to design an interesting slot machine giving the casino between a 10% and 15% house advantage (that is, the expected value is between -0.10 and -0.15). To do this you need to describe the symbols on each wheel, the combinations that receive a specific payoff, and analyze the slot machine by finding expected value. 8.8.3 Exercise - Fair Chuck-a-Luck In the game of Chuck-a-Luck, if the \\(\\$1\\) payoff was increased to some higher payoff of d dollars per occurrence of the chosen number (so d for one occurrence, 2d dollars for two occurrences, and 3d dollars for three occurrences) find the value for d that would make the game fair (that is, make the expected value 0). 8.8.4 Exercise - Chuck-a-Luck Big Prize In the game of Chuck-a-Luck, if the payoff remained \\(\\$1\\) for the first occurrence of the chosen number and \\(\\$2\\) for two occurrences but changed to b dollars for three occurrences, find the value for b that would make the game fair (that is, make the expected value 0). 8.8.5 Exercise - St. Petersburg Paradox Here’s a game for you. You flip a coin. If it comes up tails on the first flip you win $1. If it comes up heads on the first flip then tails you win $2. If it comes up heads on the first two flips then tails you win $4. If it comes up heads on the first three flips then tails you win $8. And so on. For example, if the first n flips are heads and the next one tails then you win 2n dollars. How much would you be willing to pay to play this game? Buffon played 2084 games. His winnings for those games would have been $10,057. Thus, what would you estimate the mathematical expectation to be based on his data? Now, complete the table below to calculate the mathematical expectaton. Does this answer sound reasonable to you? How does this theoretical probability match up with relative frequency. Figure 8.8: St. Petersburg Paradox Probability Distribution Table 8.8.6 Exercise - Squared Dots Here is a simple game. Roll a die and receive as many dollars as dots that are showing. How much is this game worth? Suppose you play a second game where you roll one die, observe the number of dots, and receive the square of that number in dollars. How much is this game worth? The payoff for the second game is always the square of the corresponding payoff for the first game. Is the expectation/mean for the second game the square of the expectation/mean of the first game, more, or less? Explain. 8.8.7 Exercise - Raising the Stakes You lay down a dollar and I lay down a dollar. Then we each roll a die. You roll first. The person with the highest result wins both dollars. If there is a tie the money is divided. (a) If you begin and roll a 3 then what is your expectation/mean? (b) What is the expectation/mean for the other possible outcomes? (c) Consider the following wrinkle. Suppose that right after you make your roll, you may immediately roll again but if you exercise this option you must put an additional dollar in the pot. When should you decide to exercise this option and take a second roll? (Source: Freudenthal. Probability and Statistics.) 8.8.8 Exercise - Deal or No Deal Revisited We played Deal or No Deal and were given the following offers. In one round we were given the offer of \\(\\$289,154\\) with six suitcases left containing \\(\\$1,\\$400,\\$5000,\\$500000,\\$750000,\\) and \\(\\$1000000\\). Figure 8.9: Banker offers $289,154. Then, after opening two more suitcases leaving \\(\\$1,\\$400,\\$500000,\\) and \\(\\$1000000\\) we were offered \\(\\$317,393\\). Figure 8.10: Banker offer increases to $317,393. Use mathematical expectation to explain why it makes sense that the banker’s offer increased. In the next round we opened one more suitcase and the \\(\\$500000\\) suitcase was now gone and only the \\(\\$1, \\$400\\), and \\(\\$1000000\\) were left. Figure 8.11: Banker offers now $294,991. The banker’s offer was now \\(\\$294991\\). Why did the banker’s offer decrease? Explain. From there, things got really bad for us. We opened one suitcase and lost the \\(\\$1000000\\) case. The banker offered us \\(\\$186\\). Who cares! Still, describe in general how the tool of mathematical expectation can assist in decision making in the game of Deal or No Deal. 8.8.9 Exercise - Deal or No Deal On Your Own When you play Deal or No Deal after each round the banker offers you a fixed amount. You can take this money and run or you can keep playing – it is up to you. Play the first round of the Deal or No Deal flashgame (http://www.gamesolo.com/flash-game/deal-or-no-deal.html) by opening six of the suitcases and determine your new expected value. Based on this information and amount the banker was willing to pay you to quit, determine whether or not you would take the banker’s offer. "],["measures_of_variation.html", "Chapter 9 Measures of Variation 9.1 Introduction 9.2 Chapter Scenario - Roulette Fun Bus 9.3 Measuring Variability with Variance and Standard Deviation 9.4 Example - Roulette Even Money Bet 9.5 Example - Roulette Single Number Bet 9.6 Example - Deal or No Deal 9.7 Chapter Scenario Revisited - Roulette Fun Bus", " Chapter 9 Measures of Variation 9.1 Introduction When examining data key features we look for are the shape, center, spread, and unusual values. Similarly, when examining a probability distribution we can see the shape and unusual values by visualizing the probability histogram and we can determine the expected value to shed light on the center of the distribution. But these tell us nothing about one of the most important aspects of a probability distribution to understand - the spread - that is, how the outcomes vary. We use two main measures for variability - variance and standard deviation. The main idea of the variance is that it is the average squared distance from the mean. The standard deviation is the square root of the variance. 9.2 Chapter Scenario - Roulette Fun Bus As described before, to play roulette you place a bet and spin the wheel. If the wheel matches your bet you win; if not, you lose. Remember that a roulette wheel contains slots numbered 1 through 36, half of them red, half black and green 0 and 00 slots. Different bets have different payoff ratios. Previously, we compared the even money bet paying off at 1:1 with a single number bet paying off at 35:1 and discovered the house advantage is identical for these two bets, \\(5.26\\%\\), in spite of the payoff odds being so different. Imagine two giant Fun Buses headed to Wendover each with 100 people. One is the bus and the other is the bus. On one bus (call it the conservative party bus) each person will spend the evening making 360 \\(\\$10\\) even money bets (red, black, even, odd, high, or low). Now, consider another bus (call it the party bus) where each person makes 360 bets of \\(\\$10\\) each on a single number, the lucky number of their choice. Our goal is to compare the bus ride home for these two groups. At the end of the evening, and all evenings must end, how do you expect results on the bus to compare with results on the bus in terms of shape, center, spread and unsual values? Do you expect the same distribution? Do you expect the same average winnings/losings? Do you expect the same proportion of winners? Which bus would have more big winners? Which bus would have more big losers? 9.3 Measuring Variability with Variance and Standard Deviation To measure the spread of a random variable, we need a reference point. We use the expected value, this key measure of the center of a distribution, as our reference point. We would like to see how far from the center the values of the random variable are likely to be. For technical reasons, we find the expected value of the square of the difference between random variable X and its mean. This is called the variance. The square root of the variance is called the standard deviation and have the virtue of being in the same units as the original random variable. 9.3.1 Definition of Variance If X is a random variable with expected value \\(\\mu\\), the variance of X, Var(X) or \\(\\sigma^{2}\\), is defined by \\[Var(X)=\\sum_{x} (x - Mean)^{2} \\cdot P(x)\\] A short-cut formula for variance is \\[Var(X)=E[X^{2}] - (E[X])^{2}\\]. 9.3.2 Definition of Standard Deviation If X is a random variable with expected value \\(\\mu\\), the standard deviation of X, identied as SD(X) or \\(\\sigma\\), is defined by \\[SD(X) = \\sqrt{Var(X)}=\\sqrt{\\sum_{x} (x - Mean)^{2} \\cdot P(x)}\\] 9.4 Example - Roulette Even Money Bet Suppose that \\(\\$10\\) is bet in Roulette on red. Adapting our previous analysis we can find the expected value. \\[E[X] = \\sum_{x} x \\cdot P(x)=+10 \\cdot \\frac{18}{38}-10 \\cdot \\frac{20}{38}=-\\frac{20}{38}=-0.526\\] To use the short-cut formula for the variance we can first find $E[X^{2}]. \\[E[X^{2}]=\\sum_{x} x^{2} \\cdot P(x)=10^{2} \\cdot \\frac{18}{38}+(-10)^{2} \\cdot \\frac{20}{38}=\\frac{3800}{38}=100\\] The variance is thus \\[Var(X)=E[X^{2}] - (E[X])^{2}=100 - (-0.526)^{2}=99.72\\] The standard deviation is the square root of the variance. \\[SD(X)=\\sqrt{Var(X)}=\\sqrt{99.72}=\\] 9.9859902 These values can be computed in R by first inputing the probability distribution. x &lt;- c(10,-10) probs &lt;- c(18/38,20/38) expectation &lt;- sum(x*probs) expectation ## [1] -0.5263158 variance &lt;- sum((x-expectation)^2*probs) variance ## [1] 99.72299 sd &lt;- sqrt(variance) sd ## [1] 9.98614 9.5 Example - Roulette Single Number Bet We can similarly analyze a \\(\\$10\\) is bet in Roulette on a single number. Adapting our previous analysis we can find the expected value. \\[E[X] = \\sum_{x} x \\cdot P(x)=+350 \\cdot \\frac{1}{38}-10 \\cdot \\frac{37}{38}=-\\frac{20}{38}=-0.526\\] To use the short-cut formula for the variance we can first find $E[X^{2}]. \\[E[X^{2}]=\\sum_{x} x^{2} \\cdot P(x)=350^{2} \\cdot \\frac{1}{38}+(-10)^{2} \\cdot \\frac{37}{38}=\\frac{3800}{38}=3226.316\\] The variance is thus \\[Var(X)=E[X^{2}] - (E[X])^{2}=3226.316 - (-0.526)^{2}=3226.039\\] The standard deviation is the square root of the variance. \\[SD(X)=\\sqrt{Var(X)}=\\sqrt{3226.039}=\\] 56.7982306. Using R: x &lt;- c(350,-10) probs &lt;- c(1/38,37/38) expectation &lt;- sum(x*probs) expectation ## [1] -0.5263158 variance &lt;- sum((x-expectation)^2*probs) variance ## [1] 3320.776 sd &lt;- sqrt(variance) sd ## [1] 57.62617 9.6 Example - Deal or No Deal Earlier we examined selecting a suitcase from the 26 Deal or No Deal suitcases and discovered the expected value is \\(\\$131477.50\\) while the theoretical median is \\(\\$875\\). Knowing these facts might impact how much you would be willing to pay to play the game but they are not the whole story. Suitcases amounts range from 1 cent to 1,000,000 dollars. Variance and standard deviation help us quantify how variable the outcomes are. We duplicate below the suitcase amounts and the probability vector along with calculating the expected value. suitcases &lt;- c(0.01, 1, 5, 10, 25, 50, 75, 100, 200, 300, 400, 500, 750, 1000, 5000, 10000, 25000, 50000, 75000, 100000, 200000, 300000, 400000, 500000, 750000, 1000000) probs &lt;- rep(1/26, 26) deal_expectation &lt;- sum(suitcases*probs) deal_expectation ## [1] 131477.5 Given the suitcase amounts suitcases and the mean deal_expectation and the probabilities probs we can easily compute the variance and standard deviation. deal_var &lt;- sum((suitcases-deal_expectation)^{2}*probs) deal_var ## [1] 64305084524 deal_sd &lt;- sqrt(deal_var) deal_sd ## [1] 253584.5 The standard deviation is large, approximately a quarter of a million, a reflection of the large range of possible winnings. We need to look at all of the pieces including the simulation and the theoretical analysis to better understand the situation. Suitcase amounts range from \\(\\$0.01\\) to \\(\\$1,000,000\\) with a mean of \\(\\$131,477.50\\), a median of \\(\\$875\\) and a standard deviation of \\(\\$253,584.50\\). The mean is large but so is the standard deviation. We would need to take this into account when deciding how much we would be willing to pay for the privilege of choosing a suitcase. 9.7 Chapter Scenario Revisited - Roulette Fun Bus Recall, we are imagining two giant Fun Buses headed to Wendover each with 100 people. On the conservative party bus, each person will spend the evening making 360 \\(\\$10\\) even money bets. On the party bus, each person will spend the evening making 360 bets of \\(\\$10\\) each on a single number, the lucky number of their choice. We have seen that the even money bets and the single number bets both have exactly the same house advantage, \\(5.26\\%\\). Our goal is to compare the two buses at the end of the evening. Will they have the same proportion of winners? Where will the big winners be? Where will the big losers be? Which bus would you rather ride home on? 9.7.1 Simulating the Bus The code below simulates 100 people each making 360 bets of 10 dollars each on an even money bet like Red and computes the sum for each person. red_bus &lt;- do(100)*sum(sample(c(-10,10), size=360, prob=c(20/38,18/38), replace=TRUE)) head(red_bus) ## sum ## 1 140 ## 2 -300 ## 3 -400 ## 4 -300 ## 5 -120 ## 6 -320 Running favstats() on the sum variable we can see on average how much each person lost. favstats(red_bus$sum) ## min Q1 median Q3 max mean sd n missing ## -660 -340 -220 -80 180 -207.2 181.8984 100 0 Examine the histogram of winnings/losings for the 100 people on the fun bus. ggplot(data=red_bus, aes(x=sum))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We can find the proportion of winners as follows: prop_red_winners &lt;- prop(red_bus$sum &gt; 0) prop_red_winners ## prop_TRUE ## 0.12 Summing up, we see that the average winnings on the night for these 100 people on the bus each spending the evening making 360 ten dollar even money bets on roulette was -207.2 dollars and that overall, 12% of the bus riders came out winners. 9.7.2 Simulating the Bus Now consider the party bus where each person makes 360 bets of \\(\\$10\\) each on a single number, the lucky number of their choice. The bus is where the real fun happens. Adapting the code above by changing the payoffs and probabilities, we simulate 100 people each making 360 bets of 10 dollars each on an even money bet like Red and compute the sum for each person. blue_bus &lt;- do(100)*sum(sample(c(-10,350), size=360, prob=c(37/38,1/38), replace=TRUE)) head(blue_bus) ## sum ## 1 2160 ## 2 0 ## 3 360 ## 4 -720 ## 5 -720 ## 6 -1440 Running favstats() on the sum variable we can see on average how much each person lost. favstats(blue_bus$sum) ## min Q1 median Q3 max mean sd n missing ## -2160 -720 -180 360 2160 -169.2 983.5143 100 0 Examine the histogram of winnings/losings for the 100 people on the fun bus. ggplot(data=blue_bus, aes(x=sum))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We can find the proportion of winners as follows: prop_blue_winners &lt;- prop(blue_bus$sum &gt; 0) prop_blue_winners ## prop_TRUE ## 0.38 Summing up, we see that the average winnings on the night for these 100 people on the bus each spending the evening making 360 ten dollar single nubmer bets on roulette was -169.2 dollars and that overall, 38% of the bus riders came out winners. 9.7.3 Comparing the and Buses We want to compare the results of two buses in terms of shape, center, spread, and unusual values. Both distributions were somewhat mound-shaped. The centers as measured by the means were different but we would expect in both cases the average loss to be \\(360 \\cdot 0.526\\) = 189.36. The bus lost a little more than this on average and the bus lost a little less than this on average but samples do vary. The most significant difference between the two buses is revealed when we examine the standard deviations. The bus had a standard deviation of 181.8984065 and the bus had a standard deviation of 983.5142925 which is more than five times larger. That means that outcomes on the bus were much more variable. When we place these simulated result in a side-by-side boxplot the difference in spread stands out. combined_data &lt;- data.frame(red=red_bus$sum, blue=blue_bus$sum) double_decker &lt;- stack(combined_data) colnames(double_decker) &lt;- c(&quot;winnings&quot;, &quot;bus&quot;) ggplot(double_decker, aes(x=bus,y=winnings, fill=bus))+geom_boxplot() We see there were more large winners and more large losers on the bus. There was no such large winners or losers on the bus. Variation matters. Which bus would you rather be on? "],["permutations.html", "Chapter 10 Permutations 10.1 Introduction 10.2 Chapter Scenario - GATC 10.3 Permutations 10.4 Fundamental Counting Principle Principle 10.5 Permutation Formula 10.6 Example - The Line-up 10.7 Example - The MISSISSIPPI Problem 10.8 Exercises 10.9 Exercises - Scrabble", " Chapter 10 Permutations 10.1 Introduction Determine correct probabilities relies heavily on correct counting. Combinatorics is the mathematics of counting and in this chapter we learn how to count ordered arranements (permutations) and unordered collections (combinations) for the ultimate purpose of tracking the probabilities of repeated events. 10.2 Chapter Scenario - GATC 10.3 Permutations Permutations are ordered arrangements. If we are given n distinct objects and are to select k of them and place them in order, we call this the permutation of k objects taken from n and symbolize it as P(n,k). By looking at some examples we will determine how to calculate permutations. One key to calculating permutations is using the Fundamental Principle of Counting. 10.4 Fundamental Counting Principle Principle Consider a multi-step process requiring k steps. If Step1 can be done \\(n_{1}\\) ways, Step2 done $n_{2} ways, and so on up to Step k being done $n_{k} ways, then the total number of ways the entire process can be done \\(n_{1} \\cdot n_{2} \\cdot ... \\cdot n_{k}\\) ways. Suppose you are playing scrabble and have four distinct letters, say A, S, N, and P. Not all of rearrangements are real words, of course, but how many total rearrangements of these four letters would we need to consider to check all the possible permuations? A tree diagram helps and shows there are 24 different orderings. Using the FPC there are four choices for the first letter, three for the second, two for the third, and only one choice left for the last letter making the total \\(4 \\cdot 3 \\cdot 2 \\cdot 1=4!=24\\). Thus, \\(P(4,4)=4!=24\\). Suppose you have seven distinct letters and you want to identify how many four-letter strings could be made. Using the Fundamental Counting Principle there are seven choices for the first letter, six for the second, and so on for a total of \\(P(7,4)=7 \\cdot 6 \\cdot 5 \\cdot 4\\) which is the same as \\(7!/3!\\). We describe this as a general formula below. 10.5 Permutation Formula The number of orderings of k objects taken from n distinct objects is \\(P(n,k)=n!/(n-k)!=n \\cdot (n-1) \\cdot (n-2) \\cdot ... \\cdot (n-k+1)\\). 10.6 Example - The Line-up Suppose that members of our class, all 20 of you, are to be seated in a row. How many ways can this be done? Ordering 20 people selected from 20 people is \\(P(20,20)=20!/0!=20!\\). What if Alice and Bob refuse to sit beside one another? Using the Complement Principle, let’s force them to sit together, count this, and subtract from the total. Think of putting a rubberband around them then we have only 19 things to order which can be done \\(19!\\) ways and then there are 2 orders for Alice and Bob so seating orders with them together is \\(2! \\cdot 19!\\). Putting this together \\[(\\# \\text{ of ways with Alice and Bob apart}) = \\\\ (\\text{Total}) - (\\# \\text{ of ways with Alice and Bob together}) = \\\\ 20! - 2! \\cdot 19!\\] What if there are 10 men and 10 women and we want no two men sitting together and no two women sitting together? Suppose we start with a man. Then alternating sex and using the Fundamental Counting Principle we see this can be done \\(10 \\cdot 10 \\cdot 9 \\cdot 9 \\cdot 8 \\cdot ... \\cdot 1 \\cdot 1 = 10! \\cdot 10!\\). Since we could start either with a man or with a women, two choices, the total is \\(2 \\cdot 10! \\cdot 10!\\). 10.7 Example - The MISSISSIPPI Problem How many arrangments are there of the word MISSISSIPPI? The issue we need to deal with is the repeated letters - there are four S’s, four I’s, and two P’s. If the word was LUMBERJACKS the answer would be \\(11!\\) because all the letters are unique. Let’s tackle a smaller problem, learn from it, and then ramp it up. Consider the word MISS. If the letters were all unique it would be \\(4!\\) orderings but in reality there are only twelve. To see why pretend we could tell the P’s apart with color or subscripts. Then each unique ordering of \\(MISS\\) is duplicated in the orderings of \\(MIS_{1}S_{2}\\) because of the \\(2!\\) orderings of the S’s. So, the total orderings of \\(MISS\\) is \\(4!/2!\\). Orderings of \\(MISSI\\) has to account for two S’s and two I’s so there are a total of \\(5!/(2! \\cdot 2!)\\). Orderings of \\(MISSISS\\) has to account for four S’s and two I’s. Imagining subscrips of four S’s would yield \\(4!\\) orderings. Taking care of everything, the total orderings of \\(MISSISS\\) is \\(7!/(4! \\cdot 2!)\\). Tackling MISSISSIPPI, the total number of orderings is \\(11!/(4! \\cdot 4! \\cdot 2!)\\). 10.8 Exercises 10.9 Exercises - Scrabble If you have six unique letters, how many total orderings are there of those six letters? How many total orderings are there including those not using all six letters? 10.9.1 Exercise - The Name Game Find the number of possible rearrangements for the following names - JON, BRAN, TYRION, TORMUND, KERMIT, ARYA, SANSA, JOFFREY, ELLARIA, CERSEI, EDDARD, LITTLEFINGER, DAENERYS TARGARYEN (as one word), DAENERYS TARGARYEN (as two words keeping first name letters together and last name letters together). 10.9.2 Exercise - License Plates Figure 10.1: Utah License Plates How many different license plates are there? See if you can determine the total number of license plates under the following schemes. Life Elevated Skier or Arches This plate contains six characters, consisting of one letter followed by three numbers followed by two letters. Olympic This plate was issued to commemorate the 2002 Olympic Winter Games held in Salt Lake City. As of July 1, 2002.It consists of three numbers followed by a letter followed by a number. Personalized Standard Life Elevated Skier or Arches plates For Utah personalized license plates, the type of plate requested limits the number of characters that may be used on the plate, with the Life Elevated Skier or Arches plates allowing up to seven characters which may be either numbers or letters. Personalized Motorcycle Plates These plates allow up to four characters which may be numbers or letters. 10.9.3 Exercise - Facts about Permutions What does P(n,1) equal for all \\(n \\geq 1\\)? What does P(n,n) equal for all \\(n \\geq 1\\)? What is the relationship between P(n,n-1) and P(n,n)? "],["combinations.html", "Chapter 11 Combinations 11.1 Introduction 11.2 Chapter Scenario - Three Counting Problems and an Algebra Problem 11.3 Example - From Class Line-up to Class Committee 11.4 Combination Formula 11.5 Chapter Scenario Revisited - Three Counting Problems and an Algebra Problem 11.6 Exercises", " Chapter 11 Combinations 11.1 Introduction While permutations count ordered arrangements, combinations are unordered collections of items. 11.2 Chapter Scenario - Three Counting Problems and an Algebra Problem Below are three counting problems and one algebra problem. On the surface these appear to be unrelated problems but can you find a deep connection between them? It might help to team up with classmates to gain multiple perspectives. Problem 1: Write down all the possible birth orderings for a family of three boys and two girls (for example, BGBBG is one of them). Problem 2: Find the number of ways that you can walk along the blocks from point A to point B by a path of shortest length. Figure 11.1: Block-walking Scenario Problem 3: How many ways could two captains be chosen from the five starting members of a basketball team? Problem 4: Expand the following: \\((p + q)^{5}\\). 11.3 Example - From Class Line-up to Class Committee If we were to select four people from our class of 20 and line them up, this could be done \\(P(20,4)=20!/16!=20 \\cdot 19 \\cdot 18 \\cdot 17\\) ways. But if we are interested in the number of unordered committees of four rather than ordered line-ups we notice that for each selection of four people, there were \\(4!=4 \\cdot 3 \\cdot 2 \\cdot 1\\) line-ups counted so the number of unordered committees is \\((20 \\cdot 19 \\cdot 18 \\cdot 17)/(4 \\cdot 3 \\cdot 2 \\cdot 1)\\). We call an undordered collection of k objects selected from n distinct objects a combination and use the notation \\(\\dbinom{n}{k}\\). A simple way to think of this is to find the permutation of k objects selected from n objects, \\(P(n,k)=n!/(n-k)!\\) and divide out the order, \\(k!\\). Putting all this together we get the following formula. 11.4 Combination Formula The number of unordered collections of k objects selected from n distinct objects is \\[\\dbinom{n}{k}=\\frac{P(n,k)}{k!}=\\frac{n!}{(n-k)!k!}= \\frac{n(n-1)(n-2)...(n-k+1)}{k(k-1)(k-2)...3 \\cdot 2 \\cdot 1}\\] Using this notation to recap the number of unordered committees selected from 20 students we see \\[\\dbinom{20}{4}=\\frac{20!}{16! \\cdot 4!}=\\frac{20 \\cdot 19 \\cdot 18 \\cdot 17}{4 \\cdot 3 \\cdot 2 \\cdot 1}\\] 11.5 Chapter Scenario Revisited - Three Counting Problems and an Algebra Problem After tackling these problems one at a time, we will search for underlying links between them. 11.5.1 Problem 1 - Birth Orderings Write down all the possible birth orderings for a family of three boys and two girls (for example, BGBBG is one of them). 11.5.1.1 Solution 1 - Brute Force Letting B represent a boy birth and G a girl birth and putting two B’s and three G’s in a sequence allows us to list all the possible birth orderings. To do this in a systematic way we can list them in alphabetical order and see there are 10 different birth orderings of two boys and three girls. BBBGG BBGBG BBGGB BGBBG BGBGB BGBBG GBBBG GBBGB GBGBB GGBBB 11.5.1.2 Solution 2 - Combinations We can view the problem of identifying a particular birth ordering of two boys and three girls as selecting the birth order position of the two boys or the birth order position of the three girls. Selecting the birth order position of the two boys is equivalent to selecting an unordered collection of two numbers from the set identifying the five birth order positions, {1,2,3,4,5}. This can be done \\(\\dbinom{5}{2}=\\frac{5!}{3! \\cdot 2!}=10\\) ways. Equivalently, selecting the birth order position of the three girls is equivalent to selecting an unordered collection of three numbers from the set {1,2,3,4,5} which can be done \\(\\dbinom{5}{3}=\\frac{5!}{2! \\cdot 3!}=10\\) ways, arriving at the same solution. 11.5.2 Problem 2 - Block-walking Find the number of ways that you can walk along the blocks from point A to point B by a path of shortest length. Figure 11.2: Block-walking Scenario 11.5.2.1 Solution 1 - Brute Force We can illustrate the 10 different paths of shortest length from A to B. 11.5.2.2 Solution 2 - Combinations If we identify the directions one can travel as down (D) or across (A), then a path of shortest length from A to B is a five-block walk described as a sequence of two D’s and three A’s. Again, we could choose which of the five blocks are the two down blocks as the number of unordered collection of two objects chosen from {1,2,3,4,5} which is \\(\\dbinom{5}{2}=\\frac{5!}{3! \\cdot 2!}=10\\) or, equivalently, thinking about the across blocks, the number of unordered collection of three objects chosen from {1,2,3,4,5} which is \\(\\dbinom{5}{3}=\\frac{5!}{2! \\cdot 3!}=10\\). In solving the problem using a combinations perspective we see that under the surface, Problems 1 and 2 are equivalent. 11.5.3 Problem 3 - Team Captains How many ways could two captains be chosen from the five starting members of a basketball team? 11.5.3.1 Solution 1 - Brute Force Numbering the players 1,2,3,4, and 5 and selecting two of them to be captains results in the following ten possibilities: 1,2 1,3 1,4 1,5 2,3 2,4 2,5 3,4 3,5 4,5 11.5.3.2 Solution 2 - Combinations Given players as members of the set {1,2,3,4,5} we want to select two of them, order not mattering which can be done \\(\\dbinom{5}{2}=\\frac{5!}{3! \\cdot 2!}=10\\) ways. Note, this is equivalent to counting the number of ways we can choose the three non-captains, \\(\\dbinom{5}{3}=\\frac{5!}{2! \\cdot 3!}=10\\). From this solution, we see that Problems 1, 2, and 3, although from very different real-world contexts, are combinatorially equivalent. 11.5.4 Problem 4 - Binomial Expansion Expand the following: \\((p + q)^{5}\\). 11.5.4.1 Solution 1 - Brute Force Traditionally, if we expand the binomial product above using the distributive property (often memorialized as the FOIL method) we arrive at the following terms. It’s not fun, and not always safe to try this at home but here are the results. 11.5.4.2 Solution 2 - Combinations In using the distributive property to multiply out \\((a+b)^{5}\\), we essentially have to choose a’s or b’s in each of the five binomial terms. If we focus on the b’s, we can choose zero b’s which can be done \\(\\dbinom{5}{0}\\) ways, one b which can be done \\(\\dbinom{5}{1}\\) ways, two b’s which can be done \\(\\dbinom{5}{2}\\) ways, three b’s which can be done \\(\\dbinom{5}{3}\\) ways, four b’s which can be done \\(\\dbinom{5}{4}\\) ways, or five b’s which can be done \\(\\dbinom{5}{5}\\) ways. This results in the following terms. \\[(a+b)^{5}=\\dbinom{5}{0}a^{5} + \\dbinom{5}{1}a^{4}b +\\dbinom{5}{2}a^{3}b^{2} +\\dbinom{5}{3}a^{2}b^{3} +\\dbinom{5}{4}ab^{4} +\\dbinom{5}{5}b^{5}\\] In general, this result is known as the binomial theorem. The coefficient on the \\(a^{3}b^{2}\\) term can be interpreted as the number of orderings of three a’s and two b’s, or as a combination \\(\\dbinom{5}{2}\\). What may not have been clear to us through all the years of learning algebra is that multiplying out a binomial product is really a combinatorial problem. 11.6 Exercises 11.6.1 Exercise - Alphabet Consider the 26 letters in our alphabet. How many different three letter strings can we make if repetition of letters is allowed? How many different three letter strings can we make if repetition of letters is not allowed? How many ways could three different letters be chosen? 11.6.2 Exercise - Facts about Combinations What is \\(\\dbinom{n}{0}\\) for all \\(n \\geq 1\\)? What is \\(\\dbinom{n}{1}\\) for all \\(n \\geq 1\\)? What is \\(\\dbinom{n}{n}\\) for all \\(n \\geq 1\\)? What is the relationship between \\(\\dbinom{n}{k}\\) and \\(\\dbinom{n}{n-k}\\)? "],["case_study_blockwalking.html", "Chapter 12 Case Study - Block-walking, Tree Diagrams, and the Quincunx 12.1 Chapter Scenario - The Quincunx 12.2 The Block-walking Encyclopedia 12.3 Chapter Scenario Revisited - The Quincunx 12.4 Simulation", " Chapter 12 Case Study - Block-walking, Tree Diagrams, and the Quincunx 12.1 Chapter Scenario - The Quincunx A Quincunx, (or Galton Board or Bean Machine), is a board with evenly spaced pegs laid out in a triangular grid as shown in the figure below. A ball is dropped onto the board from a funnel at the top center and bounces its way to the bottom in such a way that each time it hits a peg is has an equal chance of bouncing left or right. At the bottom the balls land in a bin. We want to examine the pattern when numerous balls are sent through the machine. Figure 12.1: Quincunx or Galton Board What pattern do you anticipate to see when a large number of balls are sent through the Quincunx? Explain why you think this pattern may emerge. 12.2 The Block-walking Encyclopedia Below is a diagram of some city blocks. How many ways can a person walk from the top corner to another corner B if she is restricted to paths of minimum length? To explore this question we document the answers at each intersection on the block-walking grid below. So, imagine that you are starting at the peak and then count how many different paths of shortest length there are from the peak to each intersection and write that number at the intersection. Do you recognize a pattern to these numbers? Figure 12.2: Block-walking Grid 12.3 Chapter Scenario Revisited - The Quincunx 12.4 Simulation Yihei Xie included a Quincunx simulation in the animation package. #quincunx(balls = 200, layers = 15, pch.layers = 2, pch.balls = 19, col.balls = sample(colors(), balls, TRUE), cex.balls = 2) 12.4.1 Exercise - Two-stage Quincunx Suppose that after running 200 balls run through a 15 layer quincunx, they then, from there ending point of this first stage, run through a another second-stage with 15 layers. In what ways would you expect the first layer and second layer results to look similar and in what ways would you expect them to look different? After making your prediction, uncomment and run the R code below and describe ways your predictions were accurate and ways they were inaccurate. #quincunx2(balls = 200, layers = 15, pch.layers = 2, pch.balls = 19, col.balls = sample(colors(), balls, TRUE), cex.balls = 2) 12.4.2 Exercise - Plinko Plinko is a popular game on The Price is Right. It is similar to a Quincunx where round disk is dropped into the board and is deflected left or right by pegs. It is, however, bounded on each side resulting in some disks being redirected. In the image below you can see there are 12 levels but only 9 possible outcomes. How would you expect the results on this board to be similar or different from an actual 12 level Quincunx? After making your prediction, run the simulation below and describe ways your prediction was accurate and ways your prediction was inaccurate. Figure 12.3: Price is Right Plinko "],["case_study_problem_of_the_points.html", "Chapter 13 Case Study - The Problem of the Points 13.1 Chapter Scenario - The BART Series 13.2 A Simpler Case - A Three-Two Split 13.3 Chapter Scenario Revisited - The BART Series", " Chapter 13 Case Study - The Problem of the Points 13.1 Chapter Scenario - The BART Series Suppose a game is stopped midway. How should the stakes be split if the game is not complete but one player is ahead of the other? This famous problem is known as the “Problem of the Points” and stimulated Blaise Pascal to generate some new ideas early in the development of probability theory. In this application we see how our tool of drawing tree diagrams helps us think it through. Let’s use baseball as an example. In the Major League Baseball World Series, teams play a series of up to seven games and the first team to win four games wins the series and is declared “world champions” (even though it is just the U.S. and a few Canadian teams). An interesting thing happened in the 1989 World Series between the Oakland Athletics and the San Francisco Giants, often called the “Battle of the Bay” or the “BART Series” for the Bay Area Rapid Transit System one would take to the opposite sides of the San Francisco Bay. The Oakland A’s were ahead two games to nothing when the interesting thing happened - an earthquake. Here is how Wikipedia describes it: “On October 17, just minutes before the start of Game 3, a magnitude 6.9 earthquake struck the Bay Area causing significant damage to both Oakland and San Francisco. Candlestick Park in San Francisco suffered damage to its upper deck as pieces of concrete fell from the baffle at the top of the stadium and the power was knocked out. The game was postponed out of concerns for the safety of everyone in the ballpark as well as the loss of power, with Vincent later saying that he did not know when play would resume.” (https://en.wikipedia.org/wiki/1989_World_Series) Suppose the series had to be permanently suspended at this point. How should the prize money be split? This is essentially an example of the famous “problem of the points.” What do you think would be a fair division of the prize money between the Oakland A’s and the San Francisco Giants? In other words, what percentage of the prize money should the Oakland A’s get and what percentage of the prize money should the San Francisco Giants get? We will use a tree diagram to solve this problem but let’s start with a simpler case. 13.2 A Simpler Case - A Three-Two Split Suppose the LA Dodgers and the Houston Astros are in the World Series and the Dodgers are ahead of the Astros 3-2. We can use a tree diagram to decide on the fair division of the prize money should the series be suspended at this point. With five games already played, there are potentially two remaining games which can be described in a tree diagram where D represents a Dodger win and A represents an Astros win. Assuming each team has the same chance of winning a new game, the four branches are equally likely. If the Dodgers win one more game, they win the series. Three of the four include at least one Dodger win and only one branch shows Houston winning the series, so a fair way to split the prize money would be a 3:1 split with the Dodgers receiving 75% of the prize money and Houston receiving 25%. Once we are comfortable we can see a shortcut to solve the problem of the points. With two remaining games left and the Dodgers needing only one to win we can examine the second row of Pascal’s triangle and identify the appropriate point in the row that represents at least on Dodger win. \\[ \\dbinom{2}{0} : \\dbinom{2}{1} + \\dbinom{2}{2}\\] You may have noticed that if the Dodgers win the next game a seventh game is not played but is included in the tree diagram. The extra branches were included in the diagram so that we could examine equally likely cases. An alternative is to place probabilities on the branches and terminate the tree when the series is over as in the diagram below. \\[P(\\text{Dodgers win})=0.5 + 0.5 \\cdot 0.5 = 0.75\\] \\[P(\\text{Astros win})=0.5 \\cdot 0.5=0.25\\] Thus, the split should be 75:25 or 3:1 in favor of the Dodgers. 13.3 Chapter Scenario Revisited - The BART Series In the original problem the Dodgers are ahead of the Astros 2 games to 0 with a potential of 5 remaining games yielding a tree diagram with 32 equally likely outcomes. If the Dodgers win 2 of the games they win the series. In the tree diagram, there are 26 brances in which the Dodgers win the series and 6 in which the Astros win the series meaning the prize money should be split 26:6 in favor of the Dodgers. Solving using Pascal’s triangle, for the five potential games, if the Dodgers win at least two they win the series. \\[\\dbinom{5}{0} + \\dbinom{5}{1} : \\dbinom{5}{2} + \\dbinom{5}{3} + \\dbinom{5}{4} + \\dbinom{5}{5}\\] \\[1+5:10+10+5+1 = 6:26\\] 13.3.1 Exercise - A Three:One Split Suppose the LA Dodgers and the Houston Astros are in the World Series and the Dodgers are ahead of the Astros 3-1. Use a tree diagram to decide on the fair division of the prize money should the series be suspended at this point. 13.3.2 Exercise - A Three:Zero Split Suppose the LA Dodgers and the Houston Astros are in the World Series and the Dodgers are ahead of the Astros 3-0. Use combinations and Pascal’s Triangle to decide on the fair division of the prize money should the series be suspended at this point. "],["the-binomial-distribution.html", "Chapter 14 The Binomial Distribution 14.1 Introduction 14.2 Chapter Scenario - Pounding Pennies 14.3 The Binomial Distribution 14.4 The Binomial Distribution in R 14.5 Example - Throwing Darts 14.6 Example - Tennis First Serve Percentage 14.7 Example - Set, Spike, Kill 14.8 Chapter Scenario Revisited - Pounding Pennies 14.9 Exercises", " Chapter 14 The Binomial Distribution 14.1 Introduction If we run an experiment where each trial has the same probability of success and failure, we can use the binomial distribution to determine the probability of any particular number of successes on a given number of trials. 14.2 Chapter Scenario - Pounding Pennies A random sample of pennies are set on edge and knocked over by gently pounding on the table. It may seem totally weird, but someone conjectures that this process we will call “pounding pennies” is significantly different from flipping a fair coin where the percentage of heads is 50%. In an experiment, we obtained 182 heads and 142 tails. Would this be considered an unusual event if the true percentage of heads was really 50%? Explain. (Note, we often consider as “unusual” an event that happens less than 5% of the time.) 14.3 The Binomial Distribution The binomial distribution is a discrete probability distribution describing the outcome of n independent trials in an experiment where each trial has only two outcomes identified as success and failure. Given n independent trials and the probability of a successful trial p, the probability of having X successful outcomes is a binomial denoted \\(X \\sim BIN(n,p)\\) with the probability density function as follows. \\[P(x)=\\binom{n}{x}p^x(1-p)^{n-x}\\] Examining the three key pieces of the binomial distribution, the initial combination, \\(\\binom{n}{x}\\), counts the arrangements of \\(x\\) successes and \\(n-x\\) failures, \\(p^x\\) is the probability of x successes and \\(p^{n-x}\\) is the probability of \\(n-x\\) failures. The expected value for \\(X \\sim BIN(n,p)\\) is \\(E(X)=np\\). The variance is \\(Var(X)=np(1-p)\\) and the standard deviation is \\(SD(X)=\\sqrt{np(1-p)}\\). As an illustration of the shape of a binomial distribution, here is the probability distribution for the number of sixes when rolling a die 10 times which is a binomial random variable with n=10 independent trials with a probability of success of \\(p=1/6=0.167\\). xpbinom(q=0:10, size = 10, prob = 1/6) ## [1] 0.1615056 0.4845167 0.7752268 0.9302722 0.9845380 0.9975618 0.9997325 ## [8] 0.9999806 0.9999992 1.0000000 1.0000000 When the expected number of successes, np, and the expected number of failures, n(1-p), are both at least 10 then the binomial distribution is approximately normal. As an illustration, here is the probability distribution for the number of sixes when rolling a die 100 times which is a binomial random variable with n=100 independent trials with a probability of success of \\(p=1/6=0.167\\). xpbinom(q=10:25, size = 100, prob = 1/6) ## [1] 0.04269568 0.07771922 0.12967080 0.20000525 0.28742092 0.38765755 ## [7] 0.49415898 0.59940744 0.69646992 0.78025016 0.84811215 0.89981653 ## [13] 0.93694967 0.96213563 0.97829662 0.98812250 14.4 The Binomial Distribution in R Assume we have a binomial random variabl of size n independent trials with probability of success p.  To find the individual probability of x successes, \\(P(X=x)\\), use dbinom(x, size, prob). To find the cumulative probability of less than or equal to q successes, \\(P(X \\leq q)\\), use pbinom(q, size, prob). To visualize the cumulative probability of less than or equal to q successes, \\(P(X \\leq q)\\), use xpbinom(q, size, prob). To find the cumulative probability of at least q successes, \\(P(X \\geq q)\\), use the complement principle to find 1-pbinom(q, size, prob), or include lower.tail=FALSE and find pbinom(q, size, prob, lower.tail=FALSE). To find the inverse probability, that is the value of q such that \\(P(X \\leq q) = p\\) use qbinom(p, size, prob). To visualize the inverse probablity, use xqbinom(p, size, prob). To generate a random sample of size n from this geometric random variable use rbinom(n, size, prob). 14.5 Example - Throwing Darts Suppose that a very good dart player hits the bulls-eye 15% of the time. Suppose she makes 25 throws. If X is the number of bulls-eyes we know \\(X \\sim BIN(25,0.15)\\). 14.5.1 Individual Probabilities Here is the probability she makes exactly 5 bulls-eyes in 25 throws. dbinom(x=5, size=25, prob=0.15) ## [1] 0.1563776 We can find the probabilities she makes 0, 1, 2, 3, 4, and 5 bulls-eyes in 25 trials with the following code. dbinom(x=c(0,1,2,3,4,5), size=25, prob=0.15) ## [1] 0.01719781 0.07587269 0.16067158 0.21737920 0.21098569 0.15637763 14.5.2 Cumulative Probabilities Suppose we want to find the cumulative probability she makes less than or equal to 5 bulls-eyes in 25 trials, \\(P(X \\leq 5)\\). Try this. pbinom(q=5, size=25, prob=0.15) ## [1] 0.8384846 Here is a visualization showing \\(P(X \\leq 5)\\). xpbinom(q=5, size = 25, prob = 0.15) ## [1] 0.8384846 Be careful regarding endpoints. If we want to find the cumulative probability she makes less than 5 bulls-eyes in 25 trials, note this is different. pbinom(q=4, size=25, prob=0.15) ## [1] 0.682107 Again, we can find cumulative probabilities for multiple values. pbinom(q=c(0,1,2,3,4,5), size=25, prob=0.15) ## [1] 0.01719781 0.09307050 0.25374208 0.47112128 0.68210697 0.83848460 To find the probability she makes between 3 and 7, inclusive, check out the following. It is tricky. pbinom(q=7, size=25, prob=0.15) - pbinom(q=2, size=25, prob=0.15) ## [1] 0.7207903 An alternative is to use the diff function. diff(pbinom(q=c(2,7), size=25, prob=0.15)) ## [1] 0.7207903 We often need to use the complement property to find the probability we seek. For example, if we want to find the cumulative probability she makes more than 5 bulls-eyes in 25 trials, \\(P(X &gt; 5)\\), try this. 1 - pbinom(q=5, size=25, prob=0.15) ## [1] 0.1615154 An alternative is the include lower.tail=FALSE. pbinom(q=5, size=25, prob=0.15, lower.tail=FALSE) ## [1] 0.1615154 To reiterate, be careful with endpoints. If we want to find the cumulative probability she makes at least 5 bulls-eyes in 25 trials, \\(P(X \\geq 5)\\) then… 1 - pbinom(q=4, size=25, prob=0.15) ## [1] 0.317893 Here is a visualization showing some individual probabilities. xpbinom(q=c(0,1,2,3,4,5), size = 25, prob = 0.15) ## [1] 0.01719781 0.09307050 0.25374208 0.47112128 0.68210697 0.83848460 14.5.3 Inverse Probabilities Suppose we want to find the number of bulls-eyes in 25 throws that she will make at least \\(75\\%\\) of the time. To find the value of q such that \\(P(X \\leq q) = 0.75\\) use qbinom(p=0.75, size=25, prob=0.15) ## [1] 5 To visualize this inverse probability: xqbinom(p=0.75, size=25, prob=0.15) ## [1] 5 To find the middle \\(95\\%\\) for the number of bulls-eyes we can expect her to make, we note there will be \\(2.5\\%\\) in each tail. We can find the range by obtaining the 2.5th and 97.5th percentiles. qbinom(p=c(0.025,0.975), size=25, prob=0.15) ## [1] 1 8 Visualizing: xqbinom(p=c(0.025,0.975), size=25, prob=0.15) ## [1] 1 8 14.6 Example - Tennis First Serve Percentage Sara Errani get about \\(79\\%\\) of her first serves in. How unusual would it be for her to make \\(95\\%\\) or more of her first serves on the next 20 tries? We can model the number of serves Errani makes on her next 20 tries, X, as a binomial random variable with n=20 independent trials and probability of success p=0.79. In summary, \\(X \\sim (20, 0.79)\\). To find the probability she makes \\(95\\%\\) or more on her next 20 tries, Errani must make 19 or 20. There are several ways we can solve all shown below. dbinom(x=19, size=20, prob=0.79) + dbinom(x=20, size=20, prob=0.79) ## [1] 0.05662592 1-pbinom(q=18, size=20, prob=0.79) ## [1] 0.05662592 Visualizing the result: xpbinom(q=18, size = 20, prob = 0.79) ## [1] 0.9433741 There is a 1-pbinom(q=18, size=20, prob=0.79) probability Errani could make \\(95\\%\\) or more of her first serves on the next 20 tries. 14.7 Example - Set, Spike, Kill Audrey and Taylor like playing volleyball. When spiking the ball, Audrey gets a kill 40% of the time and Taylor gets a kill 45% of the time. If in the next game each of them get three chances to spike the ball, what is the probability Audrey gets more kills than Taylor? If we let A represent the number of kills for Audrey and T the number of kills for Taylor then we want to find \\(P(A&gt;T)\\). To explore the possibilities we look at all the different cases and be careful with our ANDs and ORs. The table below shows the different possible combinations of kills for Audrey and kills for Taylor with the cells highlighted where Audrey has more kills than Taylor. Figure 14.1: Table for Number of Volleyball Kills by Audrey and Taylor The verbal model below describes the cases where Audrey has more kills than Taylor. Figure 14.2: Verbal Model for Audrey Having More Kills Than Taylor To find \\(P(A&gt;T)\\) we find the following: \\[P(A&gt;T)=P(T=0) \\cdot P(A \\geq 1) + P(T=1) \\cdot P(A \\geq 2) + P(T=2) \\cdot P(A=3)\\] Using dbinom and pbinom: case1 &lt;- dbinom(x=0, size=3, prob=0.45)*(1-dbinom(x=0, size=3, prob=0.4)) case2 &lt;- dbinom(x=1, size=3, prob=0.45)*(1-pbinom(q=1, size=3, prob=0.4)) case3 &lt;-dbinom(x=2, size=3, prob=0.45)*dbinom(x=3, size=3, prob=0.4) total_prob &lt;- case1 + case2 + case3 total_prob ## [1] 0.29557 Would you expect the probability that Audrey has more kills than Taylor to be lower, the same, or higher? 14.8 Chapter Scenario Revisited - Pounding Pennies So, a random sample of pennies were set on edge and knocked over by gently pounding on the table and this “pounding pennies” experiment resulted in 182 heads and 142 tails. If we were expecting heads and tails to be equally likely, how unusual is an event like this? If “pounding pennies” resulted in a 50/50 chance of heads, then the probability of getting heads is 0.50. We performed 324 independent trials of this experiment so the total number of heads we see would be a binomial random variable, X, with n=324 trials and probability of success 0.50. Given this many trials, the probability of exactly 182 heads would be small as would the probability of any particular number of heads. To see how unusual our result is we want to examine the probability of getting this many heads or more. Note \\(P(X \\geq 182) = 1 - P(X \\leq 181)\\). The expected number of heads would be \\(np=324 \\cdot 0.50 = 162\\). How unusual is it to be 20 above this? Note, the standard deviation is \\(\\sqrt{324 \\cdot 0.50 \\cdot 0.50}=\\) 9 we we are actually more than two standard deviations away from the mean. To compute the exact probaility of this many heads or more we note \\(P(X \\geq 182) = 1 - P(X \\leq 181)\\). 1-pbinom(q=181, size=324, prob=0.5) ## [1] 0.01505141 If we set our standard for an ususual event as anything with less than a \\(5\\%\\) chance, a common standard, we see that getting 182 heads out of 324 trials would be unusual if the probability really was 0.50. In fact, the probability of being this far on either side of the mean is twice the above probability. 2*(1-pbinom(q=181, size=324, prob=0.5)) ## [1] 0.03010283 Based on this analysis, this is evidence that pounding pennies is not a 50/50 proposition. We would have sufficient evidence to conclude the proportion of heads when pounding pennies is not 0.50. 14.9 Exercises 14.9.1 Exercises - Birth Orderings Consider the potential birth orderings by gender – boy or girl - for a family with four children. Assume getting a girl and getting a boy are equally likely. Given that a family has four children which sequence of boy and girl births is most likely: BBBB, BGGB, or GGGG? Explain. Find the probability distribution for the number of girls in the family. In fact, births are more likely to be boys than girls. In the United States in 1981, for example, there were 1,860,000 boy births and 1,769,000 girl births. In other words, 51.3% of all births were boys and 48.7% girls. Using these as estimates for the probabilities of a boy birth and girl birth, and assuming sexes of births are independent, recalculate the probabilities for the different gender compositions in a family of four. 14.9.2 Exercise - Slot Machine Consider a slot machine with five wheels where each wheel contains ten symbols. On each wheel there is one JACKPOT symbol and nine other non-jackpot symbols, thus, there is binary outcome - either a success (Jackpot) or a failure (non-Jackpot). Counting the number of Jackpot symbols follows a binomial distribution. A prize is won if three or more jackpot symbols are showing. Find the probability of this happening. 14.9.3 Exercise - Jasmine Recommends According to Sam nothing is more relaxing than a movie and some popcorn. Suppose she rates 75% of the movies Jasmine recommends to her with a “thumbs up.” What is the probability she will rate all four of the next movies Jasmine recommends with a “thumbs up”? 14.9.4 Exercise - Cancer Indicence Marijke enjoys thinking about diseases. She knows the number of new cases of cancer (cancer incidence) is 454.8 per 100,000 men and women per year (based on 2008-2012 cases). Given this rate, what is the probability that out of 100 people selected at random, none of them will get cancer? 14.9.5 Exercise - Famous Places Nicole likes to travel. Assume she has been to 70% of famous locations. If five famous locations are chosen at random, what is the probability she has already visited fewer than four of them? 14.9.6 Exercise - Stealing Dogs When Kennedy sees a dog there is a 90% chance she will try to steal that dog for her own. What is the probability that she will want to steal at least 5 of the next 6 dogs she sees? 14.9.7 Exercise - Please Read this Book! Sarah is a reader. She likes most of the novels she reads. Last year she liked 17 of the 20 novels she read. Assuming this proportion is approximately the true proportion of novels she likes, what is the probability she will like at least 90% of the next 10 novels she reads? 14.9.8 Exercise - The Animal Pictionary In a picture book of animals, Allison can identify 80% of the species. Suppose 100 animals are chosen at random to test her knowledge. What is the probability she can name at least 75 of them? 14.9.9 Exercise - Not that Funny! When Jake tells a joke, approximately 40% of the people laugh. If Jake tells a joke to our class of 21 people, what is the probability a majority will laugh? 14.9.10 Exercise - Beat the Dean Isaac beats the dean at ping pong approximately 1 time in a 100. What is the probability he will win at least one of the next 10 games? 14.9.11 Exercise - Perro No Habla Espanol Marin often tries to speak Spanish with dogs. Only 35% of the dogs she speaks with understand her. What is the probability that between seis y ocho of the next diez dogs will understand what she is saying? 14.9.12 Exercise - The Kitty Genovese Case Kayla likes insights from psychology. In one famous situation, it was reported that 38 bystanders neglected to intervene when Kitty Genovese was murdered. Find the probability of this occurring if we assume 1% of people will intervene. Find the probability of this occurring if we assume 5% of people will intervene. Find the probability of this occurring if we think 10% of people will intervene. 14.9.13 Exercise - Sweeping Three Jamie likes lacrosse. Suppose two teams of equal strength play three games. What is the probability of one team winning all three games? 14.9.14 Exercise - Stop Browsing Pinterest During Class Jordan can only afford to buy 2% of the boats he sees on Pinterest. What is the probability he cannot afford to buy any of the next 20 boats he views? 14.9.15 Exercise - To Sweat or Not to Sweat Assuming each day is a new day, Grace wakes up and makes a decision about whether or not to exercise. Historically she chooses to exercise on about 2/3 of the days and not exercise on about 1/3 of the days. In a given week, what is the probability she will not exercise all seven days? 14.9.16 Exercise - I Lift Things Up, I Set Things Down Luke can pretty well spot when a fellow weight lifter is using steroids and thinks about 20% of the gym rats he sees do. If a dozen of these individuals are selected at random at the gym to receive a free pound of liquid protein, what is the probability at least one of them uses steroids? 14.9.17 Exercise - Liking Probability Tegan likes learning and enjoys what she learns in probability class at least half of the time. Suppose there are 28 class sessions over the course of the semester. What is the probability she enjoys what she learns on at least 16 of the sessions? 14.9.18 Exercise - Swimming in the Ocean Emily swims in the ocean when the sun is shining. Suppose that on her favorite beach the sun shines 80% of the time. What is the probability she will go there four days in a row and not get to swim at least one day? 14.9.19 Exercise - Biking the Double Black Diamond When riding a double black diamond trail, Niklas crashes his mountain bike 6 out of every 10 times on average. Suppose he rides five trails in one day. Find and visualize the probabilities he crashes 0 times, 1 time, 2 times, 3 times, 4 times, and 5 times. 14.9.20 Exercise - Sloth-lore Jasmine like sloths. According to Wikipedia, “Currently living sloths belong largely to two families,Megalonychidae (”two-toed” sloths) and Bradypodidae (three-toed sloths). All living sloths have in fact three toes; the “two-toed” sloths, however, have only two fingers. Two-toed sloths generally move faster than three-toed sloths. Both types tend to occupy the same forests; in most areas, one species of three-toed sloth and one species of the larger two-toed sloth will jointly predominate.” Suppose that 61% of the population are three-toed sloths and 39% of the population are larger two-toed sloths. If 10 sloths are chosen at random to participate in a focus group screening the movie Zootopia (Jasmine also like movies), what is the probability less than half of the sloths chosen are three-toed sloths? 14.9.21 Exercise - DIY Binomial Make up your own binomial problem. Then solve it. "],["normal.html", "Chapter 15 Normal Distribution 15.1 Introduction 15.2 Chapter Scenario - Wanna be a Fighter Pilot 15.3 The Normal Probability Distribution 15.4 The Normal Distribution in R 15.5 Example - Normal Blood Pressure 15.6 The Standard Normal \\(Z \\sim N(0,1)\\) 15.7 Example - Tides 15.8 The 68-95-99.7 Rule 15.9 Exercises", " Chapter 15 Normal Distribution 15.1 Introduction Not everything is Normal (we certainly aren’t), but it is useful to model data that is unimodal, symmetric, and without outliers. A statistical “model” is a simplification or an idealization. Reality is, of course, never perfectly bell-shaped. Real data is not exactly symmetric with one clear peak in the middle. Nevertheless, this abstract model can give us good answers if used properly. 15.2 Chapter Scenario - Wanna be a Fighter Pilot Adult males have an average height of 70 inches with a standard deviation of 4 inches. Adult females have a short average height of 65 inches and a slightly smaller standard deviation of 3.5 inches. It is known that the heights of males and females are both normally distributed. Source: http://www.usablestats.com/lessons/normal To be a pilot in the Air Force’s you must be 64 to 77 inches tall when standing. What proportion of males and what proportion of females in the population qualify? 15.3 The Normal Probability Distribution Many natural phenomena appear to follow a bell-shaped distribution matching what is called a normal distribution. If the data is unimodal, symmetric, and without extreme outliers, a normal model might be appropriate. A normal random variable is a continuous random variable with probability density function given by \\[f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot e^{\\frac{{(x - \\mu)}^{2}}{2\\sigma ^2}}\\] where the mean is \\(\\mu\\) and the standard deviation is \\(\\sigma\\). The normal distribution with mean 0 and standard deviation 1, called the standard normal, looks like this: ggplot(data.frame(x = c(-4, 4)), aes(x)) + stat_function(fun = dnorm) + scale_x_continuous(breaks = -3:3) The probability density function, or pdf, is a function whose area under the curve on a particular region corresponds to the probability of the random variable falling in that region. The normal distribution was first discovered by Abraham DeMoivre when attempting to approximate binomial probabilities. The main reason that natural phenomena often are approximately normal is the Central Limit Theorem, discussed later, which proves that sums and means of random samples are increasingly normal as the sample size increases. 15.4 The Normal Distribution in R Given normal random variable X with parameters \\(\\mu\\) and \\(\\sigma\\): To find the probability of X being less than q, \\(P(X &lt; q)\\), use pnorm(q, mean, sd) or use pdist(\"norm\", q, mean, sd, plot = FALSE). To visualize the region and report the probability of X being less than q, \\(P(X &lt; q)\\), use pdist(dist=\"norm\", q, mean, sd). To visualize the region and not report the probability use pdist(dist=\"norm\", q, mean, sd, invisible=TRUE). To find the probability of X being greater than q, \\(P(X &gt; q)\\), use the complement principle and compute 1-pnorm(q, mean, sd) or include lower.tail=FALSE and find pnorm(q, mean, sd, lower.tail=FALSE) . To find the inverse probability, that is the value of x such that \\(P(X \\leq x) = p\\) use qnorm(p, mean, sd). To visualize the region and report the value of x such that \\(P(X \\leq x) = p\\) use qdist(dist=\"norm\", p, mean, sd). To visualize the region and not report the value use $P(X \\leq x) = p$ useqnorm(p, mean, sd, plot=FALSE)`. To generate a random sample of size n from a uniform random variable use rnorm(n, mean, sd). For all of the commands above the default value for the mean is 0 and the default value for the standard deviation is 1 generating results for the standard normal. 15.5 Example - Normal Blood Pressure Blood pressure varies normally and the mean and standard deviation for males and females both with normal blood pressure and with pre/hypertension is described in the table below. Figure 15.1: Normal and Pre/Hypertensive Blood Pressure by Sex For males with normal blood pressure, systolic blood pressure (SBP) is normally distributed with a mean of 113.8 and a standard deviation of 10.8. Source: https://www.researchgate.net/figure/The-mean-and-standard-deviation-values-for-systolic-and-diastolic-blood-pressure-among_tbl5_232742829 15.5.1 Finding SBP Probabilities with pdist If we are interested in finding the proportion or percentage of individuals within a particular range of values we use the pdist command. To find the proportion of males with normal blood pressure who have SBP below 120: pnorm(q=120, mean=113.8, sd=10.8) ## [1] 0.7170412 To get the proportion only and not the plot: pdist(&quot;norm&quot;, q = 120, mean = 113.8, sd = 10.8, plot = FALSE) ## [1] 0.7170412 To get the plot only and not the proportion: pdist(&quot;norm&quot;, q = 120, mean = 113.8, sd = 10.8, invisible = TRUE) To find the proportion of males with normal blood pressure who have SBP above 130 we use the complement principle since $P(X&gt;130)=1-P(X&lt;130). 1-pdist(&quot;norm&quot;, q = 120, mean = 113.8, sd = 10.8) ## [1] 0.2829588 To find the proportion of males with normal blood pressure who have SBP between 120 and 130 we note that \\(P(120&lt;X&lt;130)=P(X&lt;130)-P(X&lt;120)\\) and compute the following difference. To avoid getting two separate plots we include plot=FALSE. pdist(&quot;norm&quot;, q = 130, mean = 113.8, sd = 10.8, plot=FALSE) - pdist(&quot;norm&quot;, q = 120, mean = 113.8, sd = 10.8, plot=FALSE) ## [1] 0.2161516 An alternative is to input the vector q=c(120,130) and visualize the region with the area shown on the plot but not as output. pdist(&quot;norm&quot;, q = c(120,130), mean = 113.8, sd = 10.8) ## [1] 0.7170412 0.9331928 We can use the diff command to subtract the two values: diff(pdist(&quot;norm&quot;, q = c(120,130), mean = 113.8, sd = 10.8)) ## [1] 0.2161516 15.5.2 Finding SBP Percentiles with qdist If we are interested in finding the particular cutoff value for which a certain percentage of individuals fall below or above, we use the qdist command. To find the cutoff for the SBP at which \\(75\\%\\) of males with normal blood pressure fall below: qdist(&quot;norm&quot;, p = 0.75, mean = 113.8, sd = 10.8) ## [1] 121.0845 To get the percentile cutoff only and not the plot: qdist(&quot;norm&quot;, p = 0.75, mean = 113.8, sd = 10.8, plot = FALSE) ## [1] 121.0845 To get the plot only and not the percentile cutoff: qdist(&quot;norm&quot;, p = 0.75, mean = 113.8, sd = 10.8, invisible=TRUE) To find the SBP cutoff at which \\(60\\%\\) of males with normal blood pressure fall above, we need to adapt our code since the qdist command interprets the input as the area below, ie., the left-tail area. The SBP cutoff at which \\(60\\%\\) of males with normal blood pressure fall above is exactly the cutoff at which \\(40\\%\\) of males fall below. qdist(&quot;norm&quot;, p = 0.4, mean = 113.8, sd = 10.8) ## [1] 111.0639 To find the SBP cutoffs that capture the middle \\(90\\%\\) of males with normal blood pressure is subtle. Note, that the middle \\(90\\%\\) would have \\(5\\%\\) below the lower cutoff and \\(95\\%\\) below the upper cutoff. So, to find cutoffs for the middle \\(90\\%\\), we need to find the \\(5\\%\\) and the \\(95\\%\\) percentiles. Again, we can input multiple values with the vector p=c(0.05, 0.95). qdist(&quot;norm&quot;, p = c(0.05, 0.95), mean = 113.8, sd = 10.8) ## [1] 96.03558 131.56442 15.6 The Standard Normal \\(Z \\sim N(0,1)\\) The standard normal distribution is a normal distribution with mean 0 and standard deviation 1. Probability tables are available for the standard normal and other normal distributions can be converted to standard normals so an understanding of how the standard normal works is useful. If \\(X \\sim N(\\mu, \\sigma)\\) then \\(Z=\\frac{X-\\mu}{\\sigma} \\sim N(0,1)\\). The pdist, qdist, and rnorm commands use mean 0 and standard deviation 1 as default values. 15.7 Example - Tides Tides vary according to the weather, the time of year, and the phase of the moon but even taking all of these factors into account, the tide may be higher or lower than predicted and, according to M. T. Murray of the Liverpool Tidal Institute the prediction error, that is, the difference between the observed height of the tide and the predicted height of the tide, varies normally. This means that if we measure the prediction error in how many standard deviations above or below the expected hight, this variable, call it Z, will be a standard normal random variable with mean 0 and standard deviation 1, \\(Z \\sim N(0,1)\\). Source: https://journals.lib.unb.ca/index.php/ihr/article/viewFile/24101/27886 What proportion of the time is the actual tide more than one standard deviation below the mean? pdist(&quot;norm&quot;, q = -1) ## [1] 0.1586553 What proportion of the time is the actual tide within one standard deviation of the predicted tide? We want to find $P(-1&lt;Z&lt;1): pdist(&quot;norm&quot;, q = c(-1,1)) ## [1] 0.1586553 0.8413447 What proportion of the time is the actual tide within two standard deviations of the predicted tide? pdist(&quot;norm&quot;, q = c(-2,2)) ## [1] 0.02275013 0.97724987 What is the 75th percentile for the number of standard deviations the actual tide deviates from the predicted tide? We want to find q such that \\(P(X&lt;q)=0.95\\). qdist(&quot;norm&quot;, p=0.95) ## [1] 1.644854 15.8 The 68-95-99.7 Rule Summarizing the distribution of probabilities, we know that for all normal distributions \\(68\\%\\) of the population is within 1 standard deviation of the mean, \\(95\\%\\) of the population is within 2 standard deviations of the mean, and \\(99.7\\%\\) of the population is withing 3 standard deviations of the mean as visualized below. pdist(&quot;norm&quot;, q = c(-3,-2,-1,0,1,2,3), invisible = TRUE) 15.9 Exercises 15.9.1 Exercise - Exercise, Exercise Grace likes exercising and the amount of time she spends in aerobic exercise per week is normally distributed. If four hours per week is the 60th percentile and six hours per week is the 80th percentile, which would represent more exercise - the 70th percentile or 5 hours of exercise? 15.9.2 Exercise - Hello, Doggie! Audrey, Marin, and Allison like dogs, especially Viszlas. Male Viszlas weigh on average 54 pounds with a standard deviation of 5 pounds and are normally distributed. A small male Viszla named “Sweet Pea” only weighs 40 pounds. What percentage of male Viszla’s weigh less than “Sweet Pea”? 15.9.3 Exercise - Is ICE Nice? Luke is researching becoming an ICE agent and finds their salaries are normally distributed with a mean of \\(\\$58,000\\) with a standard deviation of \\(\\$9,000\\). What would the salary cutoff be for the top \\(10\\%\\) of ICE agent salaries? 15.9.4 Exercise - Friday is Skiday Jake, Nicole, Jamie, Niklas, Sarah, and Tegan like to go skiing and notice that on any given Friday during ski season about \\(33\\%\\) of their friends are headed up. If the percentage headed up skiing on a Friday is normally distributed with a mean of \\(33\\%\\) and a standard deviation of \\(9\\%\\), what is the probability \\(40\\%\\) or more will head up skiing on a randomly selected Friday? 15.9.5 Exercise - Ballroom Burn Ballroom dancing utilizes about 306 calories per hour. Assuming this is normally distributed with a standard deviation of 30 calories per hour, what is the probability that more than 350 calories will be burned in an hour? 15.9.6 Exercise - Don’t Search Pinterest During Probability Class A MasterCraft X1 Trailer and Mooring Boat Cover sells for about \\(\\$1500\\) with a standard deviation of \\(\\$300\\). Assuming price is normally distributed what proportion of items will sell for less than \\(\\$1200\\) which is the max of Jordan’s budget? 15.9.7 Exercise - Normal Blood Pressure Taylor is studying nursing and knows that systolic blood pressure (SBP) for women with normal blood pressure is normally distributed with a mean of 106.3 and a standard deviation of 8.9. (a) Find the \\(95\\%\\) middle range for SBP for women. (b) What percentage of women with normal blood pressure have SBP less than 100? (c) Use the 68-95-99.7 Rule to describe the \\(68\\%\\), \\(95\\%\\), and \\(99.7\\%\\) SBP ranges for women with normal blood pressure. 15.9.8 Exercise - Ping Pong with the Dean When playing against the Dean, Isaac scores on average 10 points with a standard deviation of 4. Assuming the data is approximately normally distributed what is the probability Isaac will score 18 or more points. 15.9.9 Exercise - Should I Take This to Antique Road Show? Small sketches by old masters sell for about \\(\\$500\\) with a standard deviation of \\(\\$125\\). Marijke wants to find the middle range, that is, the lower and upper cutoffs within which \\(50\\%\\) of small old master sketches will sell. 15.9.10 Exercise - Should be Have Universal Health Care? Medical expenses vary by household but according to Kennedy’s research within one population, the annual deductible for individual plans was \\(\\$4300\\). If this is normally distributed with a standard deviation of \\(\\$800\\), what proportion of plans have annual deductibles greater than \\(\\$5000\\)? 15.9.11 Exercise - Movie Run Times Sam is relaxing with a movie. Looking at popular movies over a period of time she notices that movie run time averages about 130 minutes but varies with a standard deviation she estimates to be 15 minutes. If the distribution of movie run times is normally distributed what is the probability a movie chosen at random will time in at under 100 minutes? 15.9.12 Exercise - The Sloth Olympics Jasmine likes sloths. During the sloth Olympics, the average time for the three meter dash is 46 seconds, normally distributed with a standard deviation of 5 seconds. For a sloth chosen at random, what is the probability their three meter dash time will be more than 50 seconds? 15.9.13 Exercise (Group Project) - Analyzing Grading Systems According to the Westminster College Catalog a letter grade of A represents “Excellent” work, a grade of B is “Above Average,” a grade of C is “Average,” a grade of D is “Poor,” and a grade of F is “Failure.” While grades vary significantly for different classes, different professors, and different disciplines, and there are an incredible number of relevant factors involved in grading procedures. Preconception: Discuss from your own personal perspective what distribution of A’s, B’s, C’s and non-passing D’s and F’s you think would represent a healthy institution that truly attempts to distinguish between “Excellent” and “Average” work. Include the percentages you would expect for each grade. Suppose that scores in the math department historically follow a normal distribution with a mean of 79.2 and a standard deviation of 9.4. Use this information throughout the rest of the project. You will compare and contrast the three grading schemas finding the point ranges and percentages of students getting an A, B, C, D, and F. Do this by completing the tables given and illustrating the distribution of scores on the normal curve provided. Note, each tick mark on the scale represents a length of one standard deviation. Consider the Traditional Grading System where a score of 90 or higher receives an A, 80 to less than 90 receives a B, 70 to less than 80 receives a C, 60 to less than 70 receives a D and below 60 receives an F. Complete the table below to determine the percentage of students obtaining each grade for this Traditional Grading System and visualize the A, B, C, D, and F regions on a plot of the normal probability density function. Figure 15.2: The Traditional Grading System Consider the Standardized Grading System where being more than 2 standard deviations above the mean receives an A, being between 1 and 2 standard deviations above the mean receives a B, being within 1 standard deviation on either side of the mean receives a C, being between 1 and 2 standard deviations below the mean receives a D, and being more than 2 standard deviations below the mean receives an F. Complete the table below identifying both the point range and percentage of students for each grade and visualize the A, B, C, D, and F regions on a plot of the normal probability density function. Figure 15.3: The Standardized Grading System Consider the Curved Grading System where the top 10% of students receive an A, the next 15% of students receive a B, the middle 50% of students receive a C, the next 15% of students receive a D, and the bottom 10% of students receive an F. (a) Complete the table below finding the point range for each grade and visualize the A, B, C, D, and F regions on a plot of the normal probability density function. Figure 15.4: The Curved Grading System In your opinion, which system most closely matches the meaning of grades according to the Westminster College catalog? Please explain. Devise your own grading scheme completing the table below and explaining your rationale. Figure 15.5: Your Own Grading System "],["sums_of_random_variables.html", "Chapter 16 Sums of Random Variables 16.1 Introduction 16.2 Chapter Scenario - Comparing Heights 16.3 Example - Wheels of Fortune 16.4 Expectation for the Sum of Two Random Variables 16.5 Variance and Standard Deviation for the Sum of Two Random Variables 16.6 Summing Independent Identically Distributed Random Variables 16.7 The Roots of the Normal 16.8 The Central Limit Theorem 16.9 Conclusion 16.10 Adding Normals 16.11 Example - Tips on the Weekend 16.12 Chapter Scenario Revisited - Comparing Heights 16.13 Exercises", " Chapter 16 Sums of Random Variables 16.1 Introduction Our lives are made up of a combination of factors. Often we are add quantities from different buckets. We receive income from different sources. We add time spent in different pursuits. How tall we are is a sum of the length of each body part. These quantities vary. How do their sums vary. In this chapter, we examine what happens when two independent random variables are added. How does their shape change? How does the center change? How does their spread change? And then, we will see, how our minds can change. 16.2 Chapter Scenario - Comparing Heights Adult males have an average height of 70 inches with a standard deviation of 4 inches. Adult females have a short average height of 65 inches and a slightly smaller standard deviation of 3.5 inches. It is known that the heights of males and females are both normally distributed. Source: http://www.usablestats.com/lessons/normal If a male and a female were chosen at random, what is the probability that the female would be taller than the male? 16.3 Example - Wheels of Fortune Consider the two games described below. Game One: A wheel has slots numbered 0 to 200 all of them equally likely and an individual spins the wheel one time and wins the dollar amount shown. Game Two: A wheel has slots numbered 0 to 100 all of them equally likely and an individual gets to spin the wheel twice and win the combined dollar amount for his/her two spins. How are these two games similar and how are they different? 16.3.1 Practice - Preconceptions Suppose each of these games was played a number of times and the results tabulated. How do you think the two data sets for the two different games would compare in terms of shape, center, and spread? 16.3.2 Simulating the Games We can run a simulation of each of these two games and compare results. To simulate Game One, generate 1000 random integers ranging from 0 to 200 in one vector and name this variable game_one. game_one &lt;- sample(x=0:200, size=1000, replace=TRUE) To simulate Game Two, generate two vectors of 1000 random integers each ranging from 0 to 100 and add them naming this sum game_two. spin_one &lt;- sample(x=0:100, size=1000, replace=TRUE) spin_two &lt;- sample(x=0:100, size=1000, replace=TRUE) game_two &lt;- spin_one + spin_two We can put these variables in a data frame. wheels_of_fortune &lt;- data.frame(game_one, game_two) And run summary statistics for game_one and game_two. favstats(wheels_of_fortune$game_one) ## min Q1 median Q3 max mean sd n missing ## 0 47 96 146 200 96.927 58.92656 1000 0 favstats(wheels_of_fortune$game_two) ## min Q1 median Q3 max mean sd n missing ## 3 72 100 130 197 100.266 41.53524 1000 0 Are the centers of game_one and game_two similar or different? Are the spreads of game_one and game_two similar or different? While both are centered around 100 as seen by the means and medians, we see that the spreads as measured by the standard deviations are not the same. Game Two is less variable than Game One. Visualizing the data with histograms might help explain this. How do the two histograms compare in terms of shape? stacked_wheels &lt;- stack(wheels_of_fortune) ggplot(data=stacked_wheels, aes(x=values)) + geom_histogram(binwidth=10) + facet_grid(ind ~ .) Game One has what looks like a flat, uniform disribution while Game Two appears mound-shaped. Can we provide a reasonable explanation for WHY the two distributions have the different shapes that they do? Consider the grid below showing one dot for each combination of a result from the first spin from 0 to 100 and a result from the second spin from 0 to 100. Figure 16.1: Sample Space for Game Two An intuitive explanation might note that when playing Game One we are just as likely to get a small value from 0 to 10 as to get a middle value from 95 to 105 as to get a large value from 190 to 200. But when playing Game Two, there are many more ways to get a middle value than there is to get a small value and than there is to get a large value. For example, to get a small total in Game Two both spins must be small and, similarly, to get a large total in Game Two both spins must be large. But to get a middle value can happen many ways - by adding a small and a large or two medium-size values. There are many more combinations of numbers summing to a middle number than there are summing to either a small or a large number. Examine the sample space of equally likely outcomes for the two wheels in the 101 x 101 grid below where the rows represent the represent the result on the wheel one and the columns the result on wheel two. Shaded in green are the results with the sum from 0 to 10. Shaded in red are the results with the sum from 95 to 105. Shaded in blue are the results with the sum from 190 to 200. Which is more likely? We see here the beginnings of important ideas about sampling distributions and how the shape, center, and spread change when summing independent random variables and the first hints of the Central Limit Theorem which reveals why the normal, bell-shaped distribution occurs when we gather sample data and examine sums or means. There is so much more to learn. Let’s capture some theory. 16.4 Expectation for the Sum of Two Random Variables If the results of two random variables, X and Y, are added, the resulting expectation is the sum of the individual expectations. For example, in Wheels of Fortune Game Two, each wheel has equally likely outcomes from 0 to 100 so the expectation on each wheel is 50. When summing the results from these wheels, as expected, we see the distribution is centered around \\(50 + 50 = 100\\). In general, for any two random variables X and Y with expectations E(X) and E(Y), respectively, the expectation of X + Y is their sum. \\[\\text{For any two random variables X and Y}, \\ E(X+Y)=E(X)+E(Y).\\] 16.5 Variance and Standard Deviation for the Sum of Two Random Variables While expectations add for the sum of two random variables, the story is more complicated for the variation of the sum of two random variables. First of all, if the two random variables are not independent, then we need to know the nature of their relationship to determine how the sum varies. For two independent random variables, X and Y, with Var(X) and Var(Y), respectively, the variance of the sum, X + Y, is the sum of the variance. \\[\\text{For any two independent random variables X and Y}, \\ Var(X+Y)=Var(X)+Var(Y).\\] If we write this relationship in terms of standard deviation we see that the standard deviation for the sum of two independent random variables follows a Pythagorean relationship. \\[\\text{For any two independent random variables X and Y}, \\ SD^{2}(X+Y)=SD^{2}(X)+SD^{2}(Y).\\] Solving for SD(X+Y), \\[\\text{For any two independent random variables X and Y}, \\ SD(X+Y)=\\sqrt{SD^{2}(X)+SD^{2}(Y)}.\\] This result can be visualized as if SD(X) and SD(Y) were legs of a right triangle with hypotenuse SD(X+Y). Figure 16.2: The Pythagorean Theorem of Standard Deviations For example, we can use the Pythagorean Theorem of Standard Deviations and the fact that for one spin of the wheel with integers 0 to 100 the theoretical standard deviation is 29.15 to explain the standard deviation you received when you analyzed the data gathered in the simulation of Game Two. \\[SD(\\text{Game Two})=\\sqrt{SD^2(\\text{Wheel One}) + SD^2(\\text{Wheel Two})}=\\sqrt{29.15^{2}+29.15^{2}}=41.2243\\] This true value of 41.2243 closely matches our simulated standard deviation of 41.5352431. It is also to be noted that the Pythagorean Theorem of Standard Deviations also holds for the difference of indpendent random variables leading to this generalization. \\[\\text{For any two independent random variables X and Y}, \\ SD(X \\pm Y)=\\sqrt{SD^{2}(X)+SD^{2}(Y)}.\\] 16.6 Summing Independent Identically Distributed Random Variables Extending the above results to the case where we are summing n independent occurrences of identically distributed random variables yields the following theorems which are important for understanding random samples drawn from the same population: \\[\\text{For any identically distributed random variables} X_{1}, X_{2}, ...,X_{n} \\sim(\\mu,\\sigma) \\\\ E(X_{1} + X_{2} + ... + X_{n})=E(X_{1})+ E(X_{2})+ ...+E(X_{n})=\\mu + \\mu + ... + \\mu=n\\mu.\\] The above fact is true whether or not the random variables are independent while the fact below is only true when the random variables are independent. \\[\\text{For independent, identically distributed random variables} \\ X_{1}, X_{2}, ...,X_{n} \\sim(\\mu,\\sigma), \\\\ SD(X_{1} + X_{2} + ... + X_{n})=\\sqrt{SD^{2}(X_{1})+ SD^{2}(X_{2})+ ...+SD^{2}(X_{n})}= \\\\ \\sqrt{\\sigma^{2} + \\sigma^{2} + ... + \\sigma^{2}}=\\sqrt{n} \\cdot \\sigma.\\] We will call this the \\(\\sqrt{n}\\) Rule. 16.7 The Roots of the Normal The normal bell-shaped curve is so ubiquitous it is almost taken for granted. It is helpful to see its origins by examining sums of independent random variables. We will use the experiment of tossing a die to illustrate how the normal distribution emerges. Consider the experiment of tossing one die and plotting the results in a histogram. What would you expect for the shape, center, and spread of this data? Code below simulates the toss of one die and puts this data into an official R data frame to facilitate the analysis and visualizes the data in a histogram. The code the the histogram uses the ggplot2 package, the standard for plotting data in R. Die1 &lt;- sample(c(1,2,3,4,5,6), 10000, replace = TRUE) Dice_data &lt;- data.frame(Die1) ggplot(data=Dice_data, aes(x=Die1)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 16.3: Histogram for Saturday Tips The theoretical expectation for the toss of one die is \\(E(X)=3.5\\) and the theoretical standard deviation is \\(SD(X)=1.708\\). Note how similar these theoretical values are to the sample values in the simulation. The casino game craps revolves around the sum of the toss of two dice. If the experiment of tossing two dice and computing the sum was done many times and the results plotted in a histogram what would you expect for the shape, center, and spread? 16.7.1 Simulating the Toss of Two Dice Code below simulates the sum of two dice. We visualize with a histogram. Dice_data$Die2 &lt;- sample(c(1,2,3,4,5,6), 10000, replace = TRUE) Dice_data$Sum &lt;- Dice_data$Die1 + Dice_data$Die2 ggplot(data=Dice_data, aes(x=Sum)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 16.4: Histogram for Saturday Tips Comparing with the results of the two simulations, while one die resulted in a flat, uniform distribution, we see that the distribution for the sum of two dice is a triangular distribution. Why is it that when summing two dice, we see a tendency towards a mound-shaped distribution? The theoretical expectation for the sum of two dice is \\(3.5 + 3.5=7.0\\). The theoretical standard deviation for the sum of two dice, according to the Pythagorean Theorem of Standard Deviations is \\(\\sqrt{1.708^{2}+1.708^{2}}=2.4155\\). Again, these values are very close to the sample values seen in the simulation. Moving on, we adapt the code above to simulate the sum of three dice and visualize with a histogram. Dice_data$Die3 &lt;- sample(c(1,2,3,4,5,6), 10000, replace = TRUE) Dice_data$Sum3 &lt;- Dice_data$Die1 + Dice_data$Die2 + Dice_data$Die3 ggplot(data=Dice_data, aes(x=Sum)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 16.5: Histogram for Saturday Tips We observe that summing three dice, the distribution becomes increasingly mound-shaped. Below is code crafted to illustrate the sum of 50 tosses of a die as well as the sample mean of these 50 tosses. die_matrix &lt;- data.frame(matrix(sample(1:6, 500000, replace=TRUE), ncol=50)) die_matrix$sum &lt;- rowSums(die_matrix) die_matrix$mean &lt;- die_matrix$sum/50 head(die_matrix[,51:52]) ## sum mean ## 1 167 3.34 ## 2 179 3.58 ## 3 186 3.72 ## 4 170 3.40 ## 5 178 3.56 ## 6 151 3.02 Let’s take a look at the histogram of the sum of 50 dice. ggplot(data=die_matrix, aes(x=sum)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 16.6: Histogram for Saturday Tips The average is the sum divided by 50 and should be close to 3.5 but varies. Let’s examine the histogram. ggplot(data=die_matrix, aes(x=mean)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 16.7: Histogram for Saturday Tips The histograms of the sum of 50 dice and the mean of 50 dice have identical shapes, it is only the scale that changes. 16.8 The Central Limit Theorem The Central Limit Theorem indicates that the sum of independent random variables as well as the sample means converge to the normal distribution as the sample size increases. We present two versions here. 16.8.1 The Central Limit for Sums For any sample of size n gathered from a ditribution of random variable X with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), the distribution of the sum a) approaches the normal distribution as n approaches infinity b) the theoretical expected value is \\(n \\cdot \\mu\\) c) the theoretical standard deviation is \\(\\sqrt{n} \\cdot \\sigma\\). 16.8.2 The Central Limit for Sample Means For any sample of size n gathered from a ditribution of random variable X with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), the distribution of sample means a) approaches the normal distribution as n approaches infinity b) the theoretical expected value is \\(\\mu\\) c) the theoretical standard deviation is \\(\\frac{\\sigma}{\\sqrt{n}}\\). 16.9 Conclusion Through simulating the toss of one die, the sum of two, three, and then more we see that sums of a random variable even if it is not originally from a mound-shaped distribution (note, the distribution for a single die is discrete uniform) we find the sums increasing become mound-shaped. And sample means are really sample sums just re-scaled by dividing by the sample size. This is the secret to why the normal distribution emerges when we examine sample means. 16.10 Adding Normals What if we are adding or subtracting random variables that are normally distributed. Then we know the sum and difference are also normal. Here is the theory: For independent \\(X \\sim N(\\mu_{X}, \\sigma_{X})\\) and \\(Y \\sim N(\\mu_{Y}, \\sigma_{Y})\\) then \\(X \\pm Y \\sim N(\\mu_{X} + \\mu_{Y}, \\sqrt{\\sigma_{X}^{2} + \\sigma_{X}^{2}})\\). 16.11 Example - Tips on the Weekend Suppose a friend of yours is working as a server. Suppose that on Fridays tips average $120 with a standard deviation of $30 and are normally distributed. With Friday tips, F, we denote this as \\(F \\sim N(\\mu = 120, \\sigma = 30)\\). The distribution would look like this: ggplot(data.frame(x = c(30, 210)), aes(x)) + stat_function(fun = dnorm, args = list(mean = 120, sd = 30)) + scale_x_continuous(breaks = c(30,60,90,120,150,180,210)) Figure 16.8: Histogram for Friday Tips Suppose that Saturday tips, S, are a little different with tips normally distributed with a mean of \\(\\$90\\) and a standard deviation of \\(\\$20\\), so \\(S \\sim N(\\mu = 90, \\sigma = 20)\\). Here we can visualize the distribution: # Again, don&#39;t worry about the syntax here. ggplot(data.frame(x = c(30, 150)), aes(x)) + stat_function(fun = dnorm, args = list(mean = 90, sd = 20)) + scale_x_continuous(breaks = c(30, 50, 70, 90, 110, 130, 150)) Figure 16.9: Histogram for Saturday Tips Suppose your friend really needs \\(\\$200\\) in tips this weekend. Rent is due. The broader question before us is what the distribution of total tips on the weekend, Friday plus Saturday (F + S), looks like. Is it normal? What is the mean? What is the standard deviation? As a simplifying assumption we will assume that based on past experience Friday tips and Saturday tips are independent. Let’s run a simulation to get an idea of what to expect. The code below simulates 1000 Friday tips calling the variable friday rounded to the nearest dollar and, similarly, 1000 Saturday night tips, then their sum, weekend, and put them into a dataframe for ease of analysis. friday &lt;- round(rnorm(1000, mean = 120, sd = 30), 0) saturday &lt;- round(rnorm(1000, mean=90, sd=20), 0) weekend &lt;- friday + saturday tips_data &lt;- data.frame(friday, saturday, weekend) Let’s visualize the weekend variable in a histogram. ggplot(data=tips_data, aes(x=weekend)) + geom_histogram(binwidth=10) Figure 16.10: Histogram for Saturday Tips It appears that adding these two independent normal random variables generated another normal. Let’s examine summary statistics to see the mean and standard deviation. favstats(tips_data$weekend) ## min Q1 median Q3 max mean sd n missing ## 91 188 211 233 318 210.45 35.17961 1000 0 Note that the mean is around \\(\\$210\\) which we might expect since the mean of Friday tips was \\(\\$120\\) and the mean of Saturday night tips was \\(\\$90\\). The standard deviation of weekend tips is bigger than the individual standard deviations of \\(\\$30\\) and \\(\\$20\\) but smaller their sum. What really happens when adding independent normal random variables is that the shape is normal, the mean is the sum of the individual means but the standard deviation is the square root of the sum of the squares of the individual standard deviations, a result akin to our familiar Pythagorean Theorem of Standard Deviations. In summary, given independent normal distributions X and Y with \\(X \\sim N(\\mu_{X}, \\sigma_{X})\\) and \\(Y \\sim N(\\mu_{Y}, \\sigma_{Y})\\) we know \\(X+Y \\sim N(\\mu_{X}+\\mu_{Y}, \\sqrt{\\sigma_{X}^{2}+\\sigma_{Y}^{2}})\\). For our example where Friday tips are \\(N(\\mu = 120, \\sigma = 30)\\) and Saturday tips are \\(N(\\mu = 90, \\sigma = 20)\\) we know that the sum of these is normal with mean \\(120 + 90\\) with a standard deviation of \\(\\sqrt{30^2 + 20^2}\\) which equals 36.0555128. Observe how close the simulated mean and SD are to what the theory says. Now, knowing tips on the weekend are normally distributed with a mean of \\(\\$210\\) and a standard deviation of \\(\\$36.06\\) we can find the probability of getting more than \\(\\$200\\). 1-pdist(&quot;norm&quot;, q = 200, mean = 210, sd = 36.06) ## [1] 0.6092311 16.12 Chapter Scenario Revisited - Comparing Heights Recall, we know dult males have an average height of 70 inches with a standard deviation of 4 inches and adult females have an average height of 65 inches and a standard deviation of 3.5 inches, both normally distributed. Letting M represent male height and F represent female height, we have \\(M \\sim N(70,4)\\) and \\(F \\sim N(65,3.5)\\). We want to find the probability that if a male and a female were chosen at random the female would be taller than the male. Mathematically, we want to know when \\(F &gt; M\\) which is equivalent to finding when \\(M - F &lt; 0\\). We know how \\(M - F\\) is distributed. Because M and F are both normal we know \\(M - F\\) is normal. The expectation is \\(E(M - F) = E(M) - E(F)=70 - 65 = 5\\). Using the Pythagorean Theorem for Standard Deviations, \\(SD(M-F)=\\sqrt{SD^{2}(M) + SD^{2}(F)}=\\sqrt{4^2 + 3.5^2}=5.315\\). Thus, \\(M-F \\sim N(5, 5.315)\\). To find the probability \\(P(M-F&lt;0)\\) we can use pdist. pdist(dist=&quot;norm&quot;, q=0, mean=5, sd=5.315) ## [1] 0.1734207 The chance that a female chosen at random is taller than a male chosen at random is 0.1734207. 16.13 Exercises 16.13.1 Exercise (Group Project) - Zombie Apocalypse It may not be the Zombie Apocalypse but we want to be ready just in case. There are Gender Alpha Zombies and Gender Beta Zombies. Different Zombies have different Power identified on a scale of 1 to 6 with 6 being the most powerful and 1 being not at all powerful, in fact, pathetic. When two Zombies meet they compare their Zombie Power Index (ZPI) to see who gets first dibs on that tender living human flesh. The highest ZPI wins. If you are an Alpha Zombie your ZPI comes from a single chromosome so you roll one die. For example, if an Alpha rolls a 2 that is their power. If you are a Beta Zombie your ZPI comes from two chromosomes so you roll two dice and find the average. If a Beta rolled a 3 and a 6 their ZPI is 4.5, the average of 3 and 6. Figure 16.11: Zombie Apocalypse Characters To get a feel for this game, play the game with friends or classmates at least 10 times recording results in the table provided on the hardcopy page distributed in class. Figure 16.12: Zombie Apocalypse Data Table Class Data: In class, examine a small sample of Alpha ZPIs and a small sample of Beta ZPI’s and make comparisons of shape, center, and spread. Simulating ZPI: Get a clearer picture of Alpha and Beta ZPIs by constructing a simulation using the sample() command. Analyze the simulated Alpha ZPIs and Beta ZPIs by constructing histograms and running summary statistics. How are they similar and how are they different in terms of shape, center, and spread? Theory: Construct the theoretical probability distributions for Alpha ZPIs and Beta ZPIs and find the expectation and the standard deviation. Conjecture: Assume you have a class of size 32 with equal numbers of Alphas and Betas. Consider a single-elimination tournament created with random seedings. Who is more likely to be eliminated in the first round - more Alphas eliminated or more Betas eliminated or no difference? Who is more likely to win, an Alpha or a Beta or equal chances? 16.13.2 Exercise - Dungeons and Dragons Dice In Dungeons and Dragons there are a number of different types of die including a traditional six-sided die and a 12-sided die. Figure 16.13: Dungeons and Dragons Dice Suppose the Dungeon Master says, “Ye are in a tavern to celebrate GrogFest, and it’s time to roll to see how many rounds of ale ye must buy. Thus, either roll the 12-sided die once or roll the six-sided die twice to find the total as these be equivalent in terms of shape, center, and spread.” Use knowledge gained from the chapter to critique the Dungeon Master’s reasoning for the results of tossing one 12-sided die compared with tossing a six-sided die twice. Regarding shape, center, and spread, how are they the same and how are they different? 16.13.3 Exercise - Difference of Wheels Suppose the wheel of fortune wheel with slots numbered 0 to 100 all equally likely is spun twice and rather than summing the two spins you win (or lose) the difference between the first spin and the second spin. Simulate this data, run summary statistics of the result, and create a histogram. How does theory help explain this result? 16.13.4 Exercise - Comparing Blood Pressure The chart below shows the mean and standard deviation for the blood pressure of individuals with normal blood pressure. If two individuals with normal blood pressure are chosen at random, what is the probability the male has the higher blood pressure? Figure 16.14: Normal and Pre/Hypertensive Blood Pressure by Sex Source: https://www.researchgate.net/figure/The-mean-and-standard-deviation-values-for-systolic-and-diastolic-blood-pressure-among_tbl5_232742829 "],["geometric_distribution.html", "Chapter 17 The Geometric Distribution 17.1 Introduction 17.2 Chapter Scenario - Lovin’ the Airport 17.3 Example - Waiting for Lucky Number 7 17.4 Exercises", " Chapter 17 The Geometric Distribution 17.1 Introduction We have learned about important discrete random variables such as the binomial and about important continuous random variables such as the normal. In this chapter we add to our repertoire the geometric random variable. 17.2 Chapter Scenario - Lovin’ the Airport Suppose a domestic flight leaves at 5:00pm and has 50 passengers who show up independently at the airport at uniformly random times between 3:15pm and 4:30pm. How many passengers can we expect to have arrived at the airport by 4:00pm, one hour before takeoff? How confident can we be in this answer? 17.3 Example - Waiting for Lucky Number 7 Suppose you are playing roulette betting on the single number seven and you are going to stay at the table until a seven occurs. How long should you expect to wait? How variable is the waiting time? If you follow this strategy, what is the probability you will leave a winner? An understanding of what is called a geometric random variable is helpful to answer these questions. Since the roulette wheel has 38 slots we know the probability of getting a seven is \\(1/38\\) and the probability of not getting a seven is \\(37/38\\). Letting S represent the event of getting a seven and N represent the event of not getting a seven we have \\(P(S)=1/38\\) and $P(N)=37/38. Using subscripts to keep track of the first, second, third spin and so on we can visualize the experiment of waiting for the first seven in a tree diagram. Figure 17.1: Tree Diagram - Waiting for Lucky Number 7 What we are really interested in is how long it takes to get our first number seven. To help us think about this distribution, let X count the number of rolls needed to get our first seven. Building up one step at a time we can find the probability X = 1, 2, 3, … and find the general pattern. We can calculate a few probabilities to get a feel. \\[P(\\text{get first 7 on first spin})=P(X=1)=\\frac{1}{38}\\] \\[P(\\text{get first 7 on second spin})=P(X=2)=\\frac{37}{38} \\cdot \\frac{1}{38}\\] \\[P(\\text{get first 7 on third spin})=P(X=3)=\\frac{37}{38} \\cdot \\frac{37}{38} \\cdot \\frac{1}{38}\\] In general, for the first seven to occur on the \\(x^{th}\\) spin, we need \\(x-1\\) failures and then success. Finding an expression to represent the probability that \\(x\\) spins are needed yields \\[P(X=x)=(\\frac{37}{38})^{x-1} \\cdot \\frac{1}{38}\\] In this situation, we have independent trials and the same probability of success on each trial and we are interested in how long it takes to get our first success. We call this situation a geometric random variable. 17.3.1 The Geometric Distribution Given independent trials with a constant probability of success, p, on each trial the number failures before the first success, X, is a geometric random variable, \\(X \\sim GEOM(p)\\), with probability density function \\[\\text{For all positive integers n}, P(X=x)=(1-p)^{x-1} \\cdot p\\] To determine the expected value of the geometric random variable requires an infinite sum and some calculus but we will examine it intuitively. When spinning the roulette wheel and counting the number of trials until our first seven occurs, this is a geometric random variable with probability of success \\(p=1/38\\), \\(X \\sim GEOM(1/38)\\). Getting the lucky number seven happens 1 out of every 38 spins on average so, intuitively, we anticpate the expected number of trials until our first success is 38. And we would be right. It turns out the expected number of trials for the first success is the reciprocal of the probability since \\(1/(1/38)=38\\). In general, for a geometric random variable X with probability of success p, the expectation, that is, the expected number of trials until the first success is \\(E(X)=1/p\\). The variance is \\(Var(X)=\\frac{1-p}{p^{2}}\\) and standard deviation \\(SD(X)=\\sqrt{\\frac{1-p}{p^{2}}}\\). 17.3.2 The Geometric Random Variable in R Assume we have a geometric random variable with probability of success parameter p. We can use R functions from the mosaic package but there is a wrinkle. These functions count the number of failures before the first success, not the total number of trials. Consequently, we need to adjust the input by adjusting by 1. It is a little tricky. To find the individual probability of x trials needed to obtain the first success, \\(P(X=x)\\), use dgeom(x-1, prob). To find the cumulative probability of less than or equal to x trials needed to obtain the first success, \\(P(X \\leq x)\\), use pgeom(q=x-1, prob=p, lower.tail = TRUE). To visualize the cumulative probability \\(P(X \\leq x)\\) use pdist(dist=\"geom\", prob=p, q=x-1). To find the inverse probability, that is the value of x such that \\(P(X \\leq x) = p\\) use qgeom(p, prob=p, lower.tail = TRUE)+1. To generate a random sample of size n from this geometric random variable use rgeom(n, prob=p)+1. For example, in waiting in roulette for our lucky number seven, the probability of getting a seven on any spin is \\(p=1/38\\) and, as we have seen, the number of rolls needed is a geometric random variable. To find the probability exactly 20 spins are needed: dgeom(x=19, prob=1/38) ## [1] 0.0158548 While the dgeom() command provides individual probabilities, one may input multiple values in a vector and see all of their individual probabilities. For example, the code below shows all the probabilities for X=1,2,3,…,20 by inputing the vector 0:19: dgeom(x=0:19, prob=1/38) ## [1] 0.02631579 0.02562327 0.02494897 0.02429242 0.02365315 0.02303069 ## [7] 0.02242462 0.02183450 0.02125991 0.02070044 0.02015569 0.01962528 ## [13] 0.01910882 0.01860596 0.01811633 0.01763958 0.01717538 0.01672340 ## [19] 0.01628331 0.01585480 Note the last value in the list, 0.0158548, matches the probability that exactly 20 spins are needed. To find the cumulative probability twenty or fewer rolls are needed: pgeom(q=19, prob=1/38, lower.tail = TRUE) ## [1] 0.4133723 To visualize the cumulative probability twenty or fewer rolls are needed: pdist(dist=&quot;geom&quot;, prob=1/38, q=19) ## [1] 0.4133723 To find the probability more than twenty rolls are needed we use the complement principle or change the lower.tail value: 1 - pgeom(q=19, prob=1/38, lower.tail = TRUE) ## [1] 0.5866277 pgeom(q=19, prob=1/38, lower.tail = FALSE) ## [1] 0.5866277 To find the number of trials needed to insure a 90% chance of obtaining a seven: qgeom(p=0.90, prob=1/38, lower.tail = TRUE)+1 ## [1] 87 To generate a random sample of 100 such experiments waiting for the first seven: rgeom(n=20, prob=1/38)+1 ## [1] 38 73 6 12 17 30 22 104 46 69 19 17 250 80 19 7 48 113 46 ## [20] 29 The important thing to remember is that these R commands count the number of failures before the first success instead of the total number of trials including the first success. 17.4 Exercises 17.4.1 Exercise - The Geometric Dice Game Two players, called Alpha and Beta, play against each other in what we’ll call the Geometric Dice Game. The players each choose a different number from 1 to 6. The die is then rolled until one of these two numbers comes up. The player whose number comes up first is the winner. Fun, huh! First, let’s think about each player’s chances. What is the probability Alpha will win? What is the probability Beta will win? Suppose we are interested in how long we would expect this game to go on. On average, how many rolls do you think are needed to resolve this game? What is the probability it will take five or more rolls to resolve this game? 17.4.2 Exercise - NBA Halfcourt Shot In the following web posting (http://apbr.org/metrics/viewtopic.php?f=2&amp;t=8167) it is claimed NBA players make 2.6% of shots beyond half court. Assuming this claim is true, on average how many shots would it take from beyond half court to make one? If an NBA player was ready to take a shot from beyond half court and a buddy offers you 20 to 1 odds on the player making it would this be a better bet for your buddy or for you? Explain. (Note, if the shot is made you win \\(\\$20\\) and if the shot is not made you lose \\(\\$1\\).) Figure 17.2: NBA Blog Posting 17.4.3 Exercise - The Chevalier de Mere Revisited In one of the games the Chevalier was interested, a die is tossed and the player has four chances to roll a six. If she does, she is a winner. If she doesn’t, she is a loser. Let geometric random variable X represent the number of rolls needed to roll a six. (a) Use the probability we found earlier when solving this game with the complement principle? (b) On average, how long does it take to roll a six? "],["hypergeometric_distribution.html", "Chapter 18 The Hypergeometric Distribution 18.1 Introduction 18.2 The Hypergeometric Random Variable 18.3 Exercises", " Chapter 18 The Hypergeometric Distribution 18.1 Introduction We have learned about important discrete random variables such as the binomial and about important continuous random variables such as the normal. In this chapter we add to our repertoire the hypergeometric discrete random variable. 18.2 The Hypergeometric Random Variable 18.2.1 Example - A Class Controversy A political science class has 12 liberal students and 8 conservative students. Four students are selected at random to organize a class debate on the presidential election. It so happens that three of the individuals are liberal and only one of the students is conservative. Some students cry foul. A relevant question is how likely is the committee to have such a composition. Which committee composition is more likely - a committee with two liberal and two conservative students or a committee with three liberal and one conservative? We can envision a class with 12 liberal students and 8 conservative students in an urn model. Imagine 20 balls in an urn that are otherwise identical except that 12 balls are white representing liberal students and 8 balls are black representing conservative students. Concerning the political leanings of four students selected at random from the class, drawing four balls without replacement from this urn is equivalent. Figure 18.1: Urn Model for Class Composition We can determine the probability of any particular committee composition. For example, to find the probability all four are liberal we note there are \\(\\binom{12}{4}\\) ways to select four liberals compared with \\(\\dbinom{20}{4}\\) ways total to select four committee members. \\[P(\\text{4 are liberal and 0 are conservative})=\\frac{\\dbinom{12}{4} \\cdot \\dbinom{8}{0}}{\\dbinom{20}{4}}=0.102\\] The number of ways to select three liberals and select one conservative is \\(\\dbinom{12}{3} \\cdot \\dbinom{8}{1}\\) yielding the following probability. \\[P(\\text{3 are liberal and 1 is conservative})=\\frac{\\dbinom{12}{3} \\cdot \\dbinom{8}{1}}{\\dbinom{20}{4}}=0.363\\] Following similar thinking, \\[P(\\text{2 are liberal and 2 are conservative})=\\frac{\\dbinom{12}{2} \\cdot \\dbinom{8}{2}}{\\dbinom{20}{4}}=0.381\\] \\[P(\\text{1 is liberal and 3 are conservative})=\\frac{\\dbinom{12}{1} \\cdot \\dbinom{8}{3}}{\\dbinom{20}{4}}=0.139\\] \\[P(\\text{0 are liberal and 4 are conservative})=\\frac{\\dbinom{12}{0} \\cdot \\dbinom{8}{4}}{\\dbinom{20}{4}}=0.014\\] Comparing these probabilities we see the probability of randomly selecting three liberals and one conservative is 0.363 while the probability of selecting two liberals and two conservatives is 0.381. While the second possibility has a slightly higher probability, they occur at very close to the same rate and it is not at all unusual for the committee to be composed of three liberals and one conservative. In fact, \\(13.9\\%\\) of the time the committee would consist of only one liberal and three conservatives. Situations similar to this which we can understand as equivalent to having an urn with two different color balls and selecting a random sample of them without replacement is called a hypergeometric distribution. 18.2.2 The Hypergeometric Distribution Drawing a sample without replacement from a population and counting the number of successes is modeled by the hypergeometric distribution. Such a situation can be conceived as drawing without replacement \\(k\\) balls from an urn containing \\(m\\) white balls and \\(n\\) black balls where the hypergeometric random variable \\(X \\sim HYP(m,n,k)\\) counts the number of white balls selected. The total number of balls we call \\(N\\) and \\(N=m+n\\). If \\(k\\) balls total are selected and \\(x\\) of them are white then \\(k-x\\) of them are black. \\(X\\) can take on values from \\(0\\) to the minimum of \\(k\\) and \\(m\\) and has the following probability distribution \\[P(X=x)=\\frac{\\dbinom{m}{x} \\cdot \\dbinom{n}{k-x}}{\\dbinom{m+n}{k}}\\] For a hypergeometric random variable, since the proportion of white balls is \\(m/N\\) and \\(k\\) are selected, the expectation of the number of white balls selected is \\(E(X)=(m \\cdot k)/N\\). The variance is \\(Var(X)=\\frac{N-k}{N-1} \\cdot n \\cdot p \\cdot (1-p)\\) and the standard deviation is the square root of the variance. Note, that when the sample is large, the hypergeometric distribution is approximated by a binomial distribution. 18.2.3 The Hypergeometric Random Variable in R We can use R to calculate probabilities for the hypergeometric random variable \\(X \\sim HYP(m,n,k)\\) representing the number of white balls drawn given the following parameters: m: the number of white balls in the urn n: the number of black balls in the urn k: the number of balls drawn without replacement To find the individual probability of x white balls, \\(P(X=x)\\), use dhyper(x, m, n, k). To find the cumulative probability of less than or equal to x successes, \\(P(X \\leq x)\\), use phyper(q=x, m, n, k, lower.tail = TRUE). To find the inverse probability, that is the value of x such that \\(P(X \\leq x) = p\\) use qhyper(p, m, n, k, lower.tail = TRUE). To generate a random sample of size nn from a poisson random variable use rhyper(nn, m, n, k). Illustrating these commands with the situation above we note the following: X: the number of liberal students selected (or white balls selected) m=12: the number of liberals in class (or white balls in urn) n=8: the number of conservatives in class (or black balls in urn) k=4: the number of students selected (or balls drawn without replacement) We describe the distribution of liberal students selected as \\(X \\sim HYP(12,8,4)\\). Here, we find the probability of three liberal students (and one conservative) being selected is 0.3632611: dhyper(x=3, m=12, n=8, k=4) ## [1] 0.3632611 Now, the probability of two liberal (and two conservative) students being selected is 0.3814241: dhyper(x=2, m=12, n=8, k=4) ## [1] 0.3814241 The probability of two or fewer liberal students being selected is 0.5345717: phyper(q=2, m=12, n=8, k=4, lower.tail = TRUE) ## [1] 0.5345717 The probability of more than two liberal students being selected can be found in different ways. First, using the complement principle: 1 - phyper(q=2, m=12, n=8, k=4, lower.tail = TRUE) ## [1] 0.4654283 Second, adding up separate individual probabilities: dhyper(x=3, m=12, n=8, k=4) + dhyper(x=4, m=12, n=8, k=4) ## [1] 0.4654283 Third, changing the command to pick up the upper tail of the distribution: phyper(q=2, m=12, n=8, k=4, lower.tail = FALSE) ## [1] 0.4654283 We see all three computations are equal showing that the probability of more than two liberal students being selected is 0.5345717. To find a particular quartile, such as the 50th percentile: qhyper(p=0.50, m=12, n=8, k=4, lower.tail = TRUE) ## [1] 2 We can conclude that at least 50% of the time, two or fewer liberal students will be selected. To generate a random sample of 10 such selections from this hypergeometric distribution: rhyper(nn=10, m=12, n=8, k=4) ## [1] 3 3 4 3 2 3 2 3 1 2 Drawing from an urn without selection is a model that usefully describes many real-world situations and the hypergeometric random variable captures the key features of this situation. 18.3 Exercises "],["poisson_distribution.html", "Chapter 19 The Poisson Distribution 19.1 Introduction 19.2 The Poisson Random Variable 19.3 Exercises", " Chapter 19 The Poisson Distribution 19.1 Introduction We have learned about important discrete random variables such as the binomial and about important continuous random variables such as the normal. In this chapter we add to our repertoire some other useful distributions including the geometric, negative binomial, and poisson discrete random variables and the uniform and exponential continuous random variables. 19.2 The Poisson Random Variable 19.2.1 The Poisson Distribution The Poisson distribution is often used to model real-world phenomena related to the number of certain events that occur over a specified period of time such as the number of math errors made in a typical math class, the number of text messages received during class, or even the chance of an earthquake occurring sometime this semester. A discrete random variable X is said to have a Poisson distribution with parameter \\(\\lambda&gt;0\\), if, for \\(k=0,1,2,...\\), is denoted as \\(X \\sim POI(\\lambda)\\) with the probability mass function of X given by \\[P(X=k)=\\frac{\\lambda^{k}*e^{-\\lambda}}{k!}\\] This formula would determine the probability of \\(k\\) events occurring. The expected value for a Poisson random variable with parameter \\(\\lambda\\) is \\(E(X)=\\lambda\\), the variance is also \\(Var(X)=\\lambda\\), and the standard deviation is \\(SD(X)=\\sqrt{\\lambda}\\). 19.2.2 The Poisson Random Variable in R Assume we have a Poisson random variable with parameter \\(\\lambda\\). We often determine \\(\\lambda\\) by finding the sample mean from data since the expectation of a Poisson is \\(\\lambda\\). To find the individual probability of x occurrences, \\(P(X=x)\\), use dpois(x, lambda). To find the cumulative probability of less than or equal to x successes, \\(P(X \\leq x)\\), use ppois(q, lambda, lower.tail = TRUE). To visualize the cumulative probability \\(P(X \\leq x)\\) use pdist(dist=\"pois\", lambda, q=x). To find the inverse probability, that is the value of x such that \\(P(X \\leq x) = p\\) use qpois(p, lambda, lower.tail = TRUE). To generate a random sample of size n from a poisson random variable use rpois(n, lambda). 19.2.3 Modeling Number of Earthquakes with the Poisson Consider how the Poisson can be used to model different phenomena. One key is that the parameter \\(\\lambda\\) equals the expected value. Thus, if you know the expected value you can use this value for \\(\\lambda\\) to find probabilities. Here we apply this technique to examine earthquake frequency along the Wasatch Front. The earthquake frequency table below is from the University of Utah Seismic Station’s website - http://www.seis.utah.edu/edservices/EES/WsatchFrontClock.shtml. Suppose that we make the simplifying assumption that the number of earthquakes of a given magnitude that occur in a given time period is a Poisson distribution and that the estimate of the recurrence interval can be used to determine the parameter . Suppose that we are interested in the occurrence of earthquakes of magnitude greater than 3.0 during a two-semester period of 8 months. Since the estimate of the recurrence interval is 4 months we would expect approximately two earthquakes in eight months thus we would model the number of earthquakes, X, as a Poisson with parameter \\(\\lambda=2\\), \\(X \\sim POI(2)\\). To find the probability of 0 earthquakes in a two-semester period: dpois(x=0,lambda=2) ## [1] 0.1353353 To find the probability of 1 earthquake in a two-semester period: dpois(x=1, lambda=2) ## [1] 0.2706706 For cumulative probabilities of 2 or fewer earthquakes in a two-semester period: ppois(q=2, lambda=2) ## [1] 0.6766764 Using the complement principle we can find the probability of more than 2 earthquakes in a two-semester period: 1 - ppois(q=2, lambda=2) ## [1] 0.3233236 The ‘mosaic’ package in R creates fantastic visualizations of probability distributions. Examine the code below showing the probability of two or fewer earthquakes. pdist(&quot;pois&quot;, q=2, lambda=2) ## [1] 0.6766764 Thus, there is a 67.6676416 percent chance of two or fewer earthquakes in a two-semester period. To find the 90th percentile: qdist(&quot;pois&quot;, p=0.9, lambda=2) ## [1] 4 Thus, we can say that according to our model, there is a 90% chance of 4 or fewer earthquakes in a given two-semester period. 19.3 Exercises 19.3.1 Exercise - Counting Earthquakes Earthquakes of magnitude greater than 3.0 along the Wasatch front occur on average every four months. Considering a two-semester period of 8 months we expect approximately two earthquakes and can model the number of earthquakes as a poisson distribution with parameter \\(\\lambda=2\\). (a) Determine the probability of three or fewer earthquakes of magnitude greater than 3.0 in the next 8 months and llustrate this probability with a plot of the probability distribution. (b) Find the 75th percentile for the number of earthquakes of magnitude greater than 3.0 in the next 8 months and illustrate the 75th percentile with a plot of the probability distribution. (c) If we were to explore the number of earthquakes of magnitude greater than 3.0 in the next two-year period instead of the next 8 months explain what value for \\(\\lambda\\) would be appropriate in a Poisson model. 19.3.2 Exercise - Growth Mindset and Math Errors Psychologist Carol Dweck, in her book Mindset: The New Psychology of Success, advocated that students focus on the learning process to develop their intelligence rather than to think intelligence is fixed. In math this might mean we need to embrace making mistakes as mistakes provide the main context for exploring effective and ineffective approaches to a problem. Suppose that in an active and engaged college math class, an average of 8 math mistakes are made on the whiteboard per class session. Use a Poisson model to find the following. (a) What is the probability that in an active and engaged math class there will be 0 math mistakes made on the whiteboard in a class session? (b) Is it more likely that there will be fewer than 8 or more than 8 math mistakes made on the whiteboard in a class session? (c) One particularly productive session had 10 great mistakes from which to learn. What is the probability of 10 or more mistakes on the whiteboard in a class session? "],["multinomial_distribution.html", "Chapter 20 Multinomial Distribution 20.1 Chapter Scenario - 3D Ant Walking 20.2 Chapter Scenario Revisited - 3D Ant Walking 20.3 Example - Hair Color", " Chapter 20 Multinomial Distribution 20.1 Chapter Scenario - 3D Ant Walking Recall the ways can a person walk from corner X to another corner by a path of shortest length is \\(\\dbinom{n}{r}\\) where n is the total number of blocks walked and r is the number of East blocks. If E is the number of blocks East and S is the blocks south then \\(\\dbinom{L+R}{L}\\) or \\(\\dbinom{L+R}{R}\\) nicely names the number of paths. We now consider a similar three-dimensional structure called a lattice. How many ways are there for an ant to walk from one diagonal corner to the other in a path of shortest length for the situation pictured below? Figure 20.1: 3D Ant-walking Grid 20.2 Chapter Scenario Revisited - 3D Ant Walking 20.2.1 A Simpler Example How many ways are there for an ant to walk from one diagonal corner to the other in a path of shortest length for the simpler situation pictured below? Figure 20.2: Simpler Ant-walking Grid The example is small enough we could illustrate the solutions. Turns out there are six of them. Figure 20.3: Simpler Ant-walking Grid Solutions We can translate this ant-walking problem into a different context by labeling the directions the ant may walk. In addition to moving Left (L) or Right (R) the ant may travel Down (D). Figure 20.4: Simpler Ant-walking Grid with Labels In moving from the top corner to the diagonally opposite bottom corner we recognize the ant make make one Left move, one Right move, and one Down move and the different paths can be described as the different orderings of one L, one R, and one D as written below. Figure 20.5: Simpler Ant-walking Grid Solutions with Orderings 20.2.2 The Original Problem In the 2 x 2 x 2 grid the ant must travel two blocks to the left, two to the right, and two down. A particular path can be represented as a sequence of two L’s, two R’s, and two D’s. This can be done a total of \\(\\frac{6!}{2! \\cdot 2! \\cdot 2!}\\) ways. 20.2.3 General 3D Lattice Situation We may describe the general situation in a 3-D lattice with width W units, length L units, and height H units. How many paths are there from one corner to the diagonally opposite corner? This would be equivalent to the number of orderings of so many W’s, L’s, and H’s resulting in \\(\\frac{(W+L+H)!}{W! \\cdot L! \\cdot H!}\\) unique paths. 20.3 Example - Hair Color According to one source, \\(84\\%\\) of the world has black hair, \\(11\\%\\) has brown hair, \\(3\\%\\) has blond hair, and \\(2\\%\\) has red hair. Of course, various combinations of these account for more descriptive names - strawberry blond, etc. Suppose 50 individuals were selected at random. Because the human population of the earth is so large and our sample so small, we could use an urn model with replacement to help us think about this probability experiment. Consider an urn with \\(84\\%\\) black beads, \\(11\\%\\) brown beads, \\(3\\%\\) blond beads, and \\(2\\%\\) red beads. Draw 50 beads at random from this urn with replacement. Figure 20.6: Urn Model for Hair Color The distribution of hair color would have a multinomial probability distribution. Source: https://infogram.com/most-common-hair-color-1gjk92e414wvp16 "],["uniform_distribution.html", "Chapter 21 The Uniform Distribution 21.1 Introduction 21.2 Chapter Scenario - Lovin’ the Airport 21.3 The Uniform Distribution 21.4 Chapter Scenario Revisited - Lovin’ the Airport 21.5 Exercises", " Chapter 21 The Uniform Distribution 21.1 Introduction We have learned about important discrete random variables such as the binomial and about important continuous random variables such as the normal. In this chapter we add to our repertoire some other useful distributions including the geometric, negative binomial, and poisson discrete random variables and the uniform and exponential continuous random variables. 21.2 Chapter Scenario - Lovin’ the Airport Suppose a domestic flight leaves at 5:00pm and has 50 passengers who show up independently at the airport at uniformly random times between 3:15pm and 4:30pm. How many passengers can we expect to have arrived at the airport by 4:00pm, one hour before takeoff? How confident can we be in this answer? 21.3 The Uniform Distribution The uniform random variable is a continuous random variable that is equally likely along its entire range of possible values. Like the normal distribution, the area under the curve between two values is the probability of the random variable being in the interval but unlike the normal bell-shaped curve, the uniform probability density function is a flat, horizontal line. If the uniform random variable X ranges from a minimum of \\(a\\) to a maximum of \\(b\\), we abbreviate this \\(X \\sim UNIF(a,b)\\). 21.3.1 The Uniform Probability Density Function The uniform probability density function is flat and the area under the curve equals the probability. For X, a uniformly distributed random variable with a minimum of a and a maximum of b, \\(X \\sim UNIF(a,b)\\), so that the total area under the curve is 1, the height of the curve must be \\(1/(b-a)\\) between a and b and 0 elsewhere. The code below creates a function to plot different uniform random variables uniform_Plot &lt;- function(a, b){ xvals &lt;- data.frame(x = c(a, b)) #Range for x-values ggplot(data.frame(x = xvals),aes(x = x)) + xlim(c(a, b)) + ylim(0, 1/(b - a)) + stat_function(fun=dunif, args=list(min=a, max=b), geom = &quot;area&quot;, fill=&quot;green&quot;, alpha=0.35) + stat_function(fun = dunif, args = list(min = a, max = b)) + labs(x=&quot;\\n u&quot;, y=&quot;f(u) \\n&quot;, title=paste0(&quot;Uniform Distribution \\n With Min = &quot;, a, &quot; &amp; Max = &quot;, b, &quot; \\n&quot;)) + theme(plot.title=element_text(hjust = 0.5), axis.title.x=element_text(face=&quot;bold&quot;, color=&quot;blue&quot;, size=12), axis.title.y=element_text(face=&quot;bold&quot;, color=&quot;blue&quot;, size=12)) + geom_vline(xintercept=a, linetype=&quot;dashed&quot;, color=&quot;red&quot;) + geom_vline(xintercept=b, linetype=&quot;dashed&quot;, color=&quot;red&quot;) } Source: http://dkmathstats.com/plotting-uniform-distributions-in-r-with-ggplot2/ Here is the plot of UNIF(4,12). uniform_Plot(4,12) For uniform random variable \\(X \\sim UNIF(a,b)\\), the expectation is \\(E(X)=\\frac{a+b}{2}\\) and the variance is \\(Var(X)=\\frac{(b-a)^{2}}{12}\\) and standard deviation \\(SD(X)=\\sqrt{\\frac{(b-a)^{2}}{12}}\\). 21.3.2 The Uniform Random Variable in R For X a uniform random variable we use the following. Since by default min=0 and max=1, for X that is uniformly distributed between a and b, \\(X \\sim UNIF(a,b)\\), we must replace 0 and 1 by a and b, respectively. To find the probability of X being less than q, \\(P(X &lt; q)\\), use punif(q, min = 0, max = 1, lower.tail = TRUE). To find the probability of X being greater than q, \\(P(X &gt; q)\\), use punif(q, min = 0, max = 1, lower.tail = FALSE) or 1-punif(q, min = 0, max = 1, lower.tail = TRUE). To find the inverse probability, that is the value of x such that \\(P(X \\leq x) = p\\) use qunif(p, min = 0, max = 1, lower.tail = TRUE). To generate a random sample of size n from a uniform random variable use runif(n, min = 0, max = 1). 21.3.3 Example - The UNIF(0,1) Random Variable The basis for most random number generator schemes is a uniform random variable X with a minimum of 0 and a maximum of 1, \\(X \\sim UNIF(0,1)\\). The probability density function is visualized below. uniform_Plot(0,1) Because the default min=0 and max=1 we could leave these parameters out when using punif(), qunif(), or runif(). For example, we can use runif(n) to generate a sample of size n. Here is a sample of twenty random UNIF(0,1): runif(n=20) ## [1] 0.33615347 0.46372327 0.06058539 0.19743361 0.47431419 0.30104860 ## [7] 0.60675886 0.13001210 0.95865471 0.54684949 0.39561597 0.66453861 ## [13] 0.98211229 0.67821539 0.80602781 0.63417988 0.27073646 0.55290413 ## [19] 0.73795568 0.82840038 Variations on UNIF(0,1) is how other random numbers are generated. Watch what happens when we multiply runif(n=20) by 4. 4*runif(n=20) ## [1] 1.0404032 2.2734415 0.6059931 0.3797474 3.0476664 2.1437142 1.3115237 ## [8] 3.6974241 2.3932470 0.2585466 0.5654715 3.4503960 0.1353209 1.9608193 ## [15] 2.0247205 3.0481376 0.1842237 0.2086938 2.3240237 0.7005295 In this case, we stretched the range so that the values are now UNIF(0,4). Suppose in addition to stretching by a factor of 4 we subtract 2. 4*runif(n=20) - 2 ## [1] 1.58744205 1.09188645 0.39513140 0.39698649 0.40748783 -1.98852087 ## [7] 1.85165059 -1.72359197 -1.55484713 1.09709086 -0.37952902 -1.16007461 ## [13] -1.42049234 1.05396454 0.65016560 1.86619209 -0.42715126 0.41739040 ## [19] -0.94499729 -0.04212705 This generates random uniform numbers UNIF(-2,2). And if we had added 2 instead: 4*runif(n=20) + 2 ## [1] 3.638652 3.402199 5.522949 2.457047 3.580058 2.035257 4.805197 4.583177 ## [9] 2.153902 4.163981 3.248564 2.912225 5.683229 2.258957 2.564514 3.941337 ## [17] 4.460030 3.103937 3.672544 2.375969 Now we are generating random uniform numbers UNIF(2,6). Of course, we could generate all of these directly using runif(0,4), runif(-2,2), and runif(2,6) but now we know a little more about how R does it under the hood. 21.3.4 Example - Catch a Flight Suppose that the time check in at the airport for a 5:00pm flight is uniformly distributed from 3:15pm to 4:30pm. If we let X represent the amount of time in minutes after 3:15pm that a person shows up then \\(X \\sim UNIF(0,75)\\). To find the probability a person chosen at random shows up before 4:15pm: punif(60, min = 0, max = 75, lower.tail = TRUE) ## [1] 0.8 To find the probability a person chosen at random shows up after 4:15pm we have options: 1-punif(60, min = 0, max = 75, lower.tail = TRUE) ## [1] 0.2 punif(60, min = 0, max = 75, lower.tail = FALSE) ## [1] 0.2 To find the 66th percentile, that is the amount of time after 3:15pm that \\(66\\%\\) of people show up: qunif(0.66, min = 0, max = 75, lower.tail = TRUE) ## [1] 49.5 As a time, this would translate into 3:15pm plus 49.5 minutes which would be 4:04:30pm. To generate a random sample of 50 passengers and the number of minutes after 3:15pm that they show up: runif(n=50, min = 0, max = 75) ## [1] 26.972408 55.429884 7.265998 29.899550 14.413928 68.177214 64.060610 ## [8] 7.276282 33.068926 23.091668 63.425941 11.603131 17.645577 74.495657 ## [15] 16.354141 57.054788 20.117461 23.867858 70.933170 71.377694 20.883991 ## [22] 26.735208 22.420707 30.888983 54.331459 24.139597 7.635658 17.286533 ## [29] 31.518733 45.225700 50.675503 5.745529 13.120406 46.839767 74.761282 ## [36] 29.505624 47.667820 49.922151 19.637350 30.995056 59.864449 29.439025 ## [43] 54.155770 29.243570 42.564885 31.680140 24.824509 48.783081 35.102692 ## [50] 55.207681 Doesn’t this give you a feeling of power? It would be easy for this go to our head. 21.4 Chapter Scenario Revisited - Lovin’ the Airport Recall, a domestic flight leaves at 5:00pm, has 50 passengers who show up independently at uniformly random times between 3:15pm and 4:30pm and we want to know how many passengers we can expect to have arrived by 4:00pm and how confident can we be in this answer? As we have seen, the time in minutes after 3:15pm that a passenger arrives can be modeled with a uniform random variable, \\(X \\sim UNIF(0,75)\\). The probability an individual passenger chosen at random will have arrived by 4:00pm is punif(45, min = 0, max = 75, lower.tail = TRUE) ## [1] 0.6 We have 50 passengers and the probability any one of them arrives by 4:00pm is 0.6. The total number of passengers who have arrived by 4:00pm is thus like a binomial random variable with n=50 and p=0.6. The expected number of passengers to have arrived is 30 but this could vary. Check out this distribution: xpbinom(20:40, size = 50, prob = 45/75) ## [1] 0.003360382 0.007617426 0.016034764 0.031405553 0.057343761 0.097807364 ## [7] 0.156168331 0.233982953 0.329861684 0.438965068 0.553523621 0.664386736 ## [13] 0.763124199 0.843909395 0.904498293 0.946044965 0.972011635 0.986749475 ## [19] 0.994312314 0.997802855 0.999242703 While we expect around 30 there is only an 11.4558553 \\(\\%\\) chance of exactly 30. This kind of knowledge could help us know how to more effectively manage airport traffic. 21.5 Exercises 21.5.1 Exercise - Transforming UNIF(0,1) Describe a transformation on runif(0,1) that generates uniform random numbers with a min=0 and max=3. Describe a transformation on runif(0,1) that generates uniform random numbers with a min=-3 and max=3. Describe a transformation on runif(0,1) that generates uniform random numbers with a min=4 and max=12. 21.5.2 Exercise - Showing Up for Class Suppose that in a class of 20 students that begins at 2:00pm, the time each student shows up is independent of other students and is uniformly distributed from 1:55pm to 2:10pm. (a) What is the probability a student chosen at random will arrive on time? (b) At what time can we be 90% certain a student chosen at random has arrived? (c) What is the probability student A shows up before student B? (d) What is the probability that a majority of students will show up on time? "],["exponential_distribution.html", "Chapter 22 The Exponential Distribution 22.1 Introduction 22.2 The Exponential Distribution 22.3 Exercises", " Chapter 22 The Exponential Distribution 22.1 Introduction We have learned about important discrete random variables such as the binomial and about important continuous random variables such as the normal. In this chapter we add to our repertoire some other useful distributions including the geometric, negative binomial, and poisson discrete random variables and the uniform and exponential continuous random variables. 22.2 The Exponential Distribution Recall, the Poisson distribution is models the number of events that occur over a specified period of time. A related variable of interest is the time we need to wait for the next event. In a real-world situation, if the number of events in a certain period of time - be it math errors in class, earthquakes in a school year, etc. - then the time until the next occurrence can be modeled with the continuous random variable called the exponential distribution. 22.2.1 The Exponential Probability Density Function If the average rate of an event is \\(\\lambda\\) occurrences per period of time then wait time until the next occurrence can be modeled with an exponential random variable \\(T \\sim (\\lambda)\\) with probability density function \\[f(t)=\\lambda \\cdot c^{\\lambda \\cdot t}\\] for \\(t &gt; 0\\). Using base graphics, here is the probability density function for an exponential random variable with \\(\\lambda=2\\). curve(dexp(x, rate=2), from=0, to=10) The expected value of an exponential random variable is \\(1/\\lambda\\) and the variance is \\(2/\\lambda^{2}\\), and standard deviation \\(\\sqrt{2/\\lambda^{2}}\\). The exponential random variable can be shown to be memoryless, meaning that if a certain amount of time has passed without an occurrence this doesn’t change the expected amount of time we still need to wait. 22.2.2 The Exponential Random Variable in R Given exponential random variable T with parameter \\(\\lambda\\) To find the probability of T being less than q, \\(P(T &lt; q)\\), use pexp(q, rate=lambda, lower.tail=TRUE). To find the probability of X being greater than q, \\(P(X &gt; q)\\), use pexp(q, rate=lambda, lower.tail = FALSE) or 1-pexp(q, rate=lambda, lower.tail = TRUE). To find the inverse probability, that is the value of x such that \\(P(T \\leq x) = p\\) use qexp(p, rate=lambda, lower.tail = TRUE). To generate a random sample of size n from a uniform random variable use rexp(n, rate=lambda). 22.2.3 Example - Soccer Wait Times The average number of soccer goals per game in the 2014 World Cup in Brazil was 2.7 meaning the goal rate was \\(2.7/90=0.03\\) goals per minute. To model the time in minutes until the next goal occurs in a soccer match we can use the exponential random variable T with \\(\\lambda=0.03\\). The expected value or average time until the next goal is \\(1/\\lambda=1/0.03=33.33\\) minutes. What is the chance there will be a goal in the next 15 minutes? We want to find \\(P(T &lt; 15)\\). pexp(15, rate=.03, lower.tail=TRUE) ## [1] 0.3623718 According to our model, there is a 36.2371848 \\(\\%\\) chance of a goal in the next 15 minutes. What are the chances there will be no goal in the next game is \\(P(T &gt; 90)\\)? 1-pexp(90, rate=.03, lower.tail=TRUE) ## [1] 0.06720551 Thus, the chance of no goal for the entire game is 0.0672055, a small probability but not that unusual. 22.2.4 Example - The Computer Help Desk According to the latest stats, Westminster’s computer help desk receives about 20 calls per 8 hour shift for a rate of \\(20/8=2.5\\) calls per hour. The time T in hours until the next support call can be modeled with an exponential function with parameter \\(\\lambda=2.5\\). The average time until the next call is \\(1/2.5=0.4\\) hours or 24 minutes. What is the probability the next call will occur sometime between 30 and 60 minutes from now. To find this probability, we need to find \\(P(T &lt; 60)\\) and subtract off the unwanted region, \\(P(T &lt; 30)\\). pexp(60, rate=2.5, lower.tail=TRUE) - pexp(30, rate=2.5, lower.tail=TRUE) ## [1] 0 The probability of a wait of between 30 and 60 minutes is 0. Do you think I have time to run down to 7-11? 22.3 Exercises 22.3.1 Exercise - Waiting on that Earthquake Earthquakes of magnitude greater than 3.0 along the Wasatch front occur on average every four months. Considering a two-semester period of 8 months we expect approximately two earthquakes. While we can model the number of earthquakes per school year as a poisson distribution with parameter \\(\\lambda=2\\), this might be an unusual time period to use to model the waiting time until the next one. If we used months as our unit of time, what value of the parameter \\(\\lambda\\) would we use to model the time until the next earthquake of magnitude greater than 3.0? What would be the probability we would wait three or more months for the next earthquake of magnitude greater than 3.0? 22.3.2 Exercise - NHL Hockey Goals During the 2017-2018 season, the home team scored on average 2.97 goals. Hockey games consist of three 20 minute periods so each game is 60 minutes. Model the time until the next goal with an exponential random variable. Find the probability that in one period, 20 minutes, there will not be a goal. Find the probability that the next goal will occur between 10 and 20 minutes from now. Source: hockey-reference.com "],["monte_carlo_simulation.html", "Chapter 23 Monte Carlo Simulation 23.1 Introduction 23.2 Chapter Scenario - Random Darts 23.3 About Random Number Generators 23.4 Chapter Scenario Revisited - Random Darts 23.5 Example - The Holey Cube 23.6 Simulating The Cube 23.7 Exercises", " Chapter 23 Monte Carlo Simulation 23.1 Introduction Simulation can give you (apparent) superpowers! It does this by leveraging experience. Rather than spend all day flipping coins (and developing rare condition of flipper’s thumbitis) we run a simulation. Financial analysts, meteorologists, astronauts, and geneticists also use simulation to test out their theories and models. In this chapter we look at random number generation in R and introduce the Monte Carlo simulation method. 23.2 Chapter Scenario - Random Darts The standard dart board is known as the clock board and has an 18 inch diameter, that is, a 9 inch radius. Suppose that a bunch of darts are thrown and hit the board at random locations. What do you think the average distance from the center is? Would the average distance from the center be closest to 0, 1, 3, 4.5, 6, 8, or 9 inches? 23.3 About Random Number Generators The runif(n,min=0,max=1) command with default minimum of 0 and maximum of 1 generates n random numbers between 0 and 1 from a uniform or flat distribution where the number is as likely to be any one section as in any other equally sized section. If we take a look at 1000 of these numbers and plot in a histogram we can see their distribution which should be approximately uniform or flat. sim &lt;- runif(n=1000) sim_df &lt;- data.frame(sim) ggplot(data=sim_df, aes(x=sim))+geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. It looks a little like the New York skyline at night and not perfectly uniform because random samples vary. The min and max parameters can be adjusted. For example, if at a particular intersection (choose your least favorite) the traffic light had a three minute long red light and we assume cars show up at the red light at random we could model the wait time of 1000 cars with runif(n=1000, min=0, max=3). We can model random points in the plane by using runif() to select the x and y coordinates. For example, given the region in the xy-coordinate plane with x between -1 and 1 and y between -1 and 1, we can choose 1000 points at random in this region. x &lt;- runif(n=1000, min=-1, max=1) y &lt;- runif(n=1000, min=-1, max=1) plane &lt;- data.frame(x,y) ggplot(data=plane, aes(x=x, y=y)) + geom_point() We might think we see patterns but this is what random points look like. 23.4 Chapter Scenario Revisited - Random Darts Darts are thrown at random and hit a round 18 inch diameter dart board. To estimate the average distance from the center we can generate a number of random points in a region representing the dart board, determine each point’s distance from the center, and find the average of these distances. Let’s start by generating points in a square region of the plane with x and y both between -9 and 9. x &lt;- runif(n=1000, min=-9, max=9) y &lt;- runif(n=1000, min=-9, max=9) plane &lt;- data.frame(x,y) ggplot(data=plane, aes(x=x, y=y)) + geom_point() + coord_fixed(ratio = 1) We need to select only these points that would be on a circular dartboard of radius 9. The equation of a circle of radius 9 centered at the origin is \\(x^{2}+y^{2}=9^{2}\\) and the interior of the circle is all points such that \\(x^{2}+y^{2} &lt; 9^{2}\\) and we can select all of these rows from the dataframe plane and call it dartboard. dartboard &lt;- plane[plane$x^2+plane$y^2 &lt; 81,] ggplot(data=dartboard, aes(x=x, y=y)) + geom_point() + coord_fixed(ratio = 1) Nice, random darts! Now we can create a new variable distance using the Pythagorean Theorem distance formula. dartboard$distance &lt;- sqrt(dartboard$x^2 + dartboard$y^2) head(dartboard) ## x y distance ## 1 2.6812408 5.5383754 6.153264 ## 2 -8.0089604 0.8604449 8.055049 ## 3 -6.6708524 -1.8723648 6.928638 ## 4 -3.4267511 0.4348523 3.454232 ## 6 4.3905381 -3.8079460 5.811822 ## 8 0.7586528 -3.6448880 3.723005 We can visualize these distances. ggplot(data=dartboard, aes(x=distance)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Running summary statistics. favstats(dartboard$distance) ## min Q1 median Q3 max mean sd n missing ## 0.03082102 4.328436 6.226172 7.764374 8.973836 5.903155 2.161193 791 0 We see the mean distance is 5.90 inches, close to 6 inches, about 2/3 of the radius. The median is a little bigger at 6.23 inches, consistent with a negatively skewed distance data. 23.5 Example - The Holey Cube Monte Carlo Simulation is the data equivalent of throwing a large number of random darts towards a target to estimate to estimate a proportion of successes. Here is our challenge: Imagine a cube with sides all of length four centimeters which has cylindrical holes bored out from the center of each face clear through the cube where each cylinder has a diameter of three centimeters. Check out the picture below. Since the volume of the resulting solid cannot be determined using the analytical methods of calculus, we use the Monte Carlo method to estimate the volume of the resulting solid. Figure 23.1: The Holey Cube 23.6 Simulating The Cube Assume the cube has its center of mass on the origin of a three dimensional coordinate system. We simulate 10000 (x,y,z) points in the cube using the runif and matrix commands. x &lt;- runif(n=10000, min=-2, max=2) y &lt;- runif(n=10000, min=-2, max=2) z &lt;- runif(n=10000, min=-2, max=2) points &lt;- data.frame(x,y,z) head(points) ## x y z ## 1 1.4355842 -0.2838091 -1.1370572 ## 2 -0.5899566 -1.3507116 -1.8302157 ## 3 -1.3021451 -1.2234585 -0.7298637 ## 4 -0.6323716 1.2106794 -1.1077620 ## 5 -0.6940108 -1.1407666 -1.5994467 ## 6 -0.8499943 -0.6788638 0.8158404 Points not in the drilled out cylinders are now identified as ones not in either of the three circles. The circle in the xy-plane is \\(x^{2}+y^{2}=1\\), the circle in the xz-plane is \\(x^{2}+z^{2}=1\\) and the circle in the yz-plane is \\(y^{2}+z^{2}=1\\). By replacing equality with &gt; we identify points not in the removed circles with the and logical connective. points$holey_cube &lt;- points$x^2+points$y^2&gt;1 &amp; points$x^2+points$z^2&gt;1 &amp; points$y^2+points$z^2&gt;1 head(points, n=10) ## x y z holey_cube ## 1 1.4355842 -0.2838091 -1.1370572 TRUE ## 2 -0.5899566 -1.3507116 -1.8302157 TRUE ## 3 -1.3021451 -1.2234585 -0.7298637 TRUE ## 4 -0.6323716 1.2106794 -1.1077620 TRUE ## 5 -0.6940108 -1.1407666 -1.5994467 TRUE ## 6 -0.8499943 -0.6788638 0.8158404 TRUE ## 7 -0.6286035 1.6807813 1.2995039 TRUE ## 8 0.5442574 -0.6559936 -0.8069817 FALSE ## 9 -0.5487874 0.6407869 1.6537750 FALSE ## 10 -0.6023055 -0.4900964 0.5878563 FALSE Since points is a logical variable with \\(1=TRUE\\) we can sum the points variable to see how many and what proportion of the 10,000 points are left. sum(points$holey_cube) ## [1] 5891 In our simulation, 5891 of the 10000 points still remain after the holes are drilled, or 58.91 \\(\\%\\) of the points. prob_holey_cube &lt;- sum(points$holey_cube)/10000 prob_holey_cube ## [1] 0.5891 Since the original cube was of volume \\(4^{3}=64\\) cubic centimeters the remaining volume is 58.91 percent of 64. volume &lt;- prob_holey_cube * 64 volume ## [1] 37.7024 The holey cube has a volume of 37.7024 cubic centimeters. 23.7 Exercises 23.7.1 Exercise - City Grid In 1877, Lewis Haupt, Professor of Civic Engineering at the University of Pennsylvania, laid out his ideas for urban planning including the street design below. Figure 23.2: Haupt Urban Planning Model If the city grid was one mile square mile, use the Monte Carlo method to determine the average distance from the center. Sources: http://urbanplanning.library.cornell.edu/DOCS/haupt_77.htm http://urbanplanning.library.cornell.edu/DOCS/haupt_95.htm#hauptbio 23.7.2 Exercise - A Big Bead Imagine a bead with a cylindrical hole drilled out of it. If the bead was a sphere of diameter 12 inches and the hole was a cylinder of diameter 3 inches, how much of the sphere was removed and how much was left? "],["case_study_roulette.html", "Chapter 24 Case Study - Roulette 24.1 Chapter Scenario - Conservative or Playa? 24.2 The Rules of Roulette 24.3 Analyzing the Even-Money Bets 24.4 Roulette Simulation 24.5 Analyzing the Single Number Bet 24.6 Exercises", " Chapter 24 Case Study - Roulette 24.1 Chapter Scenario - Conservative or Playa? Suppose that you have $100 to make one bet. Would you make an even money bet, like a bet on red that pays 1 to 1 or a single number bet, say on the lucky number 7, that pays off at 35 to 1 if a seven comes up? Discuss which bet appeals most to you and why. 24.2 The Rules of Roulette To play roulette you place a bet and spin the wheel. If the wheel matches your bet you win; if not, you lose. Remember that a roulette wheel contains slots numbered 1 through 36, half of them red, half black and green 0 and 00 slots. Figure 24.1: American Roulette Wheel The table layout allows a number of different bets Figure 24.2: American Roulette Layout and payout schedule are below. For fun, view a simulation of roulette at http://www.flash-game.net/game/534/flash-roulette.html Note that European roulette as played in Monte Carlo only has the green zero and not the green double zero and thus the probabilities and expectations are different. There are also some minor differences in the rules. See the exercise at the end of the chapter. The payoff odds vary depending on your bet. The harder it is to win your bet, the greater the payoff odds. The payoff odds are shown in the table Figure 24.3: Roulette Payoff Odds Each player at the table will have different color chips and may make several bets at once by placing their chips in the right location as shown below. Figure 24.4: Roulette Bet Positions 24.3 Analyzing the Even-Money Bets First, examine an even money bet, such as a \\(\\$100\\) bet on Red. The payout for Red bet is 1 to 1 meaning if you win you win \\(\\$1\\) for every \\(\\$1\\) bet. The probability distribution describing this bet is as follows. Since there are 18 red slots on the wheel the probability of winning a red bet is 18/38 while the probability of winning a single number bet is 1/38. If we let X represent the winnings the list of all the possible outcomes matched with their associated probabilities P(X) is called the probability distribution. Figure 24.5: Roulette Even Money Disribution The sum of the X*P(X) is - 5.26 thus the expected payoff for a $100 bet on Red is to lose about five dollars and a quarter. 24.4 Roulette Simulation Considering a \\(\\$100\\) even-money roulette bet, such as a red bet, we can simulate a large number of trials noting the two outcomes or \\(-\\$100\\) or \\(+\\$100\\) with probabilities \\(20/38\\) and \\(18/38\\), respectively. red_bet &lt;- sample(x=c(-100,100), prob=c(20/38,18/38),size=10000, replace = TRUE) red_bet_df &lt;- data.frame(red_bet) head(red_bet) ## [1] -100 -100 -100 -100 -100 -100 We can examine the histogram. ggplot(data=red_bet_df, aes(x=red_bet)) + geom_histogram(aes(y=..density..), binwidth = 10) Figure 24.6: Histogram for Tossing One Die It is not very interesting but we can identify whether we won more often or lost more often. In this case, we lost more often than we won and summary statistics can tell us the average amount lost. favstats(red_bet, data=red_bet_df) ## min Q1 median Q3 max mean sd n missing ## -100 -100 -100 100 100 -6.52 99.79221 10000 0 For our simulation of 10,000 trials of \\(\\$100\\) red bet, our mean was \\(-\\$6.52\\), a little worse than our theoretical expectation of \\(-\\$5.26\\). Note also the standard deviation is \\(99.79\\) which makes sense given the typical deviation on either side of the mean is around \\(100\\). 24.5 Analyzing the Single Number Bet Consider a long shot single number bet, such as a \\(\\$100\\) bet on the number 7. The single number bet (called a “straight”) has a payout of 35 to 1 meaning if you win you win \\(\\$35\\) for every \\(\\$1\\) bet. There is only one way to win so the probability of winning is 1/38. We complete the table below to find the probability distribution and expected value for \\(\\$100\\) bet on a single number. Figure 24.7: Roulette Single Number Disribution The expectation is \\(-\\$5.26\\). Let’s see how a simulation compares modifying the distribution values and probabilities. single_bet &lt;- sample(x=c(-100,3500), prob=c(37/38,1/38),size=10000, replace = TRUE) single_bet_df &lt;- data.frame(single_bet) head(single_bet) ## [1] -100 -100 -100 -100 -100 -100 Examining the histogram we see that wins are few and far between (but remember the payoff is awesome when it happens). ggplot(data=single_bet_df, aes(x=single_bet)) + geom_histogram(aes(y=..density..), binwidth = 50) Figure 24.8: Histogram for Tossing One Die We really need to run summary statistics to find the mean amount won or lost in our simulation favstats(single_bet, data=single_bet_df) ## min Q1 median Q3 max mean sd n missing ## -100 -100 -100 -100 3500 8.36 615.1357 10000 0 For our simulation of 10,000 trials of \\(\\$100\\) bet on a single number, our mean was \\(+\\$8.36\\). Wow. We came out a winner and actually won \\(10000 \\cdot 8.63=86,300\\) dollars though may not be as lucky next time. Note, also the standard deviation is \\(615.14\\) which is more than six times larger than the standard deviation for a \\(\\$100\\) even-money bet. 24.6 Exercises 24.6.1 Exercise - Four and Five Number Bets Determine the expectation for a \\(\\$100\\) bet on four numbers. Determine the expectation for a \\(\\$100\\) bet on five numbers. Which of these bets has the more favorable expectation? 24.6.2 Exercise - Simulating a Roulette Bet Select one of the roulette bets not yet analyzed and consider a \\(\\$100\\) bet. (a) Determine the expectation for this bet. (b) Run a simulation of at least 1000 trials of this bet, visualize the results with a histogram, and find the mean amount won/lost. (c) How similar or different was the theoretical expectation from the simulated mean? 24.6.3 Exercise - The Rule of 36 One nice rule for determining the roulette payoffs is the following formula we’ll call the Rule of 36: The payoff ratio plus one all multiplied by the number of ways you can win the bet always equals 36. Write the Rule of 36 symbolically letting N be the number of ways to win your bet and X being the payoff ratio. Use the Rule of 36 to confirm the payoff odds for following bets - single number (straight up), two number (split), three number (street), four number (corner), five number (basket) NB: round down!, six number (line), and twelve number (column, dozen). 24.6.4 Exercise - European Roulette European roulette as played in Monte Carlo, for example, is different than American roulette. In European roulette there is only a single zero…no double zero. In addition, in an even money bet such as a bet on red, if the ball lands on the green 0 on the first spin, then your bet is put “in prison” and gets to stay there one more round. In such a case, on the second round, if one of your spots comes up, instead of losing you get your bet back and on any other spot you lose. Here we examine the difference the single zero and the “in prison” rule has on the expectation. Figure 24.9: European Roulette Wheel and Layout Suppose that you have \\(\\$100\\) to make one bet. Calculate the expected value for a \\(\\$100\\) bet on Red on a single-zero wheel with the “in prison” rule. To do so, you need to find the probabilities associated with three possible outcomes - you lose \\(\\$100\\) if you get black, you break even if you get 0 and then a red, you win \\(\\$100\\) if you get red. Recall the expected payoff on an even-money bet American double-zero wheel is \\(-\\$5.26\\). Is the expectation on a European single-zero wheel the same, more negative, or less negative? Determine the expectation for one of the other bets (there is no in prison rule for the non-even-money bets). Is it the same, more negative, or less negative than the corresponding bet in American roulette? "],["case_study_craps.html", "Chapter 25 Case Study - Craps 25.1 Chapter Scenario - Getting Six the Hard Way 25.2 Single Roll Craps Bets 25.3 The Craps Passline Bet Explained 25.4 Chapter Scenario Revisited - Getting Six the Hard Way 25.5 Exercises", " Chapter 25 Case Study - Craps 25.1 Chapter Scenario - Getting Six the Hard Way In the game of craps, players can make a plethora of bets on the outcome of two dice. See the craps layout below. Figure 25.1: Craps Layout Some bets are single-roll bets, resolved with one toss of the dice, and others are multi-roll bets, where it may take many rolls before the bet is decided. One of the multi-roll bets is the Hardway 6. To win this bet you have to roll a sum of six the hard way, that is, with double-threes, before rolling a sum of six the easy way (1,5 or 2,4) or before rolling a sum of seven. This bet has a payoff of 9:1. What is the probability of winning this bet and what is the expectation? 25.2 Single Roll Craps Bets Some craps bets are single roll bets, resolved in one toss of the dice. For example, one can make the Eleven or Five Six bet. If a sum of 11 comes up you win. Otherwise, you lose. The payoff is 15:1. Examining the sample space for dice there are 2 ways to win and 34 ways to lose, thus, \\(P(win \\ eleven \\ bet)=2/36\\) and \\(P(lose \\ eleven \\ bet)=34/36\\). We can calculate the expectation of winnings on the eleven bet, X, assuming a \\(\\$1\\) bet. \\[E(X)= 15 \\cdot \\frac{2}{36}+(-1) \\cdot \\frac{34}{36}=\\frac{-4}{36}=-0.111\\] Thus, we expect to lose 11.1 cents on average for every 1 dollar bet on the eleven bet, an \\(11.1\\%\\) house advantage. 25.3 The Craps Passline Bet Explained The heart of craps is the passline bet. The player rolling the dice must make this bet and other players around the table may join her (or, to be contrary, may bet against her). The passline bet pays off at even money, 1:1, and is potentially a multi-roll bet. The first roll of the dice on the passline bet is called the come out roll and you win on this first roll if you roll a sum of 7 or 11 (this is called a natural) and you lose on the first roll if you roll a sum of 2, 3, or 12 (this is called craps). It helps to have an image of the sample space for rolling two dice handy. Figure 25.2: Sample Space for Two Dice \\[P(natural)=P(7 \\ or \\ 11)=P(7)+P(11)=6/36+2/36=8/36\\] \\[P(craps)=P(2 \\ or \\ 3 \\ or \\ 12)=P(2)+P(3)+P(12)=1/36+2/36+1/36=4/36\\] You are twice as likely to win on the come out roll as to lose but notice most of the time (1-8/36-4/36=24/36) you neither win nor lose. In these cases, the sum you roll on the come out roll is established as the “point”, thus, the sum you roll (4, 5, 6, 8, 9, or 10) is the point and now to win you must roll this sum again before rolling a sum of seven. If you do, this is called passing. If you roll the sum of seven before you roll your first sum again, then you lose. We need to determine the probability of winning (ie., passing) in all of these different cases. Let’s start with the case you roll a sum of 4. In the original two dice sample space below we have circled the outcomes that resolve this bet. Figure 25.3: Sample Space for Two Dice for a Point of Four Since these 9 outcomes are the only ones that resolve the bet, we will ignore all occurrences of other sums and use these 9 outcomes as our new sample space as shown below. Figure 25.4: Sample Space for a Point of Four Since there are three ways to win and six ways to lose, \\[P(passing \\mid point \\ of \\ four) = 3/9\\] and \\[P(not \\ passing \\mid point \\ of \\ four) = 6/9\\] With a similar analysis, we can determine the probability of passing and of not passing for points of 5, 6, 8, 9, and 10. These values are shown in the table below. Figure 25.5: Passing and Not Passing for Different Points To find the probability of winning on a passline bet we need to examine all of these cases. Here is how we can partition winning on the passline bet. \\[P(win \\ passline)=P(natural)+P(4 \\ and \\ pass) + P(5 \\ and \\ pass)+ \\\\ P(6 \\ and \\ pass)+P(8 \\ and\\ pass)+P(9 \\ and \\ pass)+p(10 \\ and \\ pass)= \\\\ P(natural)+P(4)P(pass \\mid 4)+P(5)P(pass \\mid 5)+P(6)P(pass \\mid 6) \\\\ +P(8)P(pass \\mid 8)+P(9)P(pass \\mid 9)+P(10)P(pass \\mid 10) = \\\\ 4/36+(3/36)(3/36)+(4/36)(4/10)+(5/36)(5/11)+(5/36)(5/11)+(4/36)(4/10)+(3/36)(3/36)\\] It is now easy to determine the probability of losing the passline bet. \\[P(losing \\ passline) = 1 - P(winning \\ passline) = 1 - 0.493=0.507\\] We are now in position to find the expectation of the winnings, X. Let’s assume \\(\\$1\\) is bet on the passline. Note, there are no casinos allowing this small of a bet. Often the minimum is \\(\\$5\\). \\[E(X)= (+1) \\cdot 0.493 + (-1) \\cdot 0.507 = -0.0140\\] This means that we lose about 1.4 cents for each dollar bet on the passline. This is a \\(1.4\\%\\) house advantage. 25.4 Chapter Scenario Revisited - Getting Six the Hard Way Recall, we win a Hardway Six bet by rolling six the hard way with double threes before rolling a six any other way or rolling a seven. The payoff is 9:1. Out of the eleven different ways this bet is resolved as shown in the image below, there is only one way to win. Figure 25.6: The Hardway Six Sample Space Thus, \\(P(win Hardway Six)=1/11\\) and \\(P(lose Hardway Six)=10/11\\). We find the expectation of the winnings below \\[E(X)= (+9) \\cdot \\frac{1}{11} + (-1) \\cdot \\frac{10}{11}= \\frac{-1}{11}=-0.0909\\] On average, on the Hardway Six we lose about 9 cents per dollar bet for a house advantage of \\(9.09\\%\\). 25.5 Exercises 25.5.1 Exercise - Single Roll Bet Find the expected value on the Aces bet, a single roll bet where double ones is a winner and everything else is a loser. This bet pays off at 30:1. 25.5.2 Exercise - Multi-roll Bet The Hardway Four bet pays off at 7:1. You win if you roll a sum of four the hardway (double two’s) and you lose if you roll a sum of four any other way or roll a sum of seven. Find the expected value. 25.5.3 Exercise - The Don’t Pass Bet The Don’t Pass Bet has payoff odds of 1:1 is almost the opposite of the Passline Bet as described below. Roll a 2 or 3 on first roll and win. Roll a 12 on first roll and get your money back (this is called BAR 12). Roll a 7 or 11 on first roll and lose. Roll anything else and this becomes the point. Roll a 7 before the point and win. Roll the point before 7 and lose. Find the expected value of a \\(\\$1\\) bet on Don’t Pass. Be sure to factor in that when 12 is rolled on the come out roll you get your money back and break even. 25.5.4 Exercise - Free Odds When a point is established a pass line player may place a bet equal to the original bet on the point paying off at the true odds of that point passing. (a) Determine true odds for each possible point - 4, 5, 6, 8, 9, 10. That is, determine the payoff odds that would result in a fair bet with expected value of 0. (b) Consider a \\(\\$10\\) passline bet with a \\(\\$10\\) free odds bet taken whenever possible. The expected value for a \\(\\$10\\) passline bet is -0.140. Given that the additional odds bet is a fair bet, what would the expectation be on the \\(\\$10\\) passline bet with \\(\\$10\\) free odds taken whenever possible? Explain. "],["case_study_poker.html", "Chapter 26 Case Study - Poker 26.1 Introduction 26.2 Exercises", " Chapter 26 Case Study - Poker 26.1 Introduction Poker has hit the big time with millions of players worldwide and even a World Series of Poker with professional players. There are many variations of the game with Texas Hold’em currently being the most popular but virtually all of them are ultimately decided by whoever holds the strongest five card hand. Since you are playing against other players rather than the house an understanding of human behavior is as important as an understanding of probability. Two key elements of success in poker are money management - knowing when and how much to bet - and bluff - deceptively bet and pretend your hand is stronger than it really is. For starters we will use our probability skills to verify the ranking of hands as shown in the diagram below. Figure 26.1: Poker Hands Ranked Some terminology. A flush is five cards all from the same suit. A straight is five cards in sequence. An ace can be considered as either low or high. First of all, a standard deck consists of 52 cards with four suits (clubs, diamonds, hearts, and spades) with each suit containing 13 cards (A,2,3,4,5,6,7,8,9,10,J,Q,K). The strength of a poker hand does not depend on the order in which the cards were received so the total number of five card hands is \\(\\dbinom{52}{5}=2598960\\). We use the choose(n,k) command in R to compute \\(\\dbinom{n}{k}\\). total &lt;- choose(52,5) total ## [1] 2598960 We can take the poker hands in order and determine how many of each different hand there are and calculate the probability of obtaining such a hand. A key problem-solving tool will be to construct a verbal model of a step-by-step process to obtain such a hand. 26.1.1 The Royal Flush A royal flush is the highest hand possible. It is the 10, J, Q, K, and A all from the same suit. A flush is all the cards from the same suit and the jack, queen, and king are royalty, hence, the name royal flush. The counting on this one is easy. There are only four such hands, one for clubs, one for diamonds, one for hearts, and one for spades. The probability is prob_royal &lt;- 4/total prob_royal ## [1] 1.539077e-06 26.1.2 Straight Flush This is left as an exercise. 26.1.3 Four of a Kind This is left as an exercise. 26.1.4 Full House A full house is three of one kind and two of another. The step-by-step verbal model to construct a full house proceeds but first selecting a kind for the three of a kind and choosing three of that kind, then selecting a second kind and choosing two of that kind. Figure 26.2: Full House Step-by-step Verbal Model count_full_house &lt;- choose(13,1)*choose(4,2)*choose(12,1)*choose(4,2) count_full_house ## [1] 5616 prob_full_house &lt;- count_full_house/total prob_full_house ## [1] 0.002160864 26.1.5 Flush A flush is five cards all from the same suit. The step-by-step verbal model to construct a flush proceeds by first selecting a suit and then selecting five cards from that suit. We must then be careful to subtract off the straight flushes as they are actually a stronger hand. Figure 26.3: Flush Step-by-step Verbal Model count_flush &lt;- choose(4,1)*choose(13,5) - 36 - 4 count_flush ## [1] 5108 prob_flush &lt;- count_flush/total prob_flush ## [1] 0.001965402 26.1.6 Straight To count the number of straights we will count all straights and the subtract the straight that are also flushes which are considered higher hands. To organize in a step-by-step verbal model, first choose a starting point for the straight. There are ten starting points for the smallest card - A,2,3,4,5,6,7,8,9, or 10. Then choose one of each of the five kinds in the straight. Lastly, we subtract off the straight flushes and royal flushes. Figure 26.4: Straight Step-by-step Verbal Model count_straight &lt;- choose(10,1)*choose(4,1)^5 - 36 - 4 count_straight ## [1] 10200 prob_straight &lt;- count_straight/total prob_straight ## [1] 0.003924647 26.1.7 Three of a Kind One step-by-step verbal model for three of a kind is to first choose the kind, then choose three of that kind, then choose two other kinds and choose one each of those kinds. Figure 26.5: Three of a Kind Verbal Model count_three &lt;- choose(13,1)*choose(4,3)*choose(12,2)*choose(4,2)*choose(4,2) count_three ## [1] 123552 prob_three &lt;- count_three/total prob_three ## [1] 0.04753902 26.1.8 Two Pair Correctly counting the number of two pair hands has a subtlety. It is important to select the two kinds for the two pairs rather than select them sequentially. A correct step-by-step verbal model starts with select two different kinds, then select two of each of these kinds, then select a third kind and select one of this kind. Figure 26.6: Two Pair Verbal Model count_two_pair &lt;- choose(13,2)*choose(4,2)*choose(4,2)*choose(11,1)*choose(4,1) count_three ## [1] 123552 prob_two_pair &lt;- count_two_pair/total prob_two_pair ## [1] 0.04753902 It is worth exploring a seemingly plausible but incorrect step-by-step verbal model. What if to create a two-pair hand we select one kind, then select two of that kind, then select a second kind, then select two of that kind, then select a third kind and select one of that kind. Figure 26.7: Two Pair Competing Verbal Models If we compare and contrast these two verbal models we see most pieces are the same but the correct model has choose(13,2) which equals \\(\\frac{13*12}{2*1}\\) while in its place the incorrect model has choose(13,1)*choose(12,1) which equals \\(13*12\\). Numerically the second model is twice as big as or original model and so twice as wrong, so to speak. To see what is wrong with it, consider the following concrete examples visualized in the diagram below. They are counted as different hands in the verbal model but are really the same hand. The incorrect model imposes an inappropriate order on the two pairs. 26.1.9 One Pair This is left as an exercise. 26.1.10 High Card This is left as an exercise. 26.1.11 Summary Table Compiling the results for all the different poker hand we have the following table: Hand, Number, Probability, Odds Royal Flush Straight Flush Four of a Kind Full House Flush Straight Three of a Kind Two Pair One Pair High Card Figure 26.8: Poker Hands Table 26.2 Exercises 26.2.1 Exercise - Straight Flush How many different straight flush hands are there? If you are randomly dealt five cards, what is the probability of obtaining a straight flush? Note, make sure you are not including the royal flush hands in your count. 26.2.2 Exercise - Four of a Kind How many different four of a kind hands are there? If you are randomly dealt five cards, what is the probability of obtaining four of a kind? 26.2.3 Exercise - One Pair How many different one pair hands are there? If you are randomly dealt five cards, what is the probability of obtaining a one pair hand? 26.2.4 Exercise - High Card How many different high card hands are there? If you are randomly dealt five cards, what is the probability of obtaining nothing better than a high card hand? (Hint: Since all the other kinds of hands have been analyzed, the complement principle is one effective approach to counting this last hand type.) 26.2.5 Exercise - Spot the Error Consider this flawed step-by-step verbal model for a three of a kind hand. First choose one kind and then three of that kind, then choose a second kind and choose one of that kind, then choose a third kind and choose one of that kind. What is the subtle flaw in this step-by-step verbal model? "],["case_study_keno.html", "Chapter 27 Case Study - Keno 27.1 Analyzing a One-spot Keno Ticket 27.2 Analyzing a Two-spot Keno Ticket 27.3 Exercises", " Chapter 27 Case Study - Keno In Keno, a player pays $1 and chooses some numbers between 1 and 80 by marking them on a Keno card. Figure 27.1: Keno Card Then the computer randomly selects 20 numbers. Depending on how many of the player’s numbers match (“catch”) the chosen numbers, they win different amounts of money as shown in the payoff table below. Figure 27.2: Keno Payouts 27.1 Analyzing a One-spot Keno Ticket For example, on a one-spot ticket, the player pays \\(\\$1\\) and marks one number and if it is among the 20 selected by the computer, the player wins \\(\\$3\\) for a net win of \\(+\\$2\\). Keno probabilities can be found using the hypergeometric model with m=20 good numbers, n=60 bad numbers, with k=1 selected and x is the number of good ones selected. The expected value of the winnings, X, is the sum of the payoffs times the probabilities. \\[E(X) = -1 \\cdot P(catch \\ 0) + 2 \\cdot P(catch \\ 1)=-1 \\cdot \\frac{60}{80} + 2 \\cdot \\frac{20}{80}=-\\frac{20}{80}=-0.25\\] Not such a great game from the player’s vantage point as they lose on average a quarter per dollar bet for a \\(25\\%\\) house advantage. We can use the R code below to find the expected value for a \\(\\$1\\) one-spot ticket by first creating a vector of the hypergeometric probabilities and a vector of the amounts won/lost. probs_one_spot &lt;- dhyper(x=0:1, m=20, n=60, k=1) amounts_one_spot &lt;- c(-1,2) distribution_one_spot &lt;- data.frame(probs_one_spot, amounts_one_spot) distribution_one_spot ## probs_one_spot amounts_one_spot ## 1 0.75 -1 ## 2 0.25 2 We can calculate the mean expected value by deterimining the sum of the amounts multiplied by the probs. expectation_one_spot &lt;- sum(amounts_one_spot*probs_one_spot) expectation_one_spot ## [1] -0.25 27.2 Analyzing a Two-spot Keno Ticket Suppose a player buys a \\(\\$1\\) ticket marking two spots. If they catch 0 spots they lose \\(\\$1\\), if they catch one spot the get their dollar back and break even, and if they catch two spots they get \\(\\$9\\) back for a net profit of \\(\\$8\\). Determining the expected value of the winnings, X, by hand using the hypergeometric probability distribution we see \\[E(X) = -1 \\cdot \\frac{\\dbinom{20}{0}\\dbinom{60}{2}}{\\dbinom{80}{2}} + 0 \\cdot \\frac{\\dbinom{20}{1}\\dbinom{60}{1}}{\\dbinom{80}{2}} + 8 \\cdot \\frac{\\dbinom{20}{2}\\dbinom{60}{0}}{\\dbinom{80}{2}}= \\\\ -1 \\cdot 0.560 + 0 \\cdot 0.380 + 8 \\cdot 0.060 = -0.079 \\] With R code: probs_two_spot &lt;- dhyper(x=0:2, m=20, n=60, k=2) amounts_two_spot &lt;- c(-1,0,8) distribution_two_spot &lt;- data.frame(probs_two_spot, amounts_two_spot) distribution_two_spot ## probs_two_spot amounts_two_spot ## 1 0.56012658 -1 ## 2 0.37974684 0 ## 3 0.06012658 8 We calculate the mean expected value. expectation_two_spot &lt;- sum(amounts_two_spot*probs_two_spot) expectation_two_spot ## [1] -0.07911392 The two-spot ticket has a much better expected value than a one-spot ticket. 27.3 Exercises 27.3.1 Exercise - Analyzing a Three-spot and Four-spot Keno Tickets Find the expected value for a three-spot Keno ticket and a four-spot Keno ticket and make comparisons about which is more advantageous (or, rather, less disadvantageous) for the player. 27.3.2 Exercise - Changing Perspectives Suppose a player has marked an 5-spot Keno ticket. In the analysis above, we consider the m=20 good numbers and n=60 bad numbers and k=5 numbers selected with x representing the numbers we catch and use this hypergeometric model. For example, \\[P(catch \\ 3) = \\frac{\\dbinom{20}{3}\\dbinom{60}{2}}{\\dbinom{80}{8}}=0.084\\] An alternative approach is to consider that we have m=5 good ones that we’ve selected and n=75 bad ones we haven’t selected and then the computer chooses k=20 with x representing the number of good ones selected. Thus, \\[P(catch \\ 3) = \\frac{\\dbinom{5}{3}\\dbinom{75}{17}}{\\dbinom{80}{20}}=0.084\\] For a 5-spot ticket show the probabilities of catching 0, catching 1, and catching 2 using both techniques and confirm they yield the same answers. 27.3.3 Exercise (Group Project) - Complete Analysis of Keno As a group project, find the expected values for a one-spot ticket, a two-spot ticket, and so on all the way through a 15-spot ticket and identify which bet has the worst expected value or the player and which has the best expected value. "],["case_study_powerball_lottery.html", "Chapter 28 Case Study - Powerball Lottery 28.1 Introduction 28.2 Ways to Win Powerball 28.3 The Expected Value of Powerball 28.4 Looking for a Winner 28.5 Exercises", " Chapter 28 Case Study - Powerball Lottery Figure 28.1: Powerball Logo 28.1 Introduction The Powerball Lottery is a multi-state lottery held twice a week. Most states participate (except Alabama, Alaska, Hawaii, Louisiana, Nevada, and Utah). A ticket costs two dollars. The player selects five different numbers from 1 to 69 for the white balls and one number from 1 to 26 for the red Powerball. If your five numbers match the five winning numbers and your Powerball matches the winning Powerball, then you can buy everything you want. The Powerball selected can be the same as one of the white balls selected. There are nine ways to win as shown in the graphic below. Figure 28.2: Ways to Win Powerball 28.2 Ways to Win Powerball To determine the probability of being a winner we need to determine how many different Powerball combinations there are. We create a step-by-step verbal model by first choosing five numbers from 69 and then choosing one number from 26. \\[Total = \\dbinom{69}{5} \\cdot \\dbinom{26}{1}=292201338\\] There is only one Grand Prize winning combination so the probability of winning is \\[P(Grand Prize)=\\frac{1}{\\dbinom{69}{5} \\cdot \\dbinom{26}{1}}=\\frac{1}{292201338}=0.000000003422298\\] There are other winning combinations. 28.2.1 Winning Powerball with Five White A step-by-step verbal model to win with five white balls is to first choose all five of the five winning white balls and then to choose one one the non-winning 25 Powerballs. \\[P(\\text{Five White Balls})=\\frac{\\dbinom{5}{5} \\cdot \\dbinom{25}{1}}{292201338}=0.00000008555745\\] 28.2.2 Winning Powerball with Four White + Powerball A step-by-step verbal model to win with four white balls plus the Powerball is to first choose four of the five winning white balls, then choose one of the 64 non-winning white balls and then to choose the one right Powerballs. \\[P(\\text{Four White Balls + Powerball})=\\frac{\\dbinom{5}{4} \\cdot \\dbinom{64}{1} \\cdot \\dbinom{1}{1}}{292201338}=0.000001095135\\] 28.2.3 Winning Powerball with Four White A step-by-step verbal model to win with four white balls is to first choose four of the five winning white balls, then choose one of the 64 non-winning white balls and then to choose one of the 25 non-winning Powerballs. \\[P(\\text{Four White Balls})=\\frac{\\dbinom{5}{4} \\cdot \\dbinom{64}{1} \\cdot \\dbinom{25}{1}}{292201338}=0.00002737838\\] 28.2.4 Winning Powerball with Three White + Powerball Left as an exercise. 28.2.5 Winning Powerball with Three White Left as an exercise. 28.2.6 Winning Powerball with Two White + Powerball Left as an exercise. 28.2.7 Winning Powerball with One White + Powerball Left as an exercise. 28.2.8 Winning Powerball with Powerball Only There is one winning Powerball number out of 26 total so your chance of getting the Powerball right is \\(1/26\\) but to get the Powerball only you must have losers for all five white. The step-by-step verbal model is to first choose all five white numbers wrong and then choose the Powerball number right. \\[P(\\text{Powerball Only})=\\frac{\\dbinom{64}{5} \\cdot 1}{292201338}=0.02609335\\] 28.3 The Expected Value of Powerball To find the expected value for the winnings, X, on a \\(\\$2\\) Powerball ticket we need to find the weighted average of the different payoffs weighted by their probabilities. We will assume the Grand Prize is \\(\\$40\\) million which is the minimum. We need a vector of the different winning amounts. winnings &lt;- c(-2,2,2,5,5,98,98,49998, 999998, 39999998) Although some of the above probabilities are left as exercises we include their answers in the function below to compute the probability of matching m=0,1,2,3,4,5 white balls and n=0,1 powerballs. powerball_prob &lt;- function(m,n) { choose(5,m)*choose(64,5-m)*choose(25,1-n)/(choose(69,5)*26) } probs &lt;- c(powerball_prob(0,0), powerball_prob(0,1), powerball_prob(1,1), powerball_prob(2,1), powerball_prob(3,0), powerball_prob(3,1), powerball_prob(4,0), powerball_prob(4,1), powerball_prob(5,0), powerball_prob(5,1)) The expectation is the sum of the winnings multiplied by the probabilities. expectation_powerball &lt;- sum(winnings*probs) expectation_powerball ## [1] -0.9283347 How does this look? Good investment? Maybe the most likely payoff is a psychological one. 28.4 Looking for a Winner As we have seen, the probability that a Powerball ticket wins the Grand Prize is \\(\\frac{1}{292201338}\\) and the probability of not winning is \\(\\frac{292201337}{292201338}\\). Only 1 in almost 300 million tickets is the Grand Prize winner. How many tickets must be sold for there to be a good chance of there being a winner? This is like an urn model where there are almost 300 million balls and only one of them is the winner. If each ticket was unique the situation would match drawing balls from the urn without replacement and the answer would be straight forward. After about 150 million balls are drawn, the probability the winning combination was drawn would be about 0.50. But each individual independently chooses their own ticket so the situation matches more closely drawing from the urn with replacement. Because there could be multiple winners, to find the probability of at least one winner, the complement principle is needed. \\[P(\\text{at least one winner})=1-P(\\text{no winners})\\] What if 1 million people buy tickets? \\[P(\\text{at least one winner})=1-P(\\text{no winners})=1-(\\frac{292201337}{292201338})^{1000000}=0.003416\\] What if 10 million people buy tickets? \\[P(\\text{at least one winner})=1-P(\\text{no winners})=1-(\\frac{292201337}{292201338})^{10000000}=0.033644\\] What if 100 million people buy tickets? \\[P(\\text{at least one winner})=1-P(\\text{no winners})=1-(\\frac{292201337}{292201338})^{100000000}=0.289815\\] Now, it’s getting hot. There is a good chance someone might win. We could turn this formula around using algebra. In general, the probability of a winner with n tickets sold is \\[P(\\text{at least one winner})=1-P(\\text{no winners})=1-(\\frac{292201337}{292201338})^{n}\\] Letting p represent the probability of at least one winner and solving for n, \\[n=\\frac{log(1-p)}{log(\\frac{292201337}{292201338})}\\] We can create a function to find n for a desired value of p. The ceiling function rounds the decimal up to the next whole number. inverse_powerball &lt;- function(p){ if (p&lt;0 | p&gt;1) stop(&quot;p must be between 0 and 1&quot;) ceiling(log(1-p)/log(292201337/292201338)) } How many tickets need to be sold for there to be a \\(10\\%\\) chance of a winner? inverse_powerball(0.1) ## [1] 30786484 How many tickets need to be sold for there to be a \\(50\\%\\) chance of a winner? inverse_powerball(0.5) ## [1] 202538536 Over 200 million tickets need to be sold for there to be a \\(50\\%\\) chance of someone winning the Grand Prize. 28.5 Exercises 28.5.1 Exercise - Ways to Win Powerball Find the probability of winning Powerball in each of the following ways. (a) Win with Three White Balls + Powerball (b) Win with Three White Balls (c) Win with Two White Balls + Powerball (d) Win with Two White Balls 28.5.2 Exercise - Can I Get a Winner? How many people need to buy tickets for the probability of a winner to be at least 0.90? 28.5.3 Exercise - Today: 522 Million Dollar Jackpot As reported on NBC Evening News with Lester Holt on July 24, 2018, the Powerball jackpot topped \\(\\$522\\) million. What is the expected value of a \\(\\$2\\) ticket? 28.5.4 Exercise - Think Positive Expectation How big would the Grand Prize need to be in order for the expected value to turn positive? (Ignore the possibility that there is more than one winner.) Would this mean that spending a chunk of your money on Powerball is a good investment? Explain. 28.5.5 Exercise - Thinking about Dependencies When finding the probability of at least one winner if n tickets were sold we assumed that each individual independently chooses their own ticket. If this was not the case and there were patterns in the selection of tickets where some patterns were more likely to be chosen than others, would this increase or decrease the probability of at least one winner if n tickets were sold? Explain. "],["case_study_bingo.html", "Chapter 29 Case Study - BINGO 29.1 Chapter Scenario - BINGO on the Fun Bus 29.2 Bingo Basics 29.3 Winning Bingo with m Numbers Called 29.4 Chapter Scenario Revisited - BINGO on the Fun Bus 29.5 Exercises", " Chapter 29 Case Study - BINGO 29.1 Chapter Scenario - BINGO on the Fun Bus If the Fun Bus to Wendover is a double-decker and full there will be around 100 full seats. On the way over, to pass the time, the hostess calls a few Bingo games and the winner gets \\(\\$1\\) plus a candy bar. Of course, you have a \\(1/100\\) chance of being a winner but how long is a Bingo game likely to go on before there is a winner. Specifically, if there are 100 players playing a regular Bingo game, how many numbers must be called for there to be a greater than \\(50\\%\\) chance of a winner? Think about it and make an estimate. 29.2 Bingo Basics You all know BINGO. Get five in a row up, down, or diagonally and win. Variations of BINGO include Blackout (completely fill your card), wedding cake (completely fill top, middle, and bottom row) T (make a T shape), Z (you can figure this one out), and getting all four corners. Bingo cards look like this: Figure 29.1: BINGO Card BINGO is a social game and a good BINGO caller has a few choice bits to spice up calling the game. For example, “The tumor was B9.” But enough of that; we are interested in the probabilities of winning. First of all, how many cards are there? Cards consist of five columns each matching with either B, I, N, G, or O. Each column has five different numbers printed in order of size from top to bottom except the middle column which only has four numbers and a FREE spot in the middle. The B column contains five different numbers from 1 to 15, the I column five different numbers from 16 to 30, the N column a free spot and four different numbers from 31 to 45, the G column five different numbers from 46 to 60, and the O column five different numbers from 61 to 75. Figure 29.2: BINGO Card Verbals Model This is a big number. We can use R to compute. bingo_total &lt;- choose(15,5)^4*choose(15,4) bingo_total ## [1] 1.110079e+17 29.3 Winning Bingo with m Numbers Called Suppose you have nothing better to do and are playing BINGO. What is the probability you will win after just four numbers have been drawns. With 75 numbers there are a total of \\(\\dbinom{74}{4}\\) ways that four numbers could be drawn but only four sets of four numbers are winners for you as shown. Figure 29.3: BINGO Win with Four Numbers Drawn So not very likely. prob_win_4 &lt;- 4/choose(75,4) prob_win_4 ## [1] 3.290962e-06 What about the chance you will win after five numbers are called? There are a total of \\(\\dbinom{75}{5}\\) ways that five numbers can be drawn and there are now 12 ways to win as shown. Figure 29.4: BINGO Win with Five Numbers Drawn Winning is more complicated as shown in the verbal model. Figure 29.5: Verbal Model for BINGO Win with Five Numbers There are eight ways to win with all five numbers. There are four ways to win with four of these numbers with a fifth number that can be any of the other 71 possibilities. prob_win_5 &lt;- (8*1+4*1*71)/choose(75,5) prob_win_5 ## [1] 1.691833e-05 Highly dubitable! What is the probability of winning with six numbers? Six numbers can be selected a total of \\(\\dbinom{75}{6}\\). Again, there are eight ways to win with five numbers and the sixth number can be any of the other 70 possibilities. There are four ways to win with four numbers and the other two numbers can be any of the other 71 possibilities. See the verbal model below. Figure 29.6: Verbal Model for BINGO Win with Six Numbers Computing this: prob_win_6 &lt;- (8*1*70+4*1*choose(71,2))/choose(75,6) prob_win_6 ## [1] 5.214553e-05 We can modify this approach to find the probability of winning after seven numbers are drawn and we leave this as an exercise. Then it gets trickier once we get above seven numbers as there is the possibility of winning in multiple ways at the same time so we need to be concerned about double-counting and subtract off any overlap. A verbal model that partially captures this idea is below though it is vague about the overlap. Suppose that \\(m\\) numbers have been called and we want to find the probability of winning. Figure 29.7: Verbal Model for BINGO Win with More than Seven Numbers We can apply this verbal model in the case of eight numbers being called. With eight numbers called the only overlap is if two different four number Bingos are completed. Since there are four different four number Bingo paths, there are \\(\\dbinom{4}{2}=6\\) ways that two of them could be completed. Figure 29.8: Verbal Model for BINGO Win with Eight Numbers Computing the total minus the overlap \\[8 \\cdot 1 \\cdot \\dbinom{70}{3}+4 \\cdot 1 \\cdot \\dbinom{71}{4} - \\dbinom{4}{2}\\] Computing this in R. prob_win_8 &lt;- (8*1*choose(70,3)+4*1*choose(71,4)-choose(4,2))/choose(75,8) prob_win_8 ## [1] 0.0002563239 Dealing with the overlap gets trickier still as the numbers called increases. For example, with 9 numbers called there could be an overlap of two four number paths or a four number path and a five number path. Here is the verbal model for getting a BINGO with 9 numbers called. Figure 29.9: Verbal Model for BINGO Win with Nine Numbers Computationally, prob_win_9 &lt;- (8*1*choose(70,4)+4*1*choose(71,5)-choose(4,2)*67-4*8)/choose(75,9) prob_win_9 ## [1] 0.0004730608 The overlap gets worse later on. With 12 numbers called there could be an overlap of two four number paths, two five number paths, a four number path and a five number path but we have overcounted because there is also the chance of three four number BINGO paths happening. 29.4 Chapter Scenario Revisited - BINGO on the Fun Bus Recall, we are on the Fun Bus to Wendover and 100 people are playing regular BINGO and we want to know how many numbers must be called for there to be a greater than \\(50\\%\\) chance of a winner. The question we consider is the probability of there being a BINGO winner if m numbers have been called and we have 100 players. Let’s deal with a specific case first fixing it at 8 called numbers. As we determined above, the probability of a BINGO winner with 8 or 9 numbers is quite small. If we have 100 players, then the number of BINGO winners after m numbers are called is a binomial random variable with \\(n=100\\) trials and probability of success we have computed. To find the probability of at least one BINGO winner we use the complement principle to find \\(P(\\text{at least one winner})=1-P(\\text{no winners})\\). Letting X represent the number of winners we know \\(P(X \\geq 1)=1-P(X=0)\\). With \\(n=100\\) people playing then the chance of a BINGO after 8 numbers are called can easily be computed. prob_win_8 &lt;- 1 - dbinom(0, size=100, prob=prob_win_8) prob_win_8 ## [1] 0.02530987 A probability of a winner with 100 people playing and 8 numbers called is 0.0253099 and happens about 1 every 40 times. We can compute the same values with 9 numbers called: prob_win_9 &lt;- 1 - dbinom(0, size=100, prob=prob_win_9) prob_win_9 ## [1] 0.04621526 The probability of a winner with \\(n=100\\) people with \\(m=9\\) numbers called jumps to 0.0462153 nearly doubling with this additional number. We need to consider having a couple more numbers drawn and try it again. The cases are more involved but here are the probabilities of getting a BINGO after 10, 11, 12, and 13 numbers are called. prob_win_10 &lt;- (8*1*choose(70,5)+4*1*choose(71,6)-choose(4,2)*choose(67,2)-choose(8,2)-4*8*66)/choose(75,10) prob_win_11 &lt;- (8*1*choose(70,6)+4*1*choose(71,7)-choose(4,2)*choose(67,3)-choose(8,2)*choose(65,1)-4*8*choose(66,2))/choose(75,11) prob_win_12 &lt;- (8*1*choose(70,7)+4*1*choose(71,8)-choose(4,2)*choose(67,4)-choose(8,2)*choose(65,2)-4*8*choose(66,3)+choose(4,3))/choose(75,12) prob_win_13 &lt;- (8*1*choose(70,8)+4*1*choose(71,9)-choose(4,2)*choose(67,5)-choose(8,2)*choose(65,3)-4*8*choose(66,4)+choose(4,3)*choose(63,1)+choose(4,2)*choose(8,1))/choose(75,13) Determining the chance of a winner with 10, 11, 12. and 13 numbers called for 100 people playing: prob_win_10 &lt;- 1 - dbinom(0, size=100, prob=prob_win_10) prob_win_10 ## [1] 0.07764177 prob_win_11 &lt;- 1 - dbinom(0, size=100, prob=prob_win_11) prob_win_11 ## [1] 0.1219866 prob_win_12 &lt;- 1 - dbinom(0, size=100, prob=prob_win_12) prob_win_12 ## [1] 0.1810966 prob_win_13 &lt;- 1 - dbinom(0, size=100, prob=prob_win_13) prob_win_13 ## [1] 0.2557133 We are getting there. Slowly! If we ignore the overlap, which is relatively small, we can facilitate the computation by creating a function to estimate the probability of a win with m numbers called. prob_win &lt;- function(m) { (8*choose(70,m-5)+4*choose(71,m-4))/choose(75,m) } Test this out. prob_win(10) ## [1] 0.000807908 prob_win(11) ## [1] 0.001300162 prob_win(12) ## [1] 0.001996131 prob_win(13) ## [1] 0.002949583 These are very close to the true probabilities computed. In addition, we can compute a number of them at once: prob_win(10:13) ## [1] 0.000807908 0.001300162 0.001996131 0.002949583 Let’s solve this puppy. Dropping prob_win(1:20) into the binomial probability of a winner with 100 people playing we see if we hit the \\(50\\%\\) mark: prob_win_vector &lt;- prob_win(1:20) prob_win_100 &lt;- 1 - dbinom(0, size=100, prob=prob_win_vector) prob_win_100 ## [1] 0.0000000000 0.0000000000 0.0000000000 0.0003290426 0.0016904166 ## [6] 0.0052011159 0.0124148234 0.0253099047 0.0462155875 0.0776434880 ## [11] 0.1219930563 0.1811157800 0.2557618043 0.3449967293 0.4457547986 ## [16] 0.5527544221 0.6589884840 0.7568621166 0.8397817035 0.9036991577 That’s cool. We see that the probability tips over the \\(50\\%\\) mark when 16 numbers are called and tips over the \\(90\\%\\) mark when 20 numbers are called. Can you just feel the tension in the room building. 29.5 Exercises 29.5.1 Exercise - Unique BINGO Cards There are 7.6 billion people on earth and there are more BINGO cards than this so everyone could have their own unique card. In fact, how many unique cards could each person have? 29.5.2 Exercise - Win with Seven What is the probability of a BINGO card being a winner after exactly seven numbers are called? "],["genetics.html", "Chapter 30 Genetics 30.1 Appendix 1: Genetics Examples", " Chapter 30 Genetics Placeholder chapter for draft genetics content 30.1 Appendix 1: Genetics Examples In this appendix, you are introduced to the absolute basic terminology of genetics and how the principles of probability that you learned in chapter 1 can be applied to genetics. We are going to adapt the examples from the main part of chapter 1 to genetics. We’ll look at some of the same tree diagrams and simulations but within a simple genetics framework (rather than coin flips and urns). 30.1.1 Genetics Terminology For now, we are going to use the minimum of genetic lingo to get going: trait: a characteristic, something you can see or measure (e.g. height, Huntington’s disease) gene: the DNA that controls a trait (e.g. hemoglobin beta gene) usually shown with a letter or letters (e.g. Hb) variant: one of several versions of a gene (e.g. HbS variant in hemoglobin beta that can cause Sickle Cell Anemia but there are other variants of the same gene (HbC, HbE, etc.), a.k.a. allele) chromosome: long, continuous stretch of DNA that contains many genes (humans have 2 copies of each of 22 numbered chromosomes and either 2 X chromosomes for females or an X and a Y for males) gamete: specialized cell that has only 1 copy of each chromosome that is used during sexual reproduction (e.g. egg or sperm) 30.1.2 Genetics Basics 30.1.2.1 intro to chromosomal genetics humans have 2 copies of every gene (can be same variant or different) meiosis is the process of making gametes with only 1 copy of all of the genes fertilization fuses two gametes each with 1 copy back into a cell/organism with 2 copies (1 from each parent/gamete) To summarize the important points about meiosis, parents each make gametes that contain only one of their 2 possible copies of each chromosome. Then the gametes can fuse together by fertilization to make the offspring (next generation) that again has 2 copies of each chromosome (one from each of their parents). Below are some cartoons of meiosis starting with an example cell that has 2 chromosomes (one with the A gene and a second with the B gene) and this organism has 2 copies of each chromosome. Figure 30.1: cartoon example cell Notice that the chromosomes have different variants. When that cell goes through meiosis, it produces gametes that have one copy of each of the 2 different chromosomes. Figure 30.2: making gametes Compare the original/parent and gamete and convince yourself that this gamete has one of each of the different chromosomes in the original/parent organism. Notice that the figure below says that the gamete shown is only one of the possibilities. If you like to think ahead, what are the other possibilities? If you’re not up for it yet, don’t worry, we’ll get there. To make an offspring, 2 gametes fuse by fertilization. Figure 30.3: fertilization Since each gamete has only 1 copy of each chromosome, when 2 gametes fuse, there are again 2 copies of each chromosome (one from each of their parents). So, new humans have 2 chromosomes, one from each parent. 30.1.2.2 thinking probilitisically To wrap this back around to probability and tree diagrams, you can think of each parent as having a coin for each chromosome, and each chromosome-coin has 2 sides - H and T for a coin, one for each copy of the chromosome (A1 or A2). The chromosome version is equally likely to fall on the A1 or A2 “side” (as long as we only consider one gene on each chromosome, which we will do for now). So, our tree diagram looks like this: Figure 30.4: one chromosome tree - first parent Now if we think of the gametes from the second parent as a second “coin” with A1 and A2 “sides”, our tree diagram looks like this: Figure 30.5: one chromosome tree - second parent Then we can use the multiplication rule to find the probabilities of the different offspring as seen below: Figure 30.6: one chromosome tree - offspring We can also use the addition rule to clean up our prediction a bit since most of the time it doesn’t matter which parent you get an allele from, so A1A2 and A2A1 are equivalent and we can add their probabilities together to get a combined \\(p(A1A2)=0.5\\). Also notice that in the tree diagrams and in parentheses in the meiosis drawings that we often just write the gene/variant shorthand. This shorthand is called the genotype and is pretty useful since it can save you from drawing a lot of chromosomes, but if you need the chromosomes to be sure you understand what’s going on, feel free to sketch away. 30.1.2.3 intro to DNA There are 4 main DNA letters (a.k.a. bases) - A, T, C, G - that make up genes, which can be thought of as DNA “words”. While it’s not my favorite analogy, it works reasonably well - genes are collections of DNA information. There are variants (different versions) of genes that change the letters, and many of those change the information the gene contains, and can change the organism. 30.1.2.4 genetic “notation” Geneticists (a lot like mathematicians) use abbreviations as short cuts a lot. They are first introduced above in the Genetics Terminology section, and again discussed at the end of the Thinking Probabilistically section but we’ll lay it out more here. Every gene has an abbreviated name (like a nickname) that makes it easier to write. For example, the hemoglobin beta gene goes by Hb. We use that as a base, then we add other letters to modify this name to show that we are talking about specific variants like the HbS variant in hemoglobin beta that can cause sickle cell anemia. Just to break that down, the Hb part tells us the gene, and the S part tells us which variant. Sometimes we will use numbers, such as A1 and A2 to mean the 1 and 2 variants of the A gene, or for other genes we’ll use lowercase and uppercase, such as B and b, to mean different variants of the same gene. And as a review, writing just the letter shorthand for all of the genes and variants together is the genotype of an organism. 30.1.3 Genetics Simulation Now we’ll use R to simulate the same situation shown in the tree diagram above. This version takes the long way around, but it conceptually models meiosis (gamete formation) and fertilization for 1000 offspring. Our first set of parents have the genotypes below: parent 1: A1/A1 parent 2: A2/A2 The code below simulates meiosis and fertilization of 1000 offspring, makes a table, and graphs the results. # set up the different variants that each parent has parent1_variants &lt;- c(&#39;A1&#39;,&#39;A1&#39;) parent2_variants &lt;- c(&#39;A2&#39;,&#39;A2&#39;) # list of 1000 gametes from each parent, probability of each is equal by default parent1_gametes &lt;- sample(parent1_variants, 1000, replace = TRUE) parent2_gametes &lt;- sample(parent2_variants, 1000, replace = TRUE) # put gametes together to make 1000 offspring cross_x1 &lt;- paste(parent1_gametes, parent2_gametes, sep=&quot;/&quot;) offspring1 &lt;- data.frame(table(cross_x1)) # table knitr::kable(offspring1, caption = &#39;A1xA2 parent cross simulation&#39;, booktabs = TRUE) Table 30.1: A1xA2 parent cross simulation cross_x1 Freq A1/A2 1000 # makes a bar graph of the frequency of genotypes ggplot(offspring1, aes(x=cross_x1, y=Freq)) + geom_bar(stat=&quot;identity&quot;) Now that we have the results for that set of offspring (all have the A1/A2 genotype), we can look at these offspring as parents for a new generation of offspring. Now the parents are: parent 1: A1/A2 parent 2: A1/A2 The code below simulates meiosis and fertilization of 1000 offspring, makes a table, and graphs the results. # set up the different variants that each parent has parent3_variants &lt;- c(&#39;A1&#39;,&#39;A2&#39;) parent4_variants &lt;- c(&#39;A1&#39;,&#39;A2&#39;) # list of 1000 gametes from each parent, probability of each is equal by default parent3_gametes &lt;- sample(parent3_variants, 1000, replace = TRUE) parent4_gametes &lt;- sample(parent4_variants, 1000, replace = TRUE) # put gametes together to make 1000 offspring cross_x2 &lt;- paste(parent3_gametes, parent4_gametes, sep=&quot;/&quot;) cross_x2 &lt;- gsub(&quot;A2/A1&quot;, &quot;A1/A2&quot;, cross_x2) # order doesn&#39;t matter offspring2 &lt;- data.frame(table(cross_x2)) # table knitr::kable(offspring2, caption = &#39;A1/A2 inter-cross simulation&#39;, booktabs = TRUE) Table 30.2: A1/A2 inter-cross simulation cross_x2 Freq A1/A1 234 A1/A2 487 A2/A2 279 # makes a bar graph of the frequency of genotypes ggplot(offspring2, aes(x=cross_x2, y=Freq)) + geom_bar(stat=&quot;identity&quot;) How does this compare to our predicted probabilities from the tree diagram? Remember that they were: \\(p(A1/A1) = 0.25\\) \\(p(A1/A2) = 0.5\\) \\(p(A2/A2) = 0.25\\) Should be reasonably close. Just as an additional example, the same code adapted to use B and b variants of the B gene: parent1_variants &lt;- c(&#39;B&#39;,&#39;B&#39;) parent2_variants &lt;- c(&#39;b&#39;,&#39;b&#39;) parent1_gametes &lt;- sample(parent1_variants, 1000, replace = TRUE) parent2_gametes &lt;- sample(parent2_variants, 1000, replace = TRUE) cross_x1 &lt;- paste(parent1_gametes, parent2_gametes, sep=&quot;&quot;) offspring1 &lt;- data.frame(table(cross_x1)) knitr::kable(offspring1, caption = &#39;BBxbb parent cross simulation&#39;, booktabs = TRUE) Table 30.3: BBxbb parent cross simulation cross_x1 Freq Bb 1000 ggplot(offspring1, aes(x=cross_x1, y=Freq)) + geom_bar(stat=&quot;identity&quot;) Now intercross the offspring from the first cross, each is Bb: parent3_variants &lt;- c(&#39;B&#39;,&#39;b&#39;) parent4_variants &lt;- c(&#39;B&#39;,&#39;b&#39;) parent3_gametes &lt;- sample(parent3_variants, 1000, replace = TRUE) parent4_gametes &lt;- sample(parent4_variants, 1000, replace = TRUE) cross_x2 &lt;- paste(parent3_gametes, parent4_gametes, sep=&quot;&quot;) cross_x2 &lt;- gsub(&quot;bB&quot;, &quot;Bb&quot;, cross_x2) offspring2 &lt;- data.frame(table(cross_x2)) knitr::kable(offspring2, caption = &#39;Bb inter-cross simulation&#39;, booktabs = TRUE) Table 30.4: Bb inter-cross simulation cross_x2 Freq bb 271 Bb 498 BB 231 ggplot(offspring2, aes(x=cross_x2, y=Freq)) + geom_bar(stat=&quot;identity&quot;) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
